{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+5\">#04. Why Neural Networks Deeply Learn a Mathematical Formula?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Book + Private Lessons [Here ‚Üó](https://sotastica.com/reservar)\n",
    "- Subscribe to my [Blog ‚Üó](https://blog.pythonassembly.com/)\n",
    "- Let's keep in touch on [LinkedIn ‚Üó](www.linkedin.com/in/jsulopz) üòÑ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Machine Learning, what does it mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - The Machine Learns...\n",
    ">\n",
    "> But, **what does it learn?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Machine Learning, what does it mean? ‚èØ<br><br>¬∑ The machine learns...<br><br>Ha ha, not funny! ü§® What does it learn?<br><br>¬∑ A mathematical equation. For example: <a href=\"https://t.co/sjtq9F2pq7\">pic.twitter.com/sjtq9F2pq7</a></p>&mdash; Jes√∫s L√≥pez (@sotastica) <a href=\"https://twitter.com/sotastica/status/1449735653328031745?ref_src=twsrc%5Etfw\">October 17, 2021</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Machine Learning, what does it mean? ‚èØ<br><br>¬∑ The machine learns...<br><br>Ha ha, not funny! ü§® What does it learn?<br><br>¬∑ A mathematical equation. For example: <a href=\"https://t.co/sjtq9F2pq7\">pic.twitter.com/sjtq9F2pq7</a></p>&mdash; Jes√∫s L√≥pez (@sotastica) <a href=\"https://twitter.com/sotastica/status/1449735653328031745?ref_src=twsrc%5Etfw\">October 17, 2021</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does the Machine Learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In a Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Ht3rYS-JilE\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Ht3rYS-JilE\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=329\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=329\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Practical Example ‚Üí [Tesla Autopilot](https://www.tesla.com/AI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Example where It Fails ‚Üí [Tesla Confuses Moon with Semaphore](https://twitter.com/Carnage4Life/status/1418920100086784000?s=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Simply execute the following lines of code to load the data.\n",
    "> - This dataset contains **statistics about Car Accidents** (columns)\n",
    "> - In each one of **USA States** (rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/fivethirtyeight/fivethirtyeight-bad-drivers-dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IN</th>\n",
       "      <td>14.5</td>\n",
       "      <td>3.625</td>\n",
       "      <td>4.205</td>\n",
       "      <td>13.775</td>\n",
       "      <td>13.775</td>\n",
       "      <td>710.46</td>\n",
       "      <td>108.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HI</th>\n",
       "      <td>17.5</td>\n",
       "      <td>9.450</td>\n",
       "      <td>7.175</td>\n",
       "      <td>14.350</td>\n",
       "      <td>15.225</td>\n",
       "      <td>861.18</td>\n",
       "      <td>120.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MN</th>\n",
       "      <td>9.6</td>\n",
       "      <td>2.208</td>\n",
       "      <td>2.784</td>\n",
       "      <td>8.448</td>\n",
       "      <td>8.448</td>\n",
       "      <td>777.18</td>\n",
       "      <td>133.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ME</th>\n",
       "      <td>15.1</td>\n",
       "      <td>5.738</td>\n",
       "      <td>4.530</td>\n",
       "      <td>13.137</td>\n",
       "      <td>12.684</td>\n",
       "      <td>661.88</td>\n",
       "      <td>96.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>7.332</td>\n",
       "      <td>5.640</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.040</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ND</th>\n",
       "      <td>23.9</td>\n",
       "      <td>5.497</td>\n",
       "      <td>10.038</td>\n",
       "      <td>23.661</td>\n",
       "      <td>20.554</td>\n",
       "      <td>688.75</td>\n",
       "      <td>109.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GA</th>\n",
       "      <td>15.6</td>\n",
       "      <td>2.964</td>\n",
       "      <td>3.900</td>\n",
       "      <td>14.820</td>\n",
       "      <td>14.508</td>\n",
       "      <td>913.15</td>\n",
       "      <td>142.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DE</th>\n",
       "      <td>16.2</td>\n",
       "      <td>6.156</td>\n",
       "      <td>4.860</td>\n",
       "      <td>14.094</td>\n",
       "      <td>16.038</td>\n",
       "      <td>1137.87</td>\n",
       "      <td>151.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA</th>\n",
       "      <td>18.2</td>\n",
       "      <td>9.100</td>\n",
       "      <td>5.642</td>\n",
       "      <td>17.472</td>\n",
       "      <td>16.016</td>\n",
       "      <td>905.99</td>\n",
       "      <td>153.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NH</th>\n",
       "      <td>11.6</td>\n",
       "      <td>4.060</td>\n",
       "      <td>3.480</td>\n",
       "      <td>10.092</td>\n",
       "      <td>9.628</td>\n",
       "      <td>746.54</td>\n",
       "      <td>120.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                       \n",
       "IN       14.5     3.625    4.205          13.775       13.775       710.46   \n",
       "HI       17.5     9.450    7.175          14.350       15.225       861.18   \n",
       "MN        9.6     2.208    2.784           8.448        8.448       777.18   \n",
       "ME       15.1     5.738    4.530          13.137       12.684       661.88   \n",
       "AL       18.8     7.332    5.640          18.048       15.040       784.55   \n",
       "ND       23.9     5.497   10.038          23.661       20.554       688.75   \n",
       "GA       15.6     2.964    3.900          14.820       14.508       913.15   \n",
       "DE       16.2     6.156    4.860          14.094       16.038      1137.87   \n",
       "PA       18.2     9.100    5.642          17.472       16.016       905.99   \n",
       "NH       11.6     4.060    3.480          10.092        9.628       746.54   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "IN          108.92  \n",
       "HI          120.92  \n",
       "MN          133.35  \n",
       "ME           96.57  \n",
       "AL          145.08  \n",
       "ND          109.72  \n",
       "GA          142.80  \n",
       "DE          151.48  \n",
       "PA          153.86  \n",
       "NH          120.21  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset(name='car_crashes', index_col='abbrev')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 7)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Concepts in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the `Weights`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - https://keras.io/api/layers/initializers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to `kernel_initializer` the weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "accidents = speeding \\cdot w_1 + alcohol \\cdot w_2 \\ + ... + \\ ins\\_losses \\cdot w_7\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/24/tg28vxls25l9mjvqrnh0plc80000gn/T/ipykernel_38098/3324602025.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fit' is not defined"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'algo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/24/tg28vxls25l9mjvqrnh0plc80000gn/T/ipykernel_38098/22777151.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'algo' is not defined"
     ]
    }
   ],
   "source": [
    "algo.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`algo = ?` | `algo.fit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-06 09:28:34.589015: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-06 09:28:34.589292: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dense' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/24/tg28vxls25l9mjvqrnh0plc80000gn/T/ipykernel_38098/21407332.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Dense' is not defined"
     ]
    }
   ],
   "source": [
    "Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(3))\n",
    "model.add(layer=Dense(1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.layers.core.Dense"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Dense(units=3, input_dim=6, kernel_initializer='zeros'))\n",
    "model.add(layer=Dense(units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a Prediction with the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Can we make a prediction for for `Washington DC` accidents\n",
    "> - With the already initialized Mathematical Equation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')\n",
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL = X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>7.332</td>\n",
       "      <td>5.64</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.04</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                \n",
       "AL         7.332     5.64          18.048        15.04       784.55   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-06 09:57:35.780228: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x=AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>7.332</td>\n",
       "      <td>5.64</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.04</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                       \n",
       "AL       18.8     7.332     5.64          18.048        15.04       784.55   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[ 0.13440204],\n",
       "        [ 0.3892213 ],\n",
       "        [-0.645908  ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `fit()` the `model` and compare again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 - 0s - loss: 222.7761 - mse: 222.7761\n",
      "Epoch 2/500\n",
      "2/2 - 0s - loss: 93.2213 - mse: 93.2213\n",
      "Epoch 3/500\n",
      "2/2 - 0s - loss: 52.9440 - mse: 52.9440\n",
      "Epoch 4/500\n",
      "2/2 - 0s - loss: 37.1020 - mse: 37.1020\n",
      "Epoch 5/500\n",
      "2/2 - 0s - loss: 30.7588 - mse: 30.7588\n",
      "Epoch 6/500\n",
      "2/2 - 0s - loss: 29.0020 - mse: 29.0020\n",
      "Epoch 7/500\n",
      "2/2 - 0s - loss: 28.2831 - mse: 28.2831\n",
      "Epoch 8/500\n",
      "2/2 - 0s - loss: 27.4843 - mse: 27.4843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-06 10:03:22.351338: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/500\n",
      "2/2 - 0s - loss: 27.0332 - mse: 27.0332\n",
      "Epoch 10/500\n",
      "2/2 - 0s - loss: 26.8303 - mse: 26.8303\n",
      "Epoch 11/500\n",
      "2/2 - 0s - loss: 27.0910 - mse: 27.0910\n",
      "Epoch 12/500\n",
      "2/2 - 0s - loss: 26.6957 - mse: 26.6957\n",
      "Epoch 13/500\n",
      "2/2 - 0s - loss: 26.4539 - mse: 26.4539\n",
      "Epoch 14/500\n",
      "2/2 - 0s - loss: 26.1589 - mse: 26.1589\n",
      "Epoch 15/500\n",
      "2/2 - 0s - loss: 25.8832 - mse: 25.8832\n",
      "Epoch 16/500\n",
      "2/2 - 0s - loss: 25.9123 - mse: 25.9123\n",
      "Epoch 17/500\n",
      "2/2 - 0s - loss: 25.9592 - mse: 25.9592\n",
      "Epoch 18/500\n",
      "2/2 - 0s - loss: 26.7020 - mse: 26.7020\n",
      "Epoch 19/500\n",
      "2/2 - 0s - loss: 25.8275 - mse: 25.8275\n",
      "Epoch 20/500\n",
      "2/2 - 0s - loss: 24.7741 - mse: 24.7741\n",
      "Epoch 21/500\n",
      "2/2 - 0s - loss: 24.9872 - mse: 24.9872\n",
      "Epoch 22/500\n",
      "2/2 - 0s - loss: 24.8492 - mse: 24.8492\n",
      "Epoch 23/500\n",
      "2/2 - 0s - loss: 23.9078 - mse: 23.9078\n",
      "Epoch 24/500\n",
      "2/2 - 0s - loss: 24.1131 - mse: 24.1131\n",
      "Epoch 25/500\n",
      "2/2 - 0s - loss: 26.7698 - mse: 26.7698\n",
      "Epoch 26/500\n",
      "2/2 - 0s - loss: 24.0691 - mse: 24.0691\n",
      "Epoch 27/500\n",
      "2/2 - 0s - loss: 23.2625 - mse: 23.2625\n",
      "Epoch 28/500\n",
      "2/2 - 0s - loss: 24.1825 - mse: 24.1825\n",
      "Epoch 29/500\n",
      "2/2 - 0s - loss: 23.3085 - mse: 23.3085\n",
      "Epoch 30/500\n",
      "2/2 - 0s - loss: 22.3871 - mse: 22.3871\n",
      "Epoch 31/500\n",
      "2/2 - 0s - loss: 22.1700 - mse: 22.1700\n",
      "Epoch 32/500\n",
      "2/2 - 0s - loss: 21.5644 - mse: 21.5644\n",
      "Epoch 33/500\n",
      "2/2 - 0s - loss: 21.4979 - mse: 21.4979\n",
      "Epoch 34/500\n",
      "2/2 - 0s - loss: 21.8217 - mse: 21.8217\n",
      "Epoch 35/500\n",
      "2/2 - 0s - loss: 23.4312 - mse: 23.4312\n",
      "Epoch 36/500\n",
      "2/2 - 0s - loss: 22.0476 - mse: 22.0476\n",
      "Epoch 37/500\n",
      "2/2 - 0s - loss: 20.2329 - mse: 20.2329\n",
      "Epoch 38/500\n",
      "2/2 - 0s - loss: 20.4762 - mse: 20.4762\n",
      "Epoch 39/500\n",
      "2/2 - 0s - loss: 20.4359 - mse: 20.4359\n",
      "Epoch 40/500\n",
      "2/2 - 0s - loss: 19.5948 - mse: 19.5948\n",
      "Epoch 41/500\n",
      "2/2 - 0s - loss: 19.5251 - mse: 19.5251\n",
      "Epoch 42/500\n",
      "2/2 - 0s - loss: 19.4378 - mse: 19.4378\n",
      "Epoch 43/500\n",
      "2/2 - 0s - loss: 18.6767 - mse: 18.6767\n",
      "Epoch 44/500\n",
      "2/2 - 0s - loss: 20.0820 - mse: 20.0820\n",
      "Epoch 45/500\n",
      "2/2 - 0s - loss: 19.4713 - mse: 19.4713\n",
      "Epoch 46/500\n",
      "2/2 - 0s - loss: 17.9832 - mse: 17.9832\n",
      "Epoch 47/500\n",
      "2/2 - 0s - loss: 18.1254 - mse: 18.1254\n",
      "Epoch 48/500\n",
      "2/2 - 0s - loss: 17.4699 - mse: 17.4699\n",
      "Epoch 49/500\n",
      "2/2 - 0s - loss: 17.3335 - mse: 17.3335\n",
      "Epoch 50/500\n",
      "2/2 - 0s - loss: 17.5593 - mse: 17.5593\n",
      "Epoch 51/500\n",
      "2/2 - 0s - loss: 16.8436 - mse: 16.8436\n",
      "Epoch 52/500\n",
      "2/2 - 0s - loss: 16.3571 - mse: 16.3571\n",
      "Epoch 53/500\n",
      "2/2 - 0s - loss: 21.9490 - mse: 21.9490\n",
      "Epoch 54/500\n",
      "2/2 - 0s - loss: 16.9083 - mse: 16.9083\n",
      "Epoch 55/500\n",
      "2/2 - 0s - loss: 15.9710 - mse: 15.9710\n",
      "Epoch 56/500\n",
      "2/2 - 0s - loss: 15.5613 - mse: 15.5613\n",
      "Epoch 57/500\n",
      "2/2 - 0s - loss: 15.5893 - mse: 15.5893\n",
      "Epoch 58/500\n",
      "2/2 - 0s - loss: 15.1499 - mse: 15.1499\n",
      "Epoch 59/500\n",
      "2/2 - 0s - loss: 14.8698 - mse: 14.8698\n",
      "Epoch 60/500\n",
      "2/2 - 0s - loss: 14.7910 - mse: 14.7910\n",
      "Epoch 61/500\n",
      "2/2 - 0s - loss: 16.4141 - mse: 16.4141\n",
      "Epoch 62/500\n",
      "2/2 - 0s - loss: 16.8570 - mse: 16.8570\n",
      "Epoch 63/500\n",
      "2/2 - 0s - loss: 14.0232 - mse: 14.0232\n",
      "Epoch 64/500\n",
      "2/2 - 0s - loss: 13.6862 - mse: 13.6862\n",
      "Epoch 65/500\n",
      "2/2 - 0s - loss: 13.5347 - mse: 13.5347\n",
      "Epoch 66/500\n",
      "2/2 - 0s - loss: 13.9548 - mse: 13.9548\n",
      "Epoch 67/500\n",
      "2/2 - 0s - loss: 16.1486 - mse: 16.1486\n",
      "Epoch 68/500\n",
      "2/2 - 0s - loss: 13.6981 - mse: 13.6981\n",
      "Epoch 69/500\n",
      "2/2 - 0s - loss: 12.8088 - mse: 12.8088\n",
      "Epoch 70/500\n",
      "2/2 - 0s - loss: 13.1956 - mse: 13.1956\n",
      "Epoch 71/500\n",
      "2/2 - 0s - loss: 12.2983 - mse: 12.2983\n",
      "Epoch 72/500\n",
      "2/2 - 0s - loss: 12.1200 - mse: 12.1200\n",
      "Epoch 73/500\n",
      "2/2 - 0s - loss: 12.3292 - mse: 12.3292\n",
      "Epoch 74/500\n",
      "2/2 - 0s - loss: 13.5179 - mse: 13.5179\n",
      "Epoch 75/500\n",
      "2/2 - 0s - loss: 12.7410 - mse: 12.7410\n",
      "Epoch 76/500\n",
      "2/2 - 0s - loss: 11.4167 - mse: 11.4167\n",
      "Epoch 77/500\n",
      "2/2 - 0s - loss: 11.1840 - mse: 11.1840\n",
      "Epoch 78/500\n",
      "2/2 - 0s - loss: 11.2869 - mse: 11.2869\n",
      "Epoch 79/500\n",
      "2/2 - 0s - loss: 10.7502 - mse: 10.7502\n",
      "Epoch 80/500\n",
      "2/2 - 0s - loss: 11.2006 - mse: 11.2006\n",
      "Epoch 81/500\n",
      "2/2 - 0s - loss: 11.4156 - mse: 11.4156\n",
      "Epoch 82/500\n",
      "2/2 - 0s - loss: 10.2408 - mse: 10.2408\n",
      "Epoch 83/500\n",
      "2/2 - 0s - loss: 11.7316 - mse: 11.7316\n",
      "Epoch 84/500\n",
      "2/2 - 0s - loss: 10.1670 - mse: 10.1670\n",
      "Epoch 85/500\n",
      "2/2 - 0s - loss: 10.5181 - mse: 10.5181\n",
      "Epoch 86/500\n",
      "2/2 - 0s - loss: 10.1342 - mse: 10.1342\n",
      "Epoch 87/500\n",
      "2/2 - 0s - loss: 9.4884 - mse: 9.4884\n",
      "Epoch 88/500\n",
      "2/2 - 0s - loss: 9.9367 - mse: 9.9367\n",
      "Epoch 89/500\n",
      "2/2 - 0s - loss: 9.6178 - mse: 9.6178\n",
      "Epoch 90/500\n",
      "2/2 - 0s - loss: 8.8449 - mse: 8.8449\n",
      "Epoch 91/500\n",
      "2/2 - 0s - loss: 9.8264 - mse: 9.8264\n",
      "Epoch 92/500\n",
      "2/2 - 0s - loss: 10.6083 - mse: 10.6083\n",
      "Epoch 93/500\n",
      "2/2 - 0s - loss: 8.4493 - mse: 8.4493\n",
      "Epoch 94/500\n",
      "2/2 - 0s - loss: 8.5235 - mse: 8.5235\n",
      "Epoch 95/500\n",
      "2/2 - 0s - loss: 8.1503 - mse: 8.1503\n",
      "Epoch 96/500\n",
      "2/2 - 0s - loss: 8.1870 - mse: 8.1870\n",
      "Epoch 97/500\n",
      "2/2 - 0s - loss: 8.7121 - mse: 8.7121\n",
      "Epoch 98/500\n",
      "2/2 - 0s - loss: 10.0632 - mse: 10.0632\n",
      "Epoch 99/500\n",
      "2/2 - 0s - loss: 7.6775 - mse: 7.6775\n",
      "Epoch 100/500\n",
      "2/2 - 0s - loss: 8.4798 - mse: 8.4798\n",
      "Epoch 101/500\n",
      "2/2 - 0s - loss: 10.3607 - mse: 10.3607\n",
      "Epoch 102/500\n",
      "2/2 - 0s - loss: 8.2308 - mse: 8.2308\n",
      "Epoch 103/500\n",
      "2/2 - 0s - loss: 8.2611 - mse: 8.2611\n",
      "Epoch 104/500\n",
      "2/2 - 0s - loss: 7.3173 - mse: 7.3173\n",
      "Epoch 105/500\n",
      "2/2 - 0s - loss: 7.1542 - mse: 7.1542\n",
      "Epoch 106/500\n",
      "2/2 - 0s - loss: 7.1544 - mse: 7.1544\n",
      "Epoch 107/500\n",
      "2/2 - 0s - loss: 6.8825 - mse: 6.8825\n",
      "Epoch 108/500\n",
      "2/2 - 0s - loss: 6.8225 - mse: 6.8225\n",
      "Epoch 109/500\n",
      "2/2 - 0s - loss: 6.3844 - mse: 6.3844\n",
      "Epoch 110/500\n",
      "2/2 - 0s - loss: 7.2883 - mse: 7.2883\n",
      "Epoch 111/500\n",
      "2/2 - 0s - loss: 7.9689 - mse: 7.9689\n",
      "Epoch 112/500\n",
      "2/2 - 0s - loss: 7.8302 - mse: 7.8302\n",
      "Epoch 113/500\n",
      "2/2 - 0s - loss: 6.6849 - mse: 6.6849\n",
      "Epoch 114/500\n",
      "2/2 - 0s - loss: 5.9061 - mse: 5.9061\n",
      "Epoch 115/500\n",
      "2/2 - 0s - loss: 6.8101 - mse: 6.8101\n",
      "Epoch 116/500\n",
      "2/2 - 0s - loss: 5.7848 - mse: 5.7848\n",
      "Epoch 117/500\n",
      "2/2 - 0s - loss: 6.2863 - mse: 6.2863\n",
      "Epoch 118/500\n",
      "2/2 - 0s - loss: 5.5534 - mse: 5.5534\n",
      "Epoch 119/500\n",
      "2/2 - 0s - loss: 6.5837 - mse: 6.5837\n",
      "Epoch 120/500\n",
      "2/2 - 0s - loss: 6.3975 - mse: 6.3975\n",
      "Epoch 121/500\n",
      "2/2 - 0s - loss: 5.2893 - mse: 5.2893\n",
      "Epoch 122/500\n",
      "2/2 - 0s - loss: 5.1630 - mse: 5.1630\n",
      "Epoch 123/500\n",
      "2/2 - 0s - loss: 5.2474 - mse: 5.2474\n",
      "Epoch 124/500\n",
      "2/2 - 0s - loss: 7.0166 - mse: 7.0166\n",
      "Epoch 125/500\n",
      "2/2 - 0s - loss: 6.1788 - mse: 6.1788\n",
      "Epoch 126/500\n",
      "2/2 - 0s - loss: 4.8640 - mse: 4.8640\n",
      "Epoch 127/500\n",
      "2/2 - 0s - loss: 4.7698 - mse: 4.7698\n",
      "Epoch 128/500\n",
      "2/2 - 0s - loss: 7.4195 - mse: 7.4195\n",
      "Epoch 129/500\n",
      "2/2 - 0s - loss: 5.2195 - mse: 5.2195\n",
      "Epoch 130/500\n",
      "2/2 - 0s - loss: 4.3620 - mse: 4.3620\n",
      "Epoch 131/500\n",
      "2/2 - 0s - loss: 4.7837 - mse: 4.7837\n",
      "Epoch 132/500\n",
      "2/2 - 0s - loss: 4.5211 - mse: 4.5211\n",
      "Epoch 133/500\n",
      "2/2 - 0s - loss: 4.3410 - mse: 4.3410\n",
      "Epoch 134/500\n",
      "2/2 - 0s - loss: 4.0525 - mse: 4.0525\n",
      "Epoch 135/500\n",
      "2/2 - 0s - loss: 4.9074 - mse: 4.9074\n",
      "Epoch 136/500\n",
      "2/2 - 0s - loss: 5.3598 - mse: 5.3598\n",
      "Epoch 137/500\n",
      "2/2 - 0s - loss: 4.6035 - mse: 4.6035\n",
      "Epoch 138/500\n",
      "2/2 - 0s - loss: 3.9493 - mse: 3.9493\n",
      "Epoch 139/500\n",
      "2/2 - 0s - loss: 4.2269 - mse: 4.2269\n",
      "Epoch 140/500\n",
      "2/2 - 0s - loss: 4.0904 - mse: 4.0904\n",
      "Epoch 141/500\n",
      "2/2 - 0s - loss: 5.1536 - mse: 5.1536\n",
      "Epoch 142/500\n",
      "2/2 - 0s - loss: 3.9985 - mse: 3.9985\n",
      "Epoch 143/500\n",
      "2/2 - 0s - loss: 3.5272 - mse: 3.5272\n",
      "Epoch 144/500\n",
      "2/2 - 0s - loss: 4.8510 - mse: 4.8510\n",
      "Epoch 145/500\n",
      "2/2 - 0s - loss: 4.6384 - mse: 4.6384\n",
      "Epoch 146/500\n",
      "2/2 - 0s - loss: 3.5837 - mse: 3.5837\n",
      "Epoch 147/500\n",
      "2/2 - 0s - loss: 4.4249 - mse: 4.4249\n",
      "Epoch 148/500\n",
      "2/2 - 0s - loss: 4.3744 - mse: 4.3744\n",
      "Epoch 149/500\n",
      "2/2 - 0s - loss: 3.4624 - mse: 3.4624\n",
      "Epoch 150/500\n",
      "2/2 - 0s - loss: 4.2671 - mse: 4.2671\n",
      "Epoch 151/500\n",
      "2/2 - 0s - loss: 3.4415 - mse: 3.4415\n",
      "Epoch 152/500\n",
      "2/2 - 0s - loss: 3.5610 - mse: 3.5610\n",
      "Epoch 153/500\n",
      "2/2 - 0s - loss: 4.1556 - mse: 4.1556\n",
      "Epoch 154/500\n",
      "2/2 - 0s - loss: 3.9856 - mse: 3.9856\n",
      "Epoch 155/500\n",
      "2/2 - 0s - loss: 3.5120 - mse: 3.5120\n",
      "Epoch 156/500\n",
      "2/2 - 0s - loss: 3.0025 - mse: 3.0025\n",
      "Epoch 157/500\n",
      "2/2 - 0s - loss: 3.0402 - mse: 3.0402\n",
      "Epoch 158/500\n",
      "2/2 - 0s - loss: 3.9188 - mse: 3.9188\n",
      "Epoch 159/500\n",
      "2/2 - 0s - loss: 5.3381 - mse: 5.3381\n",
      "Epoch 160/500\n",
      "2/2 - 0s - loss: 2.8905 - mse: 2.8905\n",
      "Epoch 161/500\n",
      "2/2 - 0s - loss: 2.7804 - mse: 2.7804\n",
      "Epoch 162/500\n",
      "2/2 - 0s - loss: 2.9893 - mse: 2.9893\n",
      "Epoch 163/500\n",
      "2/2 - 0s - loss: 4.4490 - mse: 4.4490\n",
      "Epoch 164/500\n",
      "2/2 - 0s - loss: 5.4831 - mse: 5.4831\n",
      "Epoch 165/500\n",
      "2/2 - 0s - loss: 3.8016 - mse: 3.8016\n",
      "Epoch 166/500\n",
      "2/2 - 0s - loss: 3.2006 - mse: 3.2006\n",
      "Epoch 167/500\n",
      "2/2 - 0s - loss: 3.2243 - mse: 3.2243\n",
      "Epoch 168/500\n",
      "2/2 - 0s - loss: 3.1576 - mse: 3.1576\n",
      "Epoch 169/500\n",
      "2/2 - 0s - loss: 2.9969 - mse: 2.9969\n",
      "Epoch 170/500\n",
      "2/2 - 0s - loss: 2.9315 - mse: 2.9315\n",
      "Epoch 171/500\n",
      "2/2 - 0s - loss: 3.0199 - mse: 3.0199\n",
      "Epoch 172/500\n",
      "2/2 - 0s - loss: 3.2206 - mse: 3.2206\n",
      "Epoch 173/500\n",
      "2/2 - 0s - loss: 2.9526 - mse: 2.9526\n",
      "Epoch 174/500\n",
      "2/2 - 0s - loss: 2.9846 - mse: 2.9846\n",
      "Epoch 175/500\n",
      "2/2 - 0s - loss: 2.4217 - mse: 2.4217\n",
      "Epoch 176/500\n",
      "2/2 - 0s - loss: 3.4983 - mse: 3.4983\n",
      "Epoch 177/500\n",
      "2/2 - 0s - loss: 5.1898 - mse: 5.1898\n",
      "Epoch 178/500\n",
      "2/2 - 0s - loss: 2.5464 - mse: 2.5464\n",
      "Epoch 179/500\n",
      "2/2 - 0s - loss: 2.6629 - mse: 2.6629\n",
      "Epoch 180/500\n",
      "2/2 - 0s - loss: 2.6482 - mse: 2.6482\n",
      "Epoch 181/500\n",
      "2/2 - 0s - loss: 2.7491 - mse: 2.7491\n",
      "Epoch 182/500\n",
      "2/2 - 0s - loss: 2.6063 - mse: 2.6063\n",
      "Epoch 183/500\n",
      "2/2 - 0s - loss: 2.2318 - mse: 2.2318\n",
      "Epoch 184/500\n",
      "2/2 - 0s - loss: 4.3015 - mse: 4.3015\n",
      "Epoch 185/500\n",
      "2/2 - 0s - loss: 3.3086 - mse: 3.3086\n",
      "Epoch 186/500\n",
      "2/2 - 0s - loss: 2.3460 - mse: 2.3460\n",
      "Epoch 187/500\n",
      "2/2 - 0s - loss: 2.1883 - mse: 2.1883\n",
      "Epoch 188/500\n",
      "2/2 - 0s - loss: 2.4235 - mse: 2.4235\n",
      "Epoch 189/500\n",
      "2/2 - 0s - loss: 3.7142 - mse: 3.7142\n",
      "Epoch 190/500\n",
      "2/2 - 0s - loss: 4.1086 - mse: 4.1086\n",
      "Epoch 191/500\n",
      "2/2 - 0s - loss: 2.7766 - mse: 2.7766\n",
      "Epoch 192/500\n",
      "2/2 - 0s - loss: 2.3721 - mse: 2.3721\n",
      "Epoch 193/500\n",
      "2/2 - 0s - loss: 2.1407 - mse: 2.1407\n",
      "Epoch 194/500\n",
      "2/2 - 0s - loss: 2.1441 - mse: 2.1441\n",
      "Epoch 195/500\n",
      "2/2 - 0s - loss: 2.3422 - mse: 2.3422\n",
      "Epoch 196/500\n",
      "2/2 - 0s - loss: 3.0912 - mse: 3.0912\n",
      "Epoch 197/500\n",
      "2/2 - 0s - loss: 2.1562 - mse: 2.1562\n",
      "Epoch 198/500\n",
      "2/2 - 0s - loss: 2.1236 - mse: 2.1236\n",
      "Epoch 199/500\n",
      "2/2 - 0s - loss: 2.6009 - mse: 2.6009\n",
      "Epoch 200/500\n",
      "2/2 - 0s - loss: 2.2004 - mse: 2.2004\n",
      "Epoch 201/500\n",
      "2/2 - 0s - loss: 2.9449 - mse: 2.9449\n",
      "Epoch 202/500\n",
      "2/2 - 0s - loss: 4.7769 - mse: 4.7769\n",
      "Epoch 203/500\n",
      "2/2 - 0s - loss: 2.9870 - mse: 2.9870\n",
      "Epoch 204/500\n",
      "2/2 - 0s - loss: 2.0323 - mse: 2.0323\n",
      "Epoch 205/500\n",
      "2/2 - 0s - loss: 2.6183 - mse: 2.6183\n",
      "Epoch 206/500\n",
      "2/2 - 0s - loss: 2.0055 - mse: 2.0055\n",
      "Epoch 207/500\n",
      "2/2 - 0s - loss: 2.6907 - mse: 2.6907\n",
      "Epoch 208/500\n",
      "2/2 - 0s - loss: 3.6743 - mse: 3.6743\n",
      "Epoch 209/500\n",
      "2/2 - 0s - loss: 2.7335 - mse: 2.7335\n",
      "Epoch 210/500\n",
      "2/2 - 0s - loss: 1.9270 - mse: 1.9270\n",
      "Epoch 211/500\n",
      "2/2 - 0s - loss: 2.2608 - mse: 2.2608\n",
      "Epoch 212/500\n",
      "2/2 - 0s - loss: 3.1712 - mse: 3.1712\n",
      "Epoch 213/500\n",
      "2/2 - 0s - loss: 2.5155 - mse: 2.5155\n",
      "Epoch 214/500\n",
      "2/2 - 0s - loss: 2.0025 - mse: 2.0025\n",
      "Epoch 215/500\n",
      "2/2 - 0s - loss: 2.1511 - mse: 2.1511\n",
      "Epoch 216/500\n",
      "2/2 - 0s - loss: 2.0488 - mse: 2.0488\n",
      "Epoch 217/500\n",
      "2/2 - 0s - loss: 2.0394 - mse: 2.0394\n",
      "Epoch 218/500\n",
      "2/2 - 0s - loss: 1.8677 - mse: 1.8677\n",
      "Epoch 219/500\n",
      "2/2 - 0s - loss: 2.6548 - mse: 2.6548\n",
      "Epoch 220/500\n",
      "2/2 - 0s - loss: 4.3068 - mse: 4.3068\n",
      "Epoch 221/500\n",
      "2/2 - 0s - loss: 2.0615 - mse: 2.0615\n",
      "Epoch 222/500\n",
      "2/2 - 0s - loss: 1.8118 - mse: 1.8118\n",
      "Epoch 223/500\n",
      "2/2 - 0s - loss: 1.8570 - mse: 1.8570\n",
      "Epoch 224/500\n",
      "2/2 - 0s - loss: 2.7652 - mse: 2.7652\n",
      "Epoch 225/500\n",
      "2/2 - 0s - loss: 3.7180 - mse: 3.7180\n",
      "Epoch 226/500\n",
      "2/2 - 0s - loss: 2.8748 - mse: 2.8748\n",
      "Epoch 227/500\n",
      "2/2 - 0s - loss: 3.4320 - mse: 3.4320\n",
      "Epoch 228/500\n",
      "2/2 - 0s - loss: 2.5803 - mse: 2.5803\n",
      "Epoch 229/500\n",
      "2/2 - 0s - loss: 2.2122 - mse: 2.2122\n",
      "Epoch 230/500\n",
      "2/2 - 0s - loss: 2.3369 - mse: 2.3369\n",
      "Epoch 231/500\n",
      "2/2 - 0s - loss: 2.0191 - mse: 2.0191\n",
      "Epoch 232/500\n",
      "2/2 - 0s - loss: 2.4514 - mse: 2.4514\n",
      "Epoch 233/500\n",
      "2/2 - 0s - loss: 1.7500 - mse: 1.7500\n",
      "Epoch 234/500\n",
      "2/2 - 0s - loss: 3.6127 - mse: 3.6127\n",
      "Epoch 235/500\n",
      "2/2 - 0s - loss: 2.0262 - mse: 2.0262\n",
      "Epoch 236/500\n",
      "2/2 - 0s - loss: 2.6529 - mse: 2.6529\n",
      "Epoch 237/500\n",
      "2/2 - 0s - loss: 1.7394 - mse: 1.7394\n",
      "Epoch 238/500\n",
      "2/2 - 0s - loss: 2.2728 - mse: 2.2728\n",
      "Epoch 239/500\n",
      "2/2 - 0s - loss: 4.4450 - mse: 4.4450\n",
      "Epoch 240/500\n",
      "2/2 - 0s - loss: 3.9973 - mse: 3.9973\n",
      "Epoch 241/500\n",
      "2/2 - 0s - loss: 2.6413 - mse: 2.6413\n",
      "Epoch 242/500\n",
      "2/2 - 0s - loss: 1.8577 - mse: 1.8577\n",
      "Epoch 243/500\n",
      "2/2 - 0s - loss: 1.8041 - mse: 1.8041\n",
      "Epoch 244/500\n",
      "2/2 - 0s - loss: 1.7070 - mse: 1.7070\n",
      "Epoch 245/500\n",
      "2/2 - 0s - loss: 1.7410 - mse: 1.7410\n",
      "Epoch 246/500\n",
      "2/2 - 0s - loss: 1.6994 - mse: 1.6994\n",
      "Epoch 247/500\n",
      "2/2 - 0s - loss: 1.6921 - mse: 1.6921\n",
      "Epoch 248/500\n",
      "2/2 - 0s - loss: 1.6821 - mse: 1.6821\n",
      "Epoch 249/500\n",
      "2/2 - 0s - loss: 1.6667 - mse: 1.6667\n",
      "Epoch 250/500\n",
      "2/2 - 0s - loss: 2.1930 - mse: 2.1930\n",
      "Epoch 251/500\n",
      "2/2 - 0s - loss: 5.1500 - mse: 5.1500\n",
      "Epoch 252/500\n",
      "2/2 - 0s - loss: 2.4873 - mse: 2.4873\n",
      "Epoch 253/500\n",
      "2/2 - 0s - loss: 1.8165 - mse: 1.8165\n",
      "Epoch 254/500\n",
      "2/2 - 0s - loss: 1.6596 - mse: 1.6596\n",
      "Epoch 255/500\n",
      "2/2 - 0s - loss: 1.8228 - mse: 1.8228\n",
      "Epoch 256/500\n",
      "2/2 - 0s - loss: 3.3056 - mse: 3.3056\n",
      "Epoch 257/500\n",
      "2/2 - 0s - loss: 4.1887 - mse: 4.1887\n",
      "Epoch 258/500\n",
      "2/2 - 0s - loss: 2.1785 - mse: 2.1785\n",
      "Epoch 259/500\n",
      "2/2 - 0s - loss: 1.8497 - mse: 1.8497\n",
      "Epoch 260/500\n",
      "2/2 - 0s - loss: 2.4097 - mse: 2.4097\n",
      "Epoch 261/500\n",
      "2/2 - 0s - loss: 2.7806 - mse: 2.7806\n",
      "Epoch 262/500\n",
      "2/2 - 0s - loss: 2.8932 - mse: 2.8932\n",
      "Epoch 263/500\n",
      "2/2 - 0s - loss: 3.8969 - mse: 3.8969\n",
      "Epoch 264/500\n",
      "2/2 - 0s - loss: 2.9920 - mse: 2.9920\n",
      "Epoch 265/500\n",
      "2/2 - 0s - loss: 2.2136 - mse: 2.2136\n",
      "Epoch 266/500\n",
      "2/2 - 0s - loss: 1.7738 - mse: 1.7738\n",
      "Epoch 267/500\n",
      "2/2 - 0s - loss: 1.6151 - mse: 1.6151\n",
      "Epoch 268/500\n",
      "2/2 - 0s - loss: 1.8086 - mse: 1.8086\n",
      "Epoch 269/500\n",
      "2/2 - 0s - loss: 2.2085 - mse: 2.2085\n",
      "Epoch 270/500\n",
      "2/2 - 0s - loss: 2.0632 - mse: 2.0632\n",
      "Epoch 271/500\n",
      "2/2 - 0s - loss: 2.1892 - mse: 2.1892\n",
      "Epoch 272/500\n",
      "2/2 - 0s - loss: 2.8847 - mse: 2.8847\n",
      "Epoch 273/500\n",
      "2/2 - 0s - loss: 1.9216 - mse: 1.9216\n",
      "Epoch 274/500\n",
      "2/2 - 0s - loss: 1.5937 - mse: 1.5937\n",
      "Epoch 275/500\n",
      "2/2 - 0s - loss: 1.7110 - mse: 1.7110\n",
      "Epoch 276/500\n",
      "2/2 - 0s - loss: 3.4070 - mse: 3.4070\n",
      "Epoch 277/500\n",
      "2/2 - 0s - loss: 3.6141 - mse: 3.6141\n",
      "Epoch 278/500\n",
      "2/2 - 0s - loss: 2.0063 - mse: 2.0063\n",
      "Epoch 279/500\n",
      "2/2 - 0s - loss: 1.5809 - mse: 1.5809\n",
      "Epoch 280/500\n",
      "2/2 - 0s - loss: 1.6435 - mse: 1.6435\n",
      "Epoch 281/500\n",
      "2/2 - 0s - loss: 3.1039 - mse: 3.1039\n",
      "Epoch 282/500\n",
      "2/2 - 0s - loss: 4.4364 - mse: 4.4364\n",
      "Epoch 283/500\n",
      "2/2 - 0s - loss: 2.3570 - mse: 2.3570\n",
      "Epoch 284/500\n",
      "2/2 - 0s - loss: 2.8096 - mse: 2.8096\n",
      "Epoch 285/500\n",
      "2/2 - 0s - loss: 2.0810 - mse: 2.0810\n",
      "Epoch 286/500\n",
      "2/2 - 0s - loss: 1.6782 - mse: 1.6782\n",
      "Epoch 287/500\n",
      "2/2 - 0s - loss: 2.0020 - mse: 2.0020\n",
      "Epoch 288/500\n",
      "2/2 - 0s - loss: 1.5654 - mse: 1.5654\n",
      "Epoch 289/500\n",
      "2/2 - 0s - loss: 1.6019 - mse: 1.6019\n",
      "Epoch 290/500\n",
      "2/2 - 0s - loss: 1.6294 - mse: 1.6294\n",
      "Epoch 291/500\n",
      "2/2 - 0s - loss: 2.0577 - mse: 2.0577\n",
      "Epoch 292/500\n",
      "2/2 - 0s - loss: 5.4470 - mse: 5.4470\n",
      "Epoch 293/500\n",
      "2/2 - 0s - loss: 3.4890 - mse: 3.4890\n",
      "Epoch 294/500\n",
      "2/2 - 0s - loss: 1.6518 - mse: 1.6518\n",
      "Epoch 295/500\n",
      "2/2 - 0s - loss: 1.5609 - mse: 1.5609\n",
      "Epoch 296/500\n",
      "2/2 - 0s - loss: 1.5908 - mse: 1.5908\n",
      "Epoch 297/500\n",
      "2/2 - 0s - loss: 1.8575 - mse: 1.8575\n",
      "Epoch 298/500\n",
      "2/2 - 0s - loss: 2.3165 - mse: 2.3165\n",
      "Epoch 299/500\n",
      "2/2 - 0s - loss: 1.7670 - mse: 1.7670\n",
      "Epoch 300/500\n",
      "2/2 - 0s - loss: 2.4207 - mse: 2.4207\n",
      "Epoch 301/500\n",
      "2/2 - 0s - loss: 3.0851 - mse: 3.0851\n",
      "Epoch 302/500\n",
      "2/2 - 0s - loss: 2.4587 - mse: 2.4587\n",
      "Epoch 303/500\n",
      "2/2 - 0s - loss: 1.9430 - mse: 1.9430\n",
      "Epoch 304/500\n",
      "2/2 - 0s - loss: 1.6078 - mse: 1.6078\n",
      "Epoch 305/500\n",
      "2/2 - 0s - loss: 1.5712 - mse: 1.5712\n",
      "Epoch 306/500\n",
      "2/2 - 0s - loss: 2.5497 - mse: 2.5497\n",
      "Epoch 307/500\n",
      "2/2 - 0s - loss: 3.0376 - mse: 3.0376\n",
      "Epoch 308/500\n",
      "2/2 - 0s - loss: 1.8197 - mse: 1.8197\n",
      "Epoch 309/500\n",
      "2/2 - 0s - loss: 1.5969 - mse: 1.5969\n",
      "Epoch 310/500\n",
      "2/2 - 0s - loss: 2.2071 - mse: 2.2071\n",
      "Epoch 311/500\n",
      "2/2 - 0s - loss: 4.3188 - mse: 4.3188\n",
      "Epoch 312/500\n",
      "2/2 - 0s - loss: 2.2122 - mse: 2.2122\n",
      "Epoch 313/500\n",
      "2/2 - 0s - loss: 1.6643 - mse: 1.6643\n",
      "Epoch 314/500\n",
      "2/2 - 0s - loss: 1.7521 - mse: 1.7521\n",
      "Epoch 315/500\n",
      "2/2 - 0s - loss: 1.8391 - mse: 1.8391\n",
      "Epoch 316/500\n",
      "2/2 - 0s - loss: 2.0199 - mse: 2.0199\n",
      "Epoch 317/500\n",
      "2/2 - 0s - loss: 3.3005 - mse: 3.3005\n",
      "Epoch 318/500\n",
      "2/2 - 0s - loss: 3.3488 - mse: 3.3488\n",
      "Epoch 319/500\n",
      "2/2 - 0s - loss: 1.5236 - mse: 1.5236\n",
      "Epoch 320/500\n",
      "2/2 - 0s - loss: 1.6127 - mse: 1.6127\n",
      "Epoch 321/500\n",
      "2/2 - 0s - loss: 1.7493 - mse: 1.7493\n",
      "Epoch 322/500\n",
      "2/2 - 0s - loss: 2.1829 - mse: 2.1829\n",
      "Epoch 323/500\n",
      "2/2 - 0s - loss: 2.5690 - mse: 2.5690\n",
      "Epoch 324/500\n",
      "2/2 - 0s - loss: 1.5361 - mse: 1.5361\n",
      "Epoch 325/500\n",
      "2/2 - 0s - loss: 2.2782 - mse: 2.2782\n",
      "Epoch 326/500\n",
      "2/2 - 0s - loss: 3.4192 - mse: 3.4192\n",
      "Epoch 327/500\n",
      "2/2 - 0s - loss: 1.9038 - mse: 1.9038\n",
      "Epoch 328/500\n",
      "2/2 - 0s - loss: 1.4809 - mse: 1.4809\n",
      "Epoch 329/500\n",
      "2/2 - 0s - loss: 1.5364 - mse: 1.5364\n",
      "Epoch 330/500\n",
      "2/2 - 0s - loss: 1.4529 - mse: 1.4529\n",
      "Epoch 331/500\n",
      "2/2 - 0s - loss: 1.4866 - mse: 1.4866\n",
      "Epoch 332/500\n",
      "2/2 - 0s - loss: 1.5451 - mse: 1.5451\n",
      "Epoch 333/500\n",
      "2/2 - 0s - loss: 2.3290 - mse: 2.3290\n",
      "Epoch 334/500\n",
      "2/2 - 0s - loss: 3.2640 - mse: 3.2640\n",
      "Epoch 335/500\n",
      "2/2 - 0s - loss: 2.4220 - mse: 2.4220\n",
      "Epoch 336/500\n",
      "2/2 - 0s - loss: 2.0618 - mse: 2.0618\n",
      "Epoch 337/500\n",
      "2/2 - 0s - loss: 1.6201 - mse: 1.6201\n",
      "Epoch 338/500\n",
      "2/2 - 0s - loss: 1.6412 - mse: 1.6412\n",
      "Epoch 339/500\n",
      "2/2 - 0s - loss: 3.2734 - mse: 3.2734\n",
      "Epoch 340/500\n",
      "2/2 - 0s - loss: 1.4456 - mse: 1.4456\n",
      "Epoch 341/500\n",
      "2/2 - 0s - loss: 2.1681 - mse: 2.1681\n",
      "Epoch 342/500\n",
      "2/2 - 0s - loss: 2.8174 - mse: 2.8174\n",
      "Epoch 343/500\n",
      "2/2 - 0s - loss: 2.8658 - mse: 2.8658\n",
      "Epoch 344/500\n",
      "2/2 - 0s - loss: 1.9640 - mse: 1.9640\n",
      "Epoch 345/500\n",
      "2/2 - 0s - loss: 1.4361 - mse: 1.4361\n",
      "Epoch 346/500\n",
      "2/2 - 0s - loss: 1.5323 - mse: 1.5323\n",
      "Epoch 347/500\n",
      "2/2 - 0s - loss: 2.8489 - mse: 2.8489\n",
      "Epoch 348/500\n",
      "2/2 - 0s - loss: 2.0523 - mse: 2.0523\n",
      "Epoch 349/500\n",
      "2/2 - 0s - loss: 1.4835 - mse: 1.4835\n",
      "Epoch 350/500\n",
      "2/2 - 0s - loss: 1.4174 - mse: 1.4174\n",
      "Epoch 351/500\n",
      "2/2 - 0s - loss: 1.4423 - mse: 1.4423\n",
      "Epoch 352/500\n",
      "2/2 - 0s - loss: 1.6083 - mse: 1.6083\n",
      "Epoch 353/500\n",
      "2/2 - 0s - loss: 3.1981 - mse: 3.1981\n",
      "Epoch 354/500\n",
      "2/2 - 0s - loss: 3.7283 - mse: 3.7283\n",
      "Epoch 355/500\n",
      "2/2 - 0s - loss: 2.2684 - mse: 2.2684\n",
      "Epoch 356/500\n",
      "2/2 - 0s - loss: 1.4677 - mse: 1.4677\n",
      "Epoch 357/500\n",
      "2/2 - 0s - loss: 1.6614 - mse: 1.6614\n",
      "Epoch 358/500\n",
      "2/2 - 0s - loss: 2.7599 - mse: 2.7599\n",
      "Epoch 359/500\n",
      "2/2 - 0s - loss: 2.1673 - mse: 2.1673\n",
      "Epoch 360/500\n",
      "2/2 - 0s - loss: 2.7076 - mse: 2.7076\n",
      "Epoch 361/500\n",
      "2/2 - 0s - loss: 2.8578 - mse: 2.8578\n",
      "Epoch 362/500\n",
      "2/2 - 0s - loss: 1.8902 - mse: 1.8902\n",
      "Epoch 363/500\n",
      "2/2 - 0s - loss: 1.5781 - mse: 1.5781\n",
      "Epoch 364/500\n",
      "2/2 - 0s - loss: 2.5803 - mse: 2.5803\n",
      "Epoch 365/500\n",
      "2/2 - 0s - loss: 3.4570 - mse: 3.4570\n",
      "Epoch 366/500\n",
      "2/2 - 0s - loss: 2.5299 - mse: 2.5299\n",
      "Epoch 367/500\n",
      "2/2 - 0s - loss: 1.8205 - mse: 1.8205\n",
      "Epoch 368/500\n",
      "2/2 - 0s - loss: 1.7814 - mse: 1.7814\n",
      "Epoch 369/500\n",
      "2/2 - 0s - loss: 1.8390 - mse: 1.8390\n",
      "Epoch 370/500\n",
      "2/2 - 0s - loss: 2.2629 - mse: 2.2629\n",
      "Epoch 371/500\n",
      "2/2 - 0s - loss: 1.9600 - mse: 1.9600\n",
      "Epoch 372/500\n",
      "2/2 - 0s - loss: 1.7057 - mse: 1.7057\n",
      "Epoch 373/500\n",
      "2/2 - 0s - loss: 1.5173 - mse: 1.5173\n",
      "Epoch 374/500\n",
      "2/2 - 0s - loss: 1.4759 - mse: 1.4759\n",
      "Epoch 375/500\n",
      "2/2 - 0s - loss: 2.1937 - mse: 2.1937\n",
      "Epoch 376/500\n",
      "2/2 - 0s - loss: 2.6870 - mse: 2.6870\n",
      "Epoch 377/500\n",
      "2/2 - 0s - loss: 1.3733 - mse: 1.3733\n",
      "Epoch 378/500\n",
      "2/2 - 0s - loss: 1.4034 - mse: 1.4034\n",
      "Epoch 379/500\n",
      "2/2 - 0s - loss: 1.4139 - mse: 1.4139\n",
      "Epoch 380/500\n",
      "2/2 - 0s - loss: 1.9314 - mse: 1.9314\n",
      "Epoch 381/500\n",
      "2/2 - 0s - loss: 4.3636 - mse: 4.3636\n",
      "Epoch 382/500\n",
      "2/2 - 0s - loss: 2.3722 - mse: 2.3722\n",
      "Epoch 383/500\n",
      "2/2 - 0s - loss: 2.3767 - mse: 2.3767\n",
      "Epoch 384/500\n",
      "2/2 - 0s - loss: 1.6074 - mse: 1.6074\n",
      "Epoch 385/500\n",
      "2/2 - 0s - loss: 2.1645 - mse: 2.1645\n",
      "Epoch 386/500\n",
      "2/2 - 0s - loss: 2.2708 - mse: 2.2708\n",
      "Epoch 387/500\n",
      "2/2 - 0s - loss: 1.4762 - mse: 1.4762\n",
      "Epoch 388/500\n",
      "2/2 - 0s - loss: 1.4758 - mse: 1.4758\n",
      "Epoch 389/500\n",
      "2/2 - 0s - loss: 1.6405 - mse: 1.6405\n",
      "Epoch 390/500\n",
      "2/2 - 0s - loss: 2.2880 - mse: 2.2880\n",
      "Epoch 391/500\n",
      "2/2 - 0s - loss: 4.0030 - mse: 4.0030\n",
      "Epoch 392/500\n",
      "2/2 - 0s - loss: 1.8179 - mse: 1.8179\n",
      "Epoch 393/500\n",
      "2/2 - 0s - loss: 1.4745 - mse: 1.4745\n",
      "Epoch 394/500\n",
      "2/2 - 0s - loss: 1.8719 - mse: 1.8719\n",
      "Epoch 395/500\n",
      "2/2 - 0s - loss: 1.3810 - mse: 1.3810\n",
      "Epoch 396/500\n",
      "2/2 - 0s - loss: 1.5866 - mse: 1.5866\n",
      "Epoch 397/500\n",
      "2/2 - 0s - loss: 1.7748 - mse: 1.7748\n",
      "Epoch 398/500\n",
      "2/2 - 0s - loss: 1.4438 - mse: 1.4438\n",
      "Epoch 399/500\n",
      "2/2 - 0s - loss: 1.3838 - mse: 1.3838\n",
      "Epoch 400/500\n",
      "2/2 - 0s - loss: 2.2507 - mse: 2.2507\n",
      "Epoch 401/500\n",
      "2/2 - 0s - loss: 4.2567 - mse: 4.2567\n",
      "Epoch 402/500\n",
      "2/2 - 0s - loss: 1.6831 - mse: 1.6831\n",
      "Epoch 403/500\n",
      "2/2 - 0s - loss: 1.4047 - mse: 1.4047\n",
      "Epoch 404/500\n",
      "2/2 - 0s - loss: 2.5349 - mse: 2.5349\n",
      "Epoch 405/500\n",
      "2/2 - 0s - loss: 1.9768 - mse: 1.9768\n",
      "Epoch 406/500\n",
      "2/2 - 0s - loss: 1.6548 - mse: 1.6548\n",
      "Epoch 407/500\n",
      "2/2 - 0s - loss: 1.5139 - mse: 1.5139\n",
      "Epoch 408/500\n",
      "2/2 - 0s - loss: 1.4872 - mse: 1.4872\n",
      "Epoch 409/500\n",
      "2/2 - 0s - loss: 1.7120 - mse: 1.7120\n",
      "Epoch 410/500\n",
      "2/2 - 0s - loss: 3.8770 - mse: 3.8770\n",
      "Epoch 411/500\n",
      "2/2 - 0s - loss: 3.5471 - mse: 3.5471\n",
      "Epoch 412/500\n",
      "2/2 - 0s - loss: 1.4119 - mse: 1.4119\n",
      "Epoch 413/500\n",
      "2/2 - 0s - loss: 1.8320 - mse: 1.8320\n",
      "Epoch 414/500\n",
      "2/2 - 0s - loss: 1.7716 - mse: 1.7716\n",
      "Epoch 415/500\n",
      "2/2 - 0s - loss: 1.3225 - mse: 1.3225\n",
      "Epoch 416/500\n",
      "2/2 - 0s - loss: 1.4918 - mse: 1.4918\n",
      "Epoch 417/500\n",
      "2/2 - 0s - loss: 1.9759 - mse: 1.9759\n",
      "Epoch 418/500\n",
      "2/2 - 0s - loss: 1.8100 - mse: 1.8100\n",
      "Epoch 419/500\n",
      "2/2 - 0s - loss: 1.3533 - mse: 1.3533\n",
      "Epoch 420/500\n",
      "2/2 - 0s - loss: 1.5322 - mse: 1.5322\n",
      "Epoch 421/500\n",
      "2/2 - 0s - loss: 2.9323 - mse: 2.9323\n",
      "Epoch 422/500\n",
      "2/2 - 0s - loss: 3.2689 - mse: 3.2689\n",
      "Epoch 423/500\n",
      "2/2 - 0s - loss: 3.1904 - mse: 3.1904\n",
      "Epoch 424/500\n",
      "2/2 - 0s - loss: 1.8714 - mse: 1.8714\n",
      "Epoch 425/500\n",
      "2/2 - 0s - loss: 1.8669 - mse: 1.8669\n",
      "Epoch 426/500\n",
      "2/2 - 0s - loss: 1.8668 - mse: 1.8668\n",
      "Epoch 427/500\n",
      "2/2 - 0s - loss: 2.0565 - mse: 2.0565\n",
      "Epoch 428/500\n",
      "2/2 - 0s - loss: 2.4444 - mse: 2.4444\n",
      "Epoch 429/500\n",
      "2/2 - 0s - loss: 3.8698 - mse: 3.8698\n",
      "Epoch 430/500\n",
      "2/2 - 0s - loss: 1.9083 - mse: 1.9083\n",
      "Epoch 431/500\n",
      "2/2 - 0s - loss: 1.3809 - mse: 1.3809\n",
      "Epoch 432/500\n",
      "2/2 - 0s - loss: 1.6854 - mse: 1.6854\n",
      "Epoch 433/500\n",
      "2/2 - 0s - loss: 1.3314 - mse: 1.3314\n",
      "Epoch 434/500\n",
      "2/2 - 0s - loss: 1.7508 - mse: 1.7508\n",
      "Epoch 435/500\n",
      "2/2 - 0s - loss: 1.2956 - mse: 1.2956\n",
      "Epoch 436/500\n",
      "2/2 - 0s - loss: 1.6914 - mse: 1.6914\n",
      "Epoch 437/500\n",
      "2/2 - 0s - loss: 3.5051 - mse: 3.5051\n",
      "Epoch 438/500\n",
      "2/2 - 0s - loss: 1.9453 - mse: 1.9453\n",
      "Epoch 439/500\n",
      "2/2 - 0s - loss: 1.3371 - mse: 1.3371\n",
      "Epoch 440/500\n",
      "2/2 - 0s - loss: 1.3250 - mse: 1.3250\n",
      "Epoch 441/500\n",
      "2/2 - 0s - loss: 1.2787 - mse: 1.2787\n",
      "Epoch 442/500\n",
      "2/2 - 0s - loss: 1.3188 - mse: 1.3188\n",
      "Epoch 443/500\n",
      "2/2 - 0s - loss: 1.4888 - mse: 1.4888\n",
      "Epoch 444/500\n",
      "2/2 - 0s - loss: 2.9269 - mse: 2.9269\n",
      "Epoch 445/500\n",
      "2/2 - 0s - loss: 2.9542 - mse: 2.9542\n",
      "Epoch 446/500\n",
      "2/2 - 0s - loss: 2.9894 - mse: 2.9894\n",
      "Epoch 447/500\n",
      "2/2 - 0s - loss: 1.4386 - mse: 1.4386\n",
      "Epoch 448/500\n",
      "2/2 - 0s - loss: 1.2782 - mse: 1.2782\n",
      "Epoch 449/500\n",
      "2/2 - 0s - loss: 1.2740 - mse: 1.2740\n",
      "Epoch 450/500\n",
      "2/2 - 0s - loss: 2.0145 - mse: 2.0145\n",
      "Epoch 451/500\n",
      "2/2 - 0s - loss: 2.0134 - mse: 2.0134\n",
      "Epoch 452/500\n",
      "2/2 - 0s - loss: 2.1324 - mse: 2.1324\n",
      "Epoch 453/500\n",
      "2/2 - 0s - loss: 1.7974 - mse: 1.7974\n",
      "Epoch 454/500\n",
      "2/2 - 0s - loss: 1.3277 - mse: 1.3277\n",
      "Epoch 455/500\n",
      "2/2 - 0s - loss: 3.6835 - mse: 3.6835\n",
      "Epoch 456/500\n",
      "2/2 - 0s - loss: 2.8579 - mse: 2.8579\n",
      "Epoch 457/500\n",
      "2/2 - 0s - loss: 1.2876 - mse: 1.2876\n",
      "Epoch 458/500\n",
      "2/2 - 0s - loss: 1.2611 - mse: 1.2611\n",
      "Epoch 459/500\n",
      "2/2 - 0s - loss: 1.2589 - mse: 1.2589\n",
      "Epoch 460/500\n",
      "2/2 - 0s - loss: 3.2791 - mse: 3.2791\n",
      "Epoch 461/500\n",
      "2/2 - 0s - loss: 2.9462 - mse: 2.9462\n",
      "Epoch 462/500\n",
      "2/2 - 0s - loss: 1.3107 - mse: 1.3107\n",
      "Epoch 463/500\n",
      "2/2 - 0s - loss: 1.2733 - mse: 1.2733\n",
      "Epoch 464/500\n",
      "2/2 - 0s - loss: 1.2803 - mse: 1.2803\n",
      "Epoch 465/500\n",
      "2/2 - 0s - loss: 1.2955 - mse: 1.2955\n",
      "Epoch 466/500\n",
      "2/2 - 0s - loss: 1.2444 - mse: 1.2444\n",
      "Epoch 467/500\n",
      "2/2 - 0s - loss: 1.2491 - mse: 1.2491\n",
      "Epoch 468/500\n",
      "2/2 - 0s - loss: 1.6539 - mse: 1.6539\n",
      "Epoch 469/500\n",
      "2/2 - 0s - loss: 5.4521 - mse: 5.4521\n",
      "Epoch 470/500\n",
      "2/2 - 0s - loss: 1.2927 - mse: 1.2927\n",
      "Epoch 471/500\n",
      "2/2 - 0s - loss: 1.4821 - mse: 1.4821\n",
      "Epoch 472/500\n",
      "2/2 - 0s - loss: 1.3442 - mse: 1.3442\n",
      "Epoch 473/500\n",
      "2/2 - 0s - loss: 2.0089 - mse: 2.0089\n",
      "Epoch 474/500\n",
      "2/2 - 0s - loss: 3.5968 - mse: 3.5968\n",
      "Epoch 475/500\n",
      "2/2 - 0s - loss: 1.7476 - mse: 1.7476\n",
      "Epoch 476/500\n",
      "2/2 - 0s - loss: 1.2767 - mse: 1.2767\n",
      "Epoch 477/500\n",
      "2/2 - 0s - loss: 1.2604 - mse: 1.2604\n",
      "Epoch 478/500\n",
      "2/2 - 0s - loss: 1.6081 - mse: 1.6081\n",
      "Epoch 479/500\n",
      "2/2 - 0s - loss: 2.5080 - mse: 2.5080\n",
      "Epoch 480/500\n",
      "2/2 - 0s - loss: 2.3013 - mse: 2.3013\n",
      "Epoch 481/500\n",
      "2/2 - 0s - loss: 1.5792 - mse: 1.5792\n",
      "Epoch 482/500\n",
      "2/2 - 0s - loss: 1.2281 - mse: 1.2281\n",
      "Epoch 483/500\n",
      "2/2 - 0s - loss: 1.4278 - mse: 1.4278\n",
      "Epoch 484/500\n",
      "2/2 - 0s - loss: 1.5902 - mse: 1.5902\n",
      "Epoch 485/500\n",
      "2/2 - 0s - loss: 1.2012 - mse: 1.2012\n",
      "Epoch 486/500\n",
      "2/2 - 0s - loss: 1.3797 - mse: 1.3797\n",
      "Epoch 487/500\n",
      "2/2 - 0s - loss: 2.1690 - mse: 2.1690\n",
      "Epoch 488/500\n",
      "2/2 - 0s - loss: 2.6328 - mse: 2.6328\n",
      "Epoch 489/500\n",
      "2/2 - 0s - loss: 1.2191 - mse: 1.2191\n",
      "Epoch 490/500\n",
      "2/2 - 0s - loss: 1.4258 - mse: 1.4258\n",
      "Epoch 491/500\n",
      "2/2 - 0s - loss: 2.5756 - mse: 2.5756\n",
      "Epoch 492/500\n",
      "2/2 - 0s - loss: 3.8859 - mse: 3.8859\n",
      "Epoch 493/500\n",
      "2/2 - 0s - loss: 2.4327 - mse: 2.4327\n",
      "Epoch 494/500\n",
      "2/2 - 0s - loss: 1.6529 - mse: 1.6529\n",
      "Epoch 495/500\n",
      "2/2 - 0s - loss: 1.4519 - mse: 1.4519\n",
      "Epoch 496/500\n",
      "2/2 - 0s - loss: 1.2529 - mse: 1.2529\n",
      "Epoch 497/500\n",
      "2/2 - 0s - loss: 1.4874 - mse: 1.4874\n",
      "Epoch 498/500\n",
      "2/2 - 0s - loss: 1.8867 - mse: 1.8867\n",
      "Epoch 499/500\n",
      "2/2 - 0s - loss: 4.3094 - mse: 4.3094\n",
      "Epoch 500/500\n",
      "2/2 - 0s - loss: 2.4183 - mse: 2.4183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17dff6b80>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.15157871,  0.15006189, -0.14974315],\n",
       "        [ 0.29294756,  0.29112825, -0.2907222 ],\n",
       "        [ 0.21797644,  0.21632607, -0.21596937],\n",
       "        [ 0.31826466,  0.31647795, -0.3160798 ],\n",
       "        [-0.00179686, -0.00092771,  0.00065475],\n",
       "        [ 0.01179831,  0.01225254, -0.01242991]], dtype=float32),\n",
       " array([ 0.13434592,  0.13393463, -0.13389426], dtype=float32),\n",
       " array([[ 0.24216445],\n",
       "        [ 0.49543723],\n",
       "        [-0.75170743]], dtype=float32),\n",
       " array([0.13389555], dtype=float32)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros_after_fit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>18.889677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>18.213333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>18.270931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>22.034506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>13.092728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros_after_fit\n",
       "abbrev                             \n",
       "AL       18.8             18.889677\n",
       "AK       18.1             18.213333\n",
       "AZ       18.6             18.270931\n",
       "AR       22.4             22.034506\n",
       "CA       12.0             13.092728"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsel = df[['total']].copy()\n",
    "dfsel['pred_zeros_after_fit'] = y_pred\n",
    "dfsel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to `kernel_initializer` the weights to 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Dense(units=12, input_dim=8, kernel_initializer='zeros'))\n",
    "model.add(layer=Dense(units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a Prediction with the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Can we make a prediction for for `Washington DC` accidents\n",
    "> - With the already initialized Mathematical Equation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='total')\n",
    "y = df.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL = X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>7.332</td>\n",
       "      <td>5.64</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.04</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                \n",
       "AL         7.332     5.64          18.048        15.04       784.55   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/sota/miniforge3/envs/dl/lib/python3.9/site-packages/keras/engine/training.py:1586 predict_function  *\n        return step_function(self, iterator)\n    /Users/sota/miniforge3/envs/dl/lib/python3.9/site-packages/keras/engine/training.py:1576 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/sota/miniforge3/envs/dl/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/sota/miniforge3/envs/dl/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/sota/miniforge3/envs/dl/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/sota/miniforge3/envs/dl/lib/python3.9/site-packages/keras/engine/training.py:1569 run_step  **\n        outputs = model.predict_step(data)\n    /Users/sota/miniforge3/envs/dl/lib/python3.9/site-packages/keras/engine/training.py:1537 predict_step\n        return self(x, training=False)\n    /Users/sota/miniforge3/envs/dl/lib/python3.9/site-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /Users/sota/miniforge3/envs/dl/lib/python3.9/site-packages/keras/engine/input_spec.py:250 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_3 is incompatible with the layer: expected axis -1 of input shape to have value 8 but received input with shape (None, 6)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/24/tg28vxls25l9mjvqrnh0plc80000gn/T/ipykernel_38098/3015801051.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/dl/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1749\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/dl/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/dl/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/dl/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 759\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    760\u001b[0m             *args, **kwds))\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/dl/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/dl/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/dl/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3298\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/dl/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/dl/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/dl/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/sota/miniforge3/envs/dl/lib/python3.9/site-packages/keras/engine/training.py:1586 predict_function  *\n        return step_function(self, iterator)\n    /Users/sota/miniforge3/envs/dl/lib/python3.9/site-packages/keras/engine/training.py:1576 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/sota/miniforge3/envs/dl/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/sota/miniforge3/envs/dl/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/sota/miniforge3/envs/dl/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/sota/miniforge3/envs/dl/lib/python3.9/site-packages/keras/engine/training.py:1569 run_step  **\n        outputs = model.predict_step(data)\n    /Users/sota/miniforge3/envs/dl/lib/python3.9/site-packages/keras/engine/training.py:1537 predict_step\n        return self(x, training=False)\n    /Users/sota/miniforge3/envs/dl/lib/python3.9/site-packages/keras/engine/base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /Users/sota/miniforge3/envs/dl/lib/python3.9/site-packages/keras/engine/input_spec.py:250 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_3 is incompatible with the layer: expected axis -1 of input shape to have value 8 but received input with shape (None, 6)\n"
     ]
    }
   ],
   "source": [
    "model.predict(x=AL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>speeding</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>not_distracted</th>\n",
       "      <th>no_previous</th>\n",
       "      <th>ins_premium</th>\n",
       "      <th>ins_losses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>7.332</td>\n",
       "      <td>5.64</td>\n",
       "      <td>18.048</td>\n",
       "      <td>15.04</td>\n",
       "      <td>784.55</td>\n",
       "      <td>145.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  speeding  alcohol  not_distracted  no_previous  ins_premium  \\\n",
       "abbrev                                                                       \n",
       "AL       18.8     7.332     5.64          18.048        15.04       784.55   \n",
       "\n",
       "        ins_losses  \n",
       "abbrev              \n",
       "AL          145.08  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[ 0.13440204],\n",
       "        [ 0.3892213 ],\n",
       "        [-0.645908  ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `fit()` the `model` and compare again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 - 0s - loss: 222.7761 - mse: 222.7761\n",
      "Epoch 2/500\n",
      "2/2 - 0s - loss: 93.2213 - mse: 93.2213\n",
      "Epoch 3/500\n",
      "2/2 - 0s - loss: 52.9440 - mse: 52.9440\n",
      "Epoch 4/500\n",
      "2/2 - 0s - loss: 37.1020 - mse: 37.1020\n",
      "Epoch 5/500\n",
      "2/2 - 0s - loss: 30.7588 - mse: 30.7588\n",
      "Epoch 6/500\n",
      "2/2 - 0s - loss: 29.0020 - mse: 29.0020\n",
      "Epoch 7/500\n",
      "2/2 - 0s - loss: 28.2831 - mse: 28.2831\n",
      "Epoch 8/500\n",
      "2/2 - 0s - loss: 27.4843 - mse: 27.4843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-06 10:03:22.351338: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/500\n",
      "2/2 - 0s - loss: 27.0332 - mse: 27.0332\n",
      "Epoch 10/500\n",
      "2/2 - 0s - loss: 26.8303 - mse: 26.8303\n",
      "Epoch 11/500\n",
      "2/2 - 0s - loss: 27.0910 - mse: 27.0910\n",
      "Epoch 12/500\n",
      "2/2 - 0s - loss: 26.6957 - mse: 26.6957\n",
      "Epoch 13/500\n",
      "2/2 - 0s - loss: 26.4539 - mse: 26.4539\n",
      "Epoch 14/500\n",
      "2/2 - 0s - loss: 26.1589 - mse: 26.1589\n",
      "Epoch 15/500\n",
      "2/2 - 0s - loss: 25.8832 - mse: 25.8832\n",
      "Epoch 16/500\n",
      "2/2 - 0s - loss: 25.9123 - mse: 25.9123\n",
      "Epoch 17/500\n",
      "2/2 - 0s - loss: 25.9592 - mse: 25.9592\n",
      "Epoch 18/500\n",
      "2/2 - 0s - loss: 26.7020 - mse: 26.7020\n",
      "Epoch 19/500\n",
      "2/2 - 0s - loss: 25.8275 - mse: 25.8275\n",
      "Epoch 20/500\n",
      "2/2 - 0s - loss: 24.7741 - mse: 24.7741\n",
      "Epoch 21/500\n",
      "2/2 - 0s - loss: 24.9872 - mse: 24.9872\n",
      "Epoch 22/500\n",
      "2/2 - 0s - loss: 24.8492 - mse: 24.8492\n",
      "Epoch 23/500\n",
      "2/2 - 0s - loss: 23.9078 - mse: 23.9078\n",
      "Epoch 24/500\n",
      "2/2 - 0s - loss: 24.1131 - mse: 24.1131\n",
      "Epoch 25/500\n",
      "2/2 - 0s - loss: 26.7698 - mse: 26.7698\n",
      "Epoch 26/500\n",
      "2/2 - 0s - loss: 24.0691 - mse: 24.0691\n",
      "Epoch 27/500\n",
      "2/2 - 0s - loss: 23.2625 - mse: 23.2625\n",
      "Epoch 28/500\n",
      "2/2 - 0s - loss: 24.1825 - mse: 24.1825\n",
      "Epoch 29/500\n",
      "2/2 - 0s - loss: 23.3085 - mse: 23.3085\n",
      "Epoch 30/500\n",
      "2/2 - 0s - loss: 22.3871 - mse: 22.3871\n",
      "Epoch 31/500\n",
      "2/2 - 0s - loss: 22.1700 - mse: 22.1700\n",
      "Epoch 32/500\n",
      "2/2 - 0s - loss: 21.5644 - mse: 21.5644\n",
      "Epoch 33/500\n",
      "2/2 - 0s - loss: 21.4979 - mse: 21.4979\n",
      "Epoch 34/500\n",
      "2/2 - 0s - loss: 21.8217 - mse: 21.8217\n",
      "Epoch 35/500\n",
      "2/2 - 0s - loss: 23.4312 - mse: 23.4312\n",
      "Epoch 36/500\n",
      "2/2 - 0s - loss: 22.0476 - mse: 22.0476\n",
      "Epoch 37/500\n",
      "2/2 - 0s - loss: 20.2329 - mse: 20.2329\n",
      "Epoch 38/500\n",
      "2/2 - 0s - loss: 20.4762 - mse: 20.4762\n",
      "Epoch 39/500\n",
      "2/2 - 0s - loss: 20.4359 - mse: 20.4359\n",
      "Epoch 40/500\n",
      "2/2 - 0s - loss: 19.5948 - mse: 19.5948\n",
      "Epoch 41/500\n",
      "2/2 - 0s - loss: 19.5251 - mse: 19.5251\n",
      "Epoch 42/500\n",
      "2/2 - 0s - loss: 19.4378 - mse: 19.4378\n",
      "Epoch 43/500\n",
      "2/2 - 0s - loss: 18.6767 - mse: 18.6767\n",
      "Epoch 44/500\n",
      "2/2 - 0s - loss: 20.0820 - mse: 20.0820\n",
      "Epoch 45/500\n",
      "2/2 - 0s - loss: 19.4713 - mse: 19.4713\n",
      "Epoch 46/500\n",
      "2/2 - 0s - loss: 17.9832 - mse: 17.9832\n",
      "Epoch 47/500\n",
      "2/2 - 0s - loss: 18.1254 - mse: 18.1254\n",
      "Epoch 48/500\n",
      "2/2 - 0s - loss: 17.4699 - mse: 17.4699\n",
      "Epoch 49/500\n",
      "2/2 - 0s - loss: 17.3335 - mse: 17.3335\n",
      "Epoch 50/500\n",
      "2/2 - 0s - loss: 17.5593 - mse: 17.5593\n",
      "Epoch 51/500\n",
      "2/2 - 0s - loss: 16.8436 - mse: 16.8436\n",
      "Epoch 52/500\n",
      "2/2 - 0s - loss: 16.3571 - mse: 16.3571\n",
      "Epoch 53/500\n",
      "2/2 - 0s - loss: 21.9490 - mse: 21.9490\n",
      "Epoch 54/500\n",
      "2/2 - 0s - loss: 16.9083 - mse: 16.9083\n",
      "Epoch 55/500\n",
      "2/2 - 0s - loss: 15.9710 - mse: 15.9710\n",
      "Epoch 56/500\n",
      "2/2 - 0s - loss: 15.5613 - mse: 15.5613\n",
      "Epoch 57/500\n",
      "2/2 - 0s - loss: 15.5893 - mse: 15.5893\n",
      "Epoch 58/500\n",
      "2/2 - 0s - loss: 15.1499 - mse: 15.1499\n",
      "Epoch 59/500\n",
      "2/2 - 0s - loss: 14.8698 - mse: 14.8698\n",
      "Epoch 60/500\n",
      "2/2 - 0s - loss: 14.7910 - mse: 14.7910\n",
      "Epoch 61/500\n",
      "2/2 - 0s - loss: 16.4141 - mse: 16.4141\n",
      "Epoch 62/500\n",
      "2/2 - 0s - loss: 16.8570 - mse: 16.8570\n",
      "Epoch 63/500\n",
      "2/2 - 0s - loss: 14.0232 - mse: 14.0232\n",
      "Epoch 64/500\n",
      "2/2 - 0s - loss: 13.6862 - mse: 13.6862\n",
      "Epoch 65/500\n",
      "2/2 - 0s - loss: 13.5347 - mse: 13.5347\n",
      "Epoch 66/500\n",
      "2/2 - 0s - loss: 13.9548 - mse: 13.9548\n",
      "Epoch 67/500\n",
      "2/2 - 0s - loss: 16.1486 - mse: 16.1486\n",
      "Epoch 68/500\n",
      "2/2 - 0s - loss: 13.6981 - mse: 13.6981\n",
      "Epoch 69/500\n",
      "2/2 - 0s - loss: 12.8088 - mse: 12.8088\n",
      "Epoch 70/500\n",
      "2/2 - 0s - loss: 13.1956 - mse: 13.1956\n",
      "Epoch 71/500\n",
      "2/2 - 0s - loss: 12.2983 - mse: 12.2983\n",
      "Epoch 72/500\n",
      "2/2 - 0s - loss: 12.1200 - mse: 12.1200\n",
      "Epoch 73/500\n",
      "2/2 - 0s - loss: 12.3292 - mse: 12.3292\n",
      "Epoch 74/500\n",
      "2/2 - 0s - loss: 13.5179 - mse: 13.5179\n",
      "Epoch 75/500\n",
      "2/2 - 0s - loss: 12.7410 - mse: 12.7410\n",
      "Epoch 76/500\n",
      "2/2 - 0s - loss: 11.4167 - mse: 11.4167\n",
      "Epoch 77/500\n",
      "2/2 - 0s - loss: 11.1840 - mse: 11.1840\n",
      "Epoch 78/500\n",
      "2/2 - 0s - loss: 11.2869 - mse: 11.2869\n",
      "Epoch 79/500\n",
      "2/2 - 0s - loss: 10.7502 - mse: 10.7502\n",
      "Epoch 80/500\n",
      "2/2 - 0s - loss: 11.2006 - mse: 11.2006\n",
      "Epoch 81/500\n",
      "2/2 - 0s - loss: 11.4156 - mse: 11.4156\n",
      "Epoch 82/500\n",
      "2/2 - 0s - loss: 10.2408 - mse: 10.2408\n",
      "Epoch 83/500\n",
      "2/2 - 0s - loss: 11.7316 - mse: 11.7316\n",
      "Epoch 84/500\n",
      "2/2 - 0s - loss: 10.1670 - mse: 10.1670\n",
      "Epoch 85/500\n",
      "2/2 - 0s - loss: 10.5181 - mse: 10.5181\n",
      "Epoch 86/500\n",
      "2/2 - 0s - loss: 10.1342 - mse: 10.1342\n",
      "Epoch 87/500\n",
      "2/2 - 0s - loss: 9.4884 - mse: 9.4884\n",
      "Epoch 88/500\n",
      "2/2 - 0s - loss: 9.9367 - mse: 9.9367\n",
      "Epoch 89/500\n",
      "2/2 - 0s - loss: 9.6178 - mse: 9.6178\n",
      "Epoch 90/500\n",
      "2/2 - 0s - loss: 8.8449 - mse: 8.8449\n",
      "Epoch 91/500\n",
      "2/2 - 0s - loss: 9.8264 - mse: 9.8264\n",
      "Epoch 92/500\n",
      "2/2 - 0s - loss: 10.6083 - mse: 10.6083\n",
      "Epoch 93/500\n",
      "2/2 - 0s - loss: 8.4493 - mse: 8.4493\n",
      "Epoch 94/500\n",
      "2/2 - 0s - loss: 8.5235 - mse: 8.5235\n",
      "Epoch 95/500\n",
      "2/2 - 0s - loss: 8.1503 - mse: 8.1503\n",
      "Epoch 96/500\n",
      "2/2 - 0s - loss: 8.1870 - mse: 8.1870\n",
      "Epoch 97/500\n",
      "2/2 - 0s - loss: 8.7121 - mse: 8.7121\n",
      "Epoch 98/500\n",
      "2/2 - 0s - loss: 10.0632 - mse: 10.0632\n",
      "Epoch 99/500\n",
      "2/2 - 0s - loss: 7.6775 - mse: 7.6775\n",
      "Epoch 100/500\n",
      "2/2 - 0s - loss: 8.4798 - mse: 8.4798\n",
      "Epoch 101/500\n",
      "2/2 - 0s - loss: 10.3607 - mse: 10.3607\n",
      "Epoch 102/500\n",
      "2/2 - 0s - loss: 8.2308 - mse: 8.2308\n",
      "Epoch 103/500\n",
      "2/2 - 0s - loss: 8.2611 - mse: 8.2611\n",
      "Epoch 104/500\n",
      "2/2 - 0s - loss: 7.3173 - mse: 7.3173\n",
      "Epoch 105/500\n",
      "2/2 - 0s - loss: 7.1542 - mse: 7.1542\n",
      "Epoch 106/500\n",
      "2/2 - 0s - loss: 7.1544 - mse: 7.1544\n",
      "Epoch 107/500\n",
      "2/2 - 0s - loss: 6.8825 - mse: 6.8825\n",
      "Epoch 108/500\n",
      "2/2 - 0s - loss: 6.8225 - mse: 6.8225\n",
      "Epoch 109/500\n",
      "2/2 - 0s - loss: 6.3844 - mse: 6.3844\n",
      "Epoch 110/500\n",
      "2/2 - 0s - loss: 7.2883 - mse: 7.2883\n",
      "Epoch 111/500\n",
      "2/2 - 0s - loss: 7.9689 - mse: 7.9689\n",
      "Epoch 112/500\n",
      "2/2 - 0s - loss: 7.8302 - mse: 7.8302\n",
      "Epoch 113/500\n",
      "2/2 - 0s - loss: 6.6849 - mse: 6.6849\n",
      "Epoch 114/500\n",
      "2/2 - 0s - loss: 5.9061 - mse: 5.9061\n",
      "Epoch 115/500\n",
      "2/2 - 0s - loss: 6.8101 - mse: 6.8101\n",
      "Epoch 116/500\n",
      "2/2 - 0s - loss: 5.7848 - mse: 5.7848\n",
      "Epoch 117/500\n",
      "2/2 - 0s - loss: 6.2863 - mse: 6.2863\n",
      "Epoch 118/500\n",
      "2/2 - 0s - loss: 5.5534 - mse: 5.5534\n",
      "Epoch 119/500\n",
      "2/2 - 0s - loss: 6.5837 - mse: 6.5837\n",
      "Epoch 120/500\n",
      "2/2 - 0s - loss: 6.3975 - mse: 6.3975\n",
      "Epoch 121/500\n",
      "2/2 - 0s - loss: 5.2893 - mse: 5.2893\n",
      "Epoch 122/500\n",
      "2/2 - 0s - loss: 5.1630 - mse: 5.1630\n",
      "Epoch 123/500\n",
      "2/2 - 0s - loss: 5.2474 - mse: 5.2474\n",
      "Epoch 124/500\n",
      "2/2 - 0s - loss: 7.0166 - mse: 7.0166\n",
      "Epoch 125/500\n",
      "2/2 - 0s - loss: 6.1788 - mse: 6.1788\n",
      "Epoch 126/500\n",
      "2/2 - 0s - loss: 4.8640 - mse: 4.8640\n",
      "Epoch 127/500\n",
      "2/2 - 0s - loss: 4.7698 - mse: 4.7698\n",
      "Epoch 128/500\n",
      "2/2 - 0s - loss: 7.4195 - mse: 7.4195\n",
      "Epoch 129/500\n",
      "2/2 - 0s - loss: 5.2195 - mse: 5.2195\n",
      "Epoch 130/500\n",
      "2/2 - 0s - loss: 4.3620 - mse: 4.3620\n",
      "Epoch 131/500\n",
      "2/2 - 0s - loss: 4.7837 - mse: 4.7837\n",
      "Epoch 132/500\n",
      "2/2 - 0s - loss: 4.5211 - mse: 4.5211\n",
      "Epoch 133/500\n",
      "2/2 - 0s - loss: 4.3410 - mse: 4.3410\n",
      "Epoch 134/500\n",
      "2/2 - 0s - loss: 4.0525 - mse: 4.0525\n",
      "Epoch 135/500\n",
      "2/2 - 0s - loss: 4.9074 - mse: 4.9074\n",
      "Epoch 136/500\n",
      "2/2 - 0s - loss: 5.3598 - mse: 5.3598\n",
      "Epoch 137/500\n",
      "2/2 - 0s - loss: 4.6035 - mse: 4.6035\n",
      "Epoch 138/500\n",
      "2/2 - 0s - loss: 3.9493 - mse: 3.9493\n",
      "Epoch 139/500\n",
      "2/2 - 0s - loss: 4.2269 - mse: 4.2269\n",
      "Epoch 140/500\n",
      "2/2 - 0s - loss: 4.0904 - mse: 4.0904\n",
      "Epoch 141/500\n",
      "2/2 - 0s - loss: 5.1536 - mse: 5.1536\n",
      "Epoch 142/500\n",
      "2/2 - 0s - loss: 3.9985 - mse: 3.9985\n",
      "Epoch 143/500\n",
      "2/2 - 0s - loss: 3.5272 - mse: 3.5272\n",
      "Epoch 144/500\n",
      "2/2 - 0s - loss: 4.8510 - mse: 4.8510\n",
      "Epoch 145/500\n",
      "2/2 - 0s - loss: 4.6384 - mse: 4.6384\n",
      "Epoch 146/500\n",
      "2/2 - 0s - loss: 3.5837 - mse: 3.5837\n",
      "Epoch 147/500\n",
      "2/2 - 0s - loss: 4.4249 - mse: 4.4249\n",
      "Epoch 148/500\n",
      "2/2 - 0s - loss: 4.3744 - mse: 4.3744\n",
      "Epoch 149/500\n",
      "2/2 - 0s - loss: 3.4624 - mse: 3.4624\n",
      "Epoch 150/500\n",
      "2/2 - 0s - loss: 4.2671 - mse: 4.2671\n",
      "Epoch 151/500\n",
      "2/2 - 0s - loss: 3.4415 - mse: 3.4415\n",
      "Epoch 152/500\n",
      "2/2 - 0s - loss: 3.5610 - mse: 3.5610\n",
      "Epoch 153/500\n",
      "2/2 - 0s - loss: 4.1556 - mse: 4.1556\n",
      "Epoch 154/500\n",
      "2/2 - 0s - loss: 3.9856 - mse: 3.9856\n",
      "Epoch 155/500\n",
      "2/2 - 0s - loss: 3.5120 - mse: 3.5120\n",
      "Epoch 156/500\n",
      "2/2 - 0s - loss: 3.0025 - mse: 3.0025\n",
      "Epoch 157/500\n",
      "2/2 - 0s - loss: 3.0402 - mse: 3.0402\n",
      "Epoch 158/500\n",
      "2/2 - 0s - loss: 3.9188 - mse: 3.9188\n",
      "Epoch 159/500\n",
      "2/2 - 0s - loss: 5.3381 - mse: 5.3381\n",
      "Epoch 160/500\n",
      "2/2 - 0s - loss: 2.8905 - mse: 2.8905\n",
      "Epoch 161/500\n",
      "2/2 - 0s - loss: 2.7804 - mse: 2.7804\n",
      "Epoch 162/500\n",
      "2/2 - 0s - loss: 2.9893 - mse: 2.9893\n",
      "Epoch 163/500\n",
      "2/2 - 0s - loss: 4.4490 - mse: 4.4490\n",
      "Epoch 164/500\n",
      "2/2 - 0s - loss: 5.4831 - mse: 5.4831\n",
      "Epoch 165/500\n",
      "2/2 - 0s - loss: 3.8016 - mse: 3.8016\n",
      "Epoch 166/500\n",
      "2/2 - 0s - loss: 3.2006 - mse: 3.2006\n",
      "Epoch 167/500\n",
      "2/2 - 0s - loss: 3.2243 - mse: 3.2243\n",
      "Epoch 168/500\n",
      "2/2 - 0s - loss: 3.1576 - mse: 3.1576\n",
      "Epoch 169/500\n",
      "2/2 - 0s - loss: 2.9969 - mse: 2.9969\n",
      "Epoch 170/500\n",
      "2/2 - 0s - loss: 2.9315 - mse: 2.9315\n",
      "Epoch 171/500\n",
      "2/2 - 0s - loss: 3.0199 - mse: 3.0199\n",
      "Epoch 172/500\n",
      "2/2 - 0s - loss: 3.2206 - mse: 3.2206\n",
      "Epoch 173/500\n",
      "2/2 - 0s - loss: 2.9526 - mse: 2.9526\n",
      "Epoch 174/500\n",
      "2/2 - 0s - loss: 2.9846 - mse: 2.9846\n",
      "Epoch 175/500\n",
      "2/2 - 0s - loss: 2.4217 - mse: 2.4217\n",
      "Epoch 176/500\n",
      "2/2 - 0s - loss: 3.4983 - mse: 3.4983\n",
      "Epoch 177/500\n",
      "2/2 - 0s - loss: 5.1898 - mse: 5.1898\n",
      "Epoch 178/500\n",
      "2/2 - 0s - loss: 2.5464 - mse: 2.5464\n",
      "Epoch 179/500\n",
      "2/2 - 0s - loss: 2.6629 - mse: 2.6629\n",
      "Epoch 180/500\n",
      "2/2 - 0s - loss: 2.6482 - mse: 2.6482\n",
      "Epoch 181/500\n",
      "2/2 - 0s - loss: 2.7491 - mse: 2.7491\n",
      "Epoch 182/500\n",
      "2/2 - 0s - loss: 2.6063 - mse: 2.6063\n",
      "Epoch 183/500\n",
      "2/2 - 0s - loss: 2.2318 - mse: 2.2318\n",
      "Epoch 184/500\n",
      "2/2 - 0s - loss: 4.3015 - mse: 4.3015\n",
      "Epoch 185/500\n",
      "2/2 - 0s - loss: 3.3086 - mse: 3.3086\n",
      "Epoch 186/500\n",
      "2/2 - 0s - loss: 2.3460 - mse: 2.3460\n",
      "Epoch 187/500\n",
      "2/2 - 0s - loss: 2.1883 - mse: 2.1883\n",
      "Epoch 188/500\n",
      "2/2 - 0s - loss: 2.4235 - mse: 2.4235\n",
      "Epoch 189/500\n",
      "2/2 - 0s - loss: 3.7142 - mse: 3.7142\n",
      "Epoch 190/500\n",
      "2/2 - 0s - loss: 4.1086 - mse: 4.1086\n",
      "Epoch 191/500\n",
      "2/2 - 0s - loss: 2.7766 - mse: 2.7766\n",
      "Epoch 192/500\n",
      "2/2 - 0s - loss: 2.3721 - mse: 2.3721\n",
      "Epoch 193/500\n",
      "2/2 - 0s - loss: 2.1407 - mse: 2.1407\n",
      "Epoch 194/500\n",
      "2/2 - 0s - loss: 2.1441 - mse: 2.1441\n",
      "Epoch 195/500\n",
      "2/2 - 0s - loss: 2.3422 - mse: 2.3422\n",
      "Epoch 196/500\n",
      "2/2 - 0s - loss: 3.0912 - mse: 3.0912\n",
      "Epoch 197/500\n",
      "2/2 - 0s - loss: 2.1562 - mse: 2.1562\n",
      "Epoch 198/500\n",
      "2/2 - 0s - loss: 2.1236 - mse: 2.1236\n",
      "Epoch 199/500\n",
      "2/2 - 0s - loss: 2.6009 - mse: 2.6009\n",
      "Epoch 200/500\n",
      "2/2 - 0s - loss: 2.2004 - mse: 2.2004\n",
      "Epoch 201/500\n",
      "2/2 - 0s - loss: 2.9449 - mse: 2.9449\n",
      "Epoch 202/500\n",
      "2/2 - 0s - loss: 4.7769 - mse: 4.7769\n",
      "Epoch 203/500\n",
      "2/2 - 0s - loss: 2.9870 - mse: 2.9870\n",
      "Epoch 204/500\n",
      "2/2 - 0s - loss: 2.0323 - mse: 2.0323\n",
      "Epoch 205/500\n",
      "2/2 - 0s - loss: 2.6183 - mse: 2.6183\n",
      "Epoch 206/500\n",
      "2/2 - 0s - loss: 2.0055 - mse: 2.0055\n",
      "Epoch 207/500\n",
      "2/2 - 0s - loss: 2.6907 - mse: 2.6907\n",
      "Epoch 208/500\n",
      "2/2 - 0s - loss: 3.6743 - mse: 3.6743\n",
      "Epoch 209/500\n",
      "2/2 - 0s - loss: 2.7335 - mse: 2.7335\n",
      "Epoch 210/500\n",
      "2/2 - 0s - loss: 1.9270 - mse: 1.9270\n",
      "Epoch 211/500\n",
      "2/2 - 0s - loss: 2.2608 - mse: 2.2608\n",
      "Epoch 212/500\n",
      "2/2 - 0s - loss: 3.1712 - mse: 3.1712\n",
      "Epoch 213/500\n",
      "2/2 - 0s - loss: 2.5155 - mse: 2.5155\n",
      "Epoch 214/500\n",
      "2/2 - 0s - loss: 2.0025 - mse: 2.0025\n",
      "Epoch 215/500\n",
      "2/2 - 0s - loss: 2.1511 - mse: 2.1511\n",
      "Epoch 216/500\n",
      "2/2 - 0s - loss: 2.0488 - mse: 2.0488\n",
      "Epoch 217/500\n",
      "2/2 - 0s - loss: 2.0394 - mse: 2.0394\n",
      "Epoch 218/500\n",
      "2/2 - 0s - loss: 1.8677 - mse: 1.8677\n",
      "Epoch 219/500\n",
      "2/2 - 0s - loss: 2.6548 - mse: 2.6548\n",
      "Epoch 220/500\n",
      "2/2 - 0s - loss: 4.3068 - mse: 4.3068\n",
      "Epoch 221/500\n",
      "2/2 - 0s - loss: 2.0615 - mse: 2.0615\n",
      "Epoch 222/500\n",
      "2/2 - 0s - loss: 1.8118 - mse: 1.8118\n",
      "Epoch 223/500\n",
      "2/2 - 0s - loss: 1.8570 - mse: 1.8570\n",
      "Epoch 224/500\n",
      "2/2 - 0s - loss: 2.7652 - mse: 2.7652\n",
      "Epoch 225/500\n",
      "2/2 - 0s - loss: 3.7180 - mse: 3.7180\n",
      "Epoch 226/500\n",
      "2/2 - 0s - loss: 2.8748 - mse: 2.8748\n",
      "Epoch 227/500\n",
      "2/2 - 0s - loss: 3.4320 - mse: 3.4320\n",
      "Epoch 228/500\n",
      "2/2 - 0s - loss: 2.5803 - mse: 2.5803\n",
      "Epoch 229/500\n",
      "2/2 - 0s - loss: 2.2122 - mse: 2.2122\n",
      "Epoch 230/500\n",
      "2/2 - 0s - loss: 2.3369 - mse: 2.3369\n",
      "Epoch 231/500\n",
      "2/2 - 0s - loss: 2.0191 - mse: 2.0191\n",
      "Epoch 232/500\n",
      "2/2 - 0s - loss: 2.4514 - mse: 2.4514\n",
      "Epoch 233/500\n",
      "2/2 - 0s - loss: 1.7500 - mse: 1.7500\n",
      "Epoch 234/500\n",
      "2/2 - 0s - loss: 3.6127 - mse: 3.6127\n",
      "Epoch 235/500\n",
      "2/2 - 0s - loss: 2.0262 - mse: 2.0262\n",
      "Epoch 236/500\n",
      "2/2 - 0s - loss: 2.6529 - mse: 2.6529\n",
      "Epoch 237/500\n",
      "2/2 - 0s - loss: 1.7394 - mse: 1.7394\n",
      "Epoch 238/500\n",
      "2/2 - 0s - loss: 2.2728 - mse: 2.2728\n",
      "Epoch 239/500\n",
      "2/2 - 0s - loss: 4.4450 - mse: 4.4450\n",
      "Epoch 240/500\n",
      "2/2 - 0s - loss: 3.9973 - mse: 3.9973\n",
      "Epoch 241/500\n",
      "2/2 - 0s - loss: 2.6413 - mse: 2.6413\n",
      "Epoch 242/500\n",
      "2/2 - 0s - loss: 1.8577 - mse: 1.8577\n",
      "Epoch 243/500\n",
      "2/2 - 0s - loss: 1.8041 - mse: 1.8041\n",
      "Epoch 244/500\n",
      "2/2 - 0s - loss: 1.7070 - mse: 1.7070\n",
      "Epoch 245/500\n",
      "2/2 - 0s - loss: 1.7410 - mse: 1.7410\n",
      "Epoch 246/500\n",
      "2/2 - 0s - loss: 1.6994 - mse: 1.6994\n",
      "Epoch 247/500\n",
      "2/2 - 0s - loss: 1.6921 - mse: 1.6921\n",
      "Epoch 248/500\n",
      "2/2 - 0s - loss: 1.6821 - mse: 1.6821\n",
      "Epoch 249/500\n",
      "2/2 - 0s - loss: 1.6667 - mse: 1.6667\n",
      "Epoch 250/500\n",
      "2/2 - 0s - loss: 2.1930 - mse: 2.1930\n",
      "Epoch 251/500\n",
      "2/2 - 0s - loss: 5.1500 - mse: 5.1500\n",
      "Epoch 252/500\n",
      "2/2 - 0s - loss: 2.4873 - mse: 2.4873\n",
      "Epoch 253/500\n",
      "2/2 - 0s - loss: 1.8165 - mse: 1.8165\n",
      "Epoch 254/500\n",
      "2/2 - 0s - loss: 1.6596 - mse: 1.6596\n",
      "Epoch 255/500\n",
      "2/2 - 0s - loss: 1.8228 - mse: 1.8228\n",
      "Epoch 256/500\n",
      "2/2 - 0s - loss: 3.3056 - mse: 3.3056\n",
      "Epoch 257/500\n",
      "2/2 - 0s - loss: 4.1887 - mse: 4.1887\n",
      "Epoch 258/500\n",
      "2/2 - 0s - loss: 2.1785 - mse: 2.1785\n",
      "Epoch 259/500\n",
      "2/2 - 0s - loss: 1.8497 - mse: 1.8497\n",
      "Epoch 260/500\n",
      "2/2 - 0s - loss: 2.4097 - mse: 2.4097\n",
      "Epoch 261/500\n",
      "2/2 - 0s - loss: 2.7806 - mse: 2.7806\n",
      "Epoch 262/500\n",
      "2/2 - 0s - loss: 2.8932 - mse: 2.8932\n",
      "Epoch 263/500\n",
      "2/2 - 0s - loss: 3.8969 - mse: 3.8969\n",
      "Epoch 264/500\n",
      "2/2 - 0s - loss: 2.9920 - mse: 2.9920\n",
      "Epoch 265/500\n",
      "2/2 - 0s - loss: 2.2136 - mse: 2.2136\n",
      "Epoch 266/500\n",
      "2/2 - 0s - loss: 1.7738 - mse: 1.7738\n",
      "Epoch 267/500\n",
      "2/2 - 0s - loss: 1.6151 - mse: 1.6151\n",
      "Epoch 268/500\n",
      "2/2 - 0s - loss: 1.8086 - mse: 1.8086\n",
      "Epoch 269/500\n",
      "2/2 - 0s - loss: 2.2085 - mse: 2.2085\n",
      "Epoch 270/500\n",
      "2/2 - 0s - loss: 2.0632 - mse: 2.0632\n",
      "Epoch 271/500\n",
      "2/2 - 0s - loss: 2.1892 - mse: 2.1892\n",
      "Epoch 272/500\n",
      "2/2 - 0s - loss: 2.8847 - mse: 2.8847\n",
      "Epoch 273/500\n",
      "2/2 - 0s - loss: 1.9216 - mse: 1.9216\n",
      "Epoch 274/500\n",
      "2/2 - 0s - loss: 1.5937 - mse: 1.5937\n",
      "Epoch 275/500\n",
      "2/2 - 0s - loss: 1.7110 - mse: 1.7110\n",
      "Epoch 276/500\n",
      "2/2 - 0s - loss: 3.4070 - mse: 3.4070\n",
      "Epoch 277/500\n",
      "2/2 - 0s - loss: 3.6141 - mse: 3.6141\n",
      "Epoch 278/500\n",
      "2/2 - 0s - loss: 2.0063 - mse: 2.0063\n",
      "Epoch 279/500\n",
      "2/2 - 0s - loss: 1.5809 - mse: 1.5809\n",
      "Epoch 280/500\n",
      "2/2 - 0s - loss: 1.6435 - mse: 1.6435\n",
      "Epoch 281/500\n",
      "2/2 - 0s - loss: 3.1039 - mse: 3.1039\n",
      "Epoch 282/500\n",
      "2/2 - 0s - loss: 4.4364 - mse: 4.4364\n",
      "Epoch 283/500\n",
      "2/2 - 0s - loss: 2.3570 - mse: 2.3570\n",
      "Epoch 284/500\n",
      "2/2 - 0s - loss: 2.8096 - mse: 2.8096\n",
      "Epoch 285/500\n",
      "2/2 - 0s - loss: 2.0810 - mse: 2.0810\n",
      "Epoch 286/500\n",
      "2/2 - 0s - loss: 1.6782 - mse: 1.6782\n",
      "Epoch 287/500\n",
      "2/2 - 0s - loss: 2.0020 - mse: 2.0020\n",
      "Epoch 288/500\n",
      "2/2 - 0s - loss: 1.5654 - mse: 1.5654\n",
      "Epoch 289/500\n",
      "2/2 - 0s - loss: 1.6019 - mse: 1.6019\n",
      "Epoch 290/500\n",
      "2/2 - 0s - loss: 1.6294 - mse: 1.6294\n",
      "Epoch 291/500\n",
      "2/2 - 0s - loss: 2.0577 - mse: 2.0577\n",
      "Epoch 292/500\n",
      "2/2 - 0s - loss: 5.4470 - mse: 5.4470\n",
      "Epoch 293/500\n",
      "2/2 - 0s - loss: 3.4890 - mse: 3.4890\n",
      "Epoch 294/500\n",
      "2/2 - 0s - loss: 1.6518 - mse: 1.6518\n",
      "Epoch 295/500\n",
      "2/2 - 0s - loss: 1.5609 - mse: 1.5609\n",
      "Epoch 296/500\n",
      "2/2 - 0s - loss: 1.5908 - mse: 1.5908\n",
      "Epoch 297/500\n",
      "2/2 - 0s - loss: 1.8575 - mse: 1.8575\n",
      "Epoch 298/500\n",
      "2/2 - 0s - loss: 2.3165 - mse: 2.3165\n",
      "Epoch 299/500\n",
      "2/2 - 0s - loss: 1.7670 - mse: 1.7670\n",
      "Epoch 300/500\n",
      "2/2 - 0s - loss: 2.4207 - mse: 2.4207\n",
      "Epoch 301/500\n",
      "2/2 - 0s - loss: 3.0851 - mse: 3.0851\n",
      "Epoch 302/500\n",
      "2/2 - 0s - loss: 2.4587 - mse: 2.4587\n",
      "Epoch 303/500\n",
      "2/2 - 0s - loss: 1.9430 - mse: 1.9430\n",
      "Epoch 304/500\n",
      "2/2 - 0s - loss: 1.6078 - mse: 1.6078\n",
      "Epoch 305/500\n",
      "2/2 - 0s - loss: 1.5712 - mse: 1.5712\n",
      "Epoch 306/500\n",
      "2/2 - 0s - loss: 2.5497 - mse: 2.5497\n",
      "Epoch 307/500\n",
      "2/2 - 0s - loss: 3.0376 - mse: 3.0376\n",
      "Epoch 308/500\n",
      "2/2 - 0s - loss: 1.8197 - mse: 1.8197\n",
      "Epoch 309/500\n",
      "2/2 - 0s - loss: 1.5969 - mse: 1.5969\n",
      "Epoch 310/500\n",
      "2/2 - 0s - loss: 2.2071 - mse: 2.2071\n",
      "Epoch 311/500\n",
      "2/2 - 0s - loss: 4.3188 - mse: 4.3188\n",
      "Epoch 312/500\n",
      "2/2 - 0s - loss: 2.2122 - mse: 2.2122\n",
      "Epoch 313/500\n",
      "2/2 - 0s - loss: 1.6643 - mse: 1.6643\n",
      "Epoch 314/500\n",
      "2/2 - 0s - loss: 1.7521 - mse: 1.7521\n",
      "Epoch 315/500\n",
      "2/2 - 0s - loss: 1.8391 - mse: 1.8391\n",
      "Epoch 316/500\n",
      "2/2 - 0s - loss: 2.0199 - mse: 2.0199\n",
      "Epoch 317/500\n",
      "2/2 - 0s - loss: 3.3005 - mse: 3.3005\n",
      "Epoch 318/500\n",
      "2/2 - 0s - loss: 3.3488 - mse: 3.3488\n",
      "Epoch 319/500\n",
      "2/2 - 0s - loss: 1.5236 - mse: 1.5236\n",
      "Epoch 320/500\n",
      "2/2 - 0s - loss: 1.6127 - mse: 1.6127\n",
      "Epoch 321/500\n",
      "2/2 - 0s - loss: 1.7493 - mse: 1.7493\n",
      "Epoch 322/500\n",
      "2/2 - 0s - loss: 2.1829 - mse: 2.1829\n",
      "Epoch 323/500\n",
      "2/2 - 0s - loss: 2.5690 - mse: 2.5690\n",
      "Epoch 324/500\n",
      "2/2 - 0s - loss: 1.5361 - mse: 1.5361\n",
      "Epoch 325/500\n",
      "2/2 - 0s - loss: 2.2782 - mse: 2.2782\n",
      "Epoch 326/500\n",
      "2/2 - 0s - loss: 3.4192 - mse: 3.4192\n",
      "Epoch 327/500\n",
      "2/2 - 0s - loss: 1.9038 - mse: 1.9038\n",
      "Epoch 328/500\n",
      "2/2 - 0s - loss: 1.4809 - mse: 1.4809\n",
      "Epoch 329/500\n",
      "2/2 - 0s - loss: 1.5364 - mse: 1.5364\n",
      "Epoch 330/500\n",
      "2/2 - 0s - loss: 1.4529 - mse: 1.4529\n",
      "Epoch 331/500\n",
      "2/2 - 0s - loss: 1.4866 - mse: 1.4866\n",
      "Epoch 332/500\n",
      "2/2 - 0s - loss: 1.5451 - mse: 1.5451\n",
      "Epoch 333/500\n",
      "2/2 - 0s - loss: 2.3290 - mse: 2.3290\n",
      "Epoch 334/500\n",
      "2/2 - 0s - loss: 3.2640 - mse: 3.2640\n",
      "Epoch 335/500\n",
      "2/2 - 0s - loss: 2.4220 - mse: 2.4220\n",
      "Epoch 336/500\n",
      "2/2 - 0s - loss: 2.0618 - mse: 2.0618\n",
      "Epoch 337/500\n",
      "2/2 - 0s - loss: 1.6201 - mse: 1.6201\n",
      "Epoch 338/500\n",
      "2/2 - 0s - loss: 1.6412 - mse: 1.6412\n",
      "Epoch 339/500\n",
      "2/2 - 0s - loss: 3.2734 - mse: 3.2734\n",
      "Epoch 340/500\n",
      "2/2 - 0s - loss: 1.4456 - mse: 1.4456\n",
      "Epoch 341/500\n",
      "2/2 - 0s - loss: 2.1681 - mse: 2.1681\n",
      "Epoch 342/500\n",
      "2/2 - 0s - loss: 2.8174 - mse: 2.8174\n",
      "Epoch 343/500\n",
      "2/2 - 0s - loss: 2.8658 - mse: 2.8658\n",
      "Epoch 344/500\n",
      "2/2 - 0s - loss: 1.9640 - mse: 1.9640\n",
      "Epoch 345/500\n",
      "2/2 - 0s - loss: 1.4361 - mse: 1.4361\n",
      "Epoch 346/500\n",
      "2/2 - 0s - loss: 1.5323 - mse: 1.5323\n",
      "Epoch 347/500\n",
      "2/2 - 0s - loss: 2.8489 - mse: 2.8489\n",
      "Epoch 348/500\n",
      "2/2 - 0s - loss: 2.0523 - mse: 2.0523\n",
      "Epoch 349/500\n",
      "2/2 - 0s - loss: 1.4835 - mse: 1.4835\n",
      "Epoch 350/500\n",
      "2/2 - 0s - loss: 1.4174 - mse: 1.4174\n",
      "Epoch 351/500\n",
      "2/2 - 0s - loss: 1.4423 - mse: 1.4423\n",
      "Epoch 352/500\n",
      "2/2 - 0s - loss: 1.6083 - mse: 1.6083\n",
      "Epoch 353/500\n",
      "2/2 - 0s - loss: 3.1981 - mse: 3.1981\n",
      "Epoch 354/500\n",
      "2/2 - 0s - loss: 3.7283 - mse: 3.7283\n",
      "Epoch 355/500\n",
      "2/2 - 0s - loss: 2.2684 - mse: 2.2684\n",
      "Epoch 356/500\n",
      "2/2 - 0s - loss: 1.4677 - mse: 1.4677\n",
      "Epoch 357/500\n",
      "2/2 - 0s - loss: 1.6614 - mse: 1.6614\n",
      "Epoch 358/500\n",
      "2/2 - 0s - loss: 2.7599 - mse: 2.7599\n",
      "Epoch 359/500\n",
      "2/2 - 0s - loss: 2.1673 - mse: 2.1673\n",
      "Epoch 360/500\n",
      "2/2 - 0s - loss: 2.7076 - mse: 2.7076\n",
      "Epoch 361/500\n",
      "2/2 - 0s - loss: 2.8578 - mse: 2.8578\n",
      "Epoch 362/500\n",
      "2/2 - 0s - loss: 1.8902 - mse: 1.8902\n",
      "Epoch 363/500\n",
      "2/2 - 0s - loss: 1.5781 - mse: 1.5781\n",
      "Epoch 364/500\n",
      "2/2 - 0s - loss: 2.5803 - mse: 2.5803\n",
      "Epoch 365/500\n",
      "2/2 - 0s - loss: 3.4570 - mse: 3.4570\n",
      "Epoch 366/500\n",
      "2/2 - 0s - loss: 2.5299 - mse: 2.5299\n",
      "Epoch 367/500\n",
      "2/2 - 0s - loss: 1.8205 - mse: 1.8205\n",
      "Epoch 368/500\n",
      "2/2 - 0s - loss: 1.7814 - mse: 1.7814\n",
      "Epoch 369/500\n",
      "2/2 - 0s - loss: 1.8390 - mse: 1.8390\n",
      "Epoch 370/500\n",
      "2/2 - 0s - loss: 2.2629 - mse: 2.2629\n",
      "Epoch 371/500\n",
      "2/2 - 0s - loss: 1.9600 - mse: 1.9600\n",
      "Epoch 372/500\n",
      "2/2 - 0s - loss: 1.7057 - mse: 1.7057\n",
      "Epoch 373/500\n",
      "2/2 - 0s - loss: 1.5173 - mse: 1.5173\n",
      "Epoch 374/500\n",
      "2/2 - 0s - loss: 1.4759 - mse: 1.4759\n",
      "Epoch 375/500\n",
      "2/2 - 0s - loss: 2.1937 - mse: 2.1937\n",
      "Epoch 376/500\n",
      "2/2 - 0s - loss: 2.6870 - mse: 2.6870\n",
      "Epoch 377/500\n",
      "2/2 - 0s - loss: 1.3733 - mse: 1.3733\n",
      "Epoch 378/500\n",
      "2/2 - 0s - loss: 1.4034 - mse: 1.4034\n",
      "Epoch 379/500\n",
      "2/2 - 0s - loss: 1.4139 - mse: 1.4139\n",
      "Epoch 380/500\n",
      "2/2 - 0s - loss: 1.9314 - mse: 1.9314\n",
      "Epoch 381/500\n",
      "2/2 - 0s - loss: 4.3636 - mse: 4.3636\n",
      "Epoch 382/500\n",
      "2/2 - 0s - loss: 2.3722 - mse: 2.3722\n",
      "Epoch 383/500\n",
      "2/2 - 0s - loss: 2.3767 - mse: 2.3767\n",
      "Epoch 384/500\n",
      "2/2 - 0s - loss: 1.6074 - mse: 1.6074\n",
      "Epoch 385/500\n",
      "2/2 - 0s - loss: 2.1645 - mse: 2.1645\n",
      "Epoch 386/500\n",
      "2/2 - 0s - loss: 2.2708 - mse: 2.2708\n",
      "Epoch 387/500\n",
      "2/2 - 0s - loss: 1.4762 - mse: 1.4762\n",
      "Epoch 388/500\n",
      "2/2 - 0s - loss: 1.4758 - mse: 1.4758\n",
      "Epoch 389/500\n",
      "2/2 - 0s - loss: 1.6405 - mse: 1.6405\n",
      "Epoch 390/500\n",
      "2/2 - 0s - loss: 2.2880 - mse: 2.2880\n",
      "Epoch 391/500\n",
      "2/2 - 0s - loss: 4.0030 - mse: 4.0030\n",
      "Epoch 392/500\n",
      "2/2 - 0s - loss: 1.8179 - mse: 1.8179\n",
      "Epoch 393/500\n",
      "2/2 - 0s - loss: 1.4745 - mse: 1.4745\n",
      "Epoch 394/500\n",
      "2/2 - 0s - loss: 1.8719 - mse: 1.8719\n",
      "Epoch 395/500\n",
      "2/2 - 0s - loss: 1.3810 - mse: 1.3810\n",
      "Epoch 396/500\n",
      "2/2 - 0s - loss: 1.5866 - mse: 1.5866\n",
      "Epoch 397/500\n",
      "2/2 - 0s - loss: 1.7748 - mse: 1.7748\n",
      "Epoch 398/500\n",
      "2/2 - 0s - loss: 1.4438 - mse: 1.4438\n",
      "Epoch 399/500\n",
      "2/2 - 0s - loss: 1.3838 - mse: 1.3838\n",
      "Epoch 400/500\n",
      "2/2 - 0s - loss: 2.2507 - mse: 2.2507\n",
      "Epoch 401/500\n",
      "2/2 - 0s - loss: 4.2567 - mse: 4.2567\n",
      "Epoch 402/500\n",
      "2/2 - 0s - loss: 1.6831 - mse: 1.6831\n",
      "Epoch 403/500\n",
      "2/2 - 0s - loss: 1.4047 - mse: 1.4047\n",
      "Epoch 404/500\n",
      "2/2 - 0s - loss: 2.5349 - mse: 2.5349\n",
      "Epoch 405/500\n",
      "2/2 - 0s - loss: 1.9768 - mse: 1.9768\n",
      "Epoch 406/500\n",
      "2/2 - 0s - loss: 1.6548 - mse: 1.6548\n",
      "Epoch 407/500\n",
      "2/2 - 0s - loss: 1.5139 - mse: 1.5139\n",
      "Epoch 408/500\n",
      "2/2 - 0s - loss: 1.4872 - mse: 1.4872\n",
      "Epoch 409/500\n",
      "2/2 - 0s - loss: 1.7120 - mse: 1.7120\n",
      "Epoch 410/500\n",
      "2/2 - 0s - loss: 3.8770 - mse: 3.8770\n",
      "Epoch 411/500\n",
      "2/2 - 0s - loss: 3.5471 - mse: 3.5471\n",
      "Epoch 412/500\n",
      "2/2 - 0s - loss: 1.4119 - mse: 1.4119\n",
      "Epoch 413/500\n",
      "2/2 - 0s - loss: 1.8320 - mse: 1.8320\n",
      "Epoch 414/500\n",
      "2/2 - 0s - loss: 1.7716 - mse: 1.7716\n",
      "Epoch 415/500\n",
      "2/2 - 0s - loss: 1.3225 - mse: 1.3225\n",
      "Epoch 416/500\n",
      "2/2 - 0s - loss: 1.4918 - mse: 1.4918\n",
      "Epoch 417/500\n",
      "2/2 - 0s - loss: 1.9759 - mse: 1.9759\n",
      "Epoch 418/500\n",
      "2/2 - 0s - loss: 1.8100 - mse: 1.8100\n",
      "Epoch 419/500\n",
      "2/2 - 0s - loss: 1.3533 - mse: 1.3533\n",
      "Epoch 420/500\n",
      "2/2 - 0s - loss: 1.5322 - mse: 1.5322\n",
      "Epoch 421/500\n",
      "2/2 - 0s - loss: 2.9323 - mse: 2.9323\n",
      "Epoch 422/500\n",
      "2/2 - 0s - loss: 3.2689 - mse: 3.2689\n",
      "Epoch 423/500\n",
      "2/2 - 0s - loss: 3.1904 - mse: 3.1904\n",
      "Epoch 424/500\n",
      "2/2 - 0s - loss: 1.8714 - mse: 1.8714\n",
      "Epoch 425/500\n",
      "2/2 - 0s - loss: 1.8669 - mse: 1.8669\n",
      "Epoch 426/500\n",
      "2/2 - 0s - loss: 1.8668 - mse: 1.8668\n",
      "Epoch 427/500\n",
      "2/2 - 0s - loss: 2.0565 - mse: 2.0565\n",
      "Epoch 428/500\n",
      "2/2 - 0s - loss: 2.4444 - mse: 2.4444\n",
      "Epoch 429/500\n",
      "2/2 - 0s - loss: 3.8698 - mse: 3.8698\n",
      "Epoch 430/500\n",
      "2/2 - 0s - loss: 1.9083 - mse: 1.9083\n",
      "Epoch 431/500\n",
      "2/2 - 0s - loss: 1.3809 - mse: 1.3809\n",
      "Epoch 432/500\n",
      "2/2 - 0s - loss: 1.6854 - mse: 1.6854\n",
      "Epoch 433/500\n",
      "2/2 - 0s - loss: 1.3314 - mse: 1.3314\n",
      "Epoch 434/500\n",
      "2/2 - 0s - loss: 1.7508 - mse: 1.7508\n",
      "Epoch 435/500\n",
      "2/2 - 0s - loss: 1.2956 - mse: 1.2956\n",
      "Epoch 436/500\n",
      "2/2 - 0s - loss: 1.6914 - mse: 1.6914\n",
      "Epoch 437/500\n",
      "2/2 - 0s - loss: 3.5051 - mse: 3.5051\n",
      "Epoch 438/500\n",
      "2/2 - 0s - loss: 1.9453 - mse: 1.9453\n",
      "Epoch 439/500\n",
      "2/2 - 0s - loss: 1.3371 - mse: 1.3371\n",
      "Epoch 440/500\n",
      "2/2 - 0s - loss: 1.3250 - mse: 1.3250\n",
      "Epoch 441/500\n",
      "2/2 - 0s - loss: 1.2787 - mse: 1.2787\n",
      "Epoch 442/500\n",
      "2/2 - 0s - loss: 1.3188 - mse: 1.3188\n",
      "Epoch 443/500\n",
      "2/2 - 0s - loss: 1.4888 - mse: 1.4888\n",
      "Epoch 444/500\n",
      "2/2 - 0s - loss: 2.9269 - mse: 2.9269\n",
      "Epoch 445/500\n",
      "2/2 - 0s - loss: 2.9542 - mse: 2.9542\n",
      "Epoch 446/500\n",
      "2/2 - 0s - loss: 2.9894 - mse: 2.9894\n",
      "Epoch 447/500\n",
      "2/2 - 0s - loss: 1.4386 - mse: 1.4386\n",
      "Epoch 448/500\n",
      "2/2 - 0s - loss: 1.2782 - mse: 1.2782\n",
      "Epoch 449/500\n",
      "2/2 - 0s - loss: 1.2740 - mse: 1.2740\n",
      "Epoch 450/500\n",
      "2/2 - 0s - loss: 2.0145 - mse: 2.0145\n",
      "Epoch 451/500\n",
      "2/2 - 0s - loss: 2.0134 - mse: 2.0134\n",
      "Epoch 452/500\n",
      "2/2 - 0s - loss: 2.1324 - mse: 2.1324\n",
      "Epoch 453/500\n",
      "2/2 - 0s - loss: 1.7974 - mse: 1.7974\n",
      "Epoch 454/500\n",
      "2/2 - 0s - loss: 1.3277 - mse: 1.3277\n",
      "Epoch 455/500\n",
      "2/2 - 0s - loss: 3.6835 - mse: 3.6835\n",
      "Epoch 456/500\n",
      "2/2 - 0s - loss: 2.8579 - mse: 2.8579\n",
      "Epoch 457/500\n",
      "2/2 - 0s - loss: 1.2876 - mse: 1.2876\n",
      "Epoch 458/500\n",
      "2/2 - 0s - loss: 1.2611 - mse: 1.2611\n",
      "Epoch 459/500\n",
      "2/2 - 0s - loss: 1.2589 - mse: 1.2589\n",
      "Epoch 460/500\n",
      "2/2 - 0s - loss: 3.2791 - mse: 3.2791\n",
      "Epoch 461/500\n",
      "2/2 - 0s - loss: 2.9462 - mse: 2.9462\n",
      "Epoch 462/500\n",
      "2/2 - 0s - loss: 1.3107 - mse: 1.3107\n",
      "Epoch 463/500\n",
      "2/2 - 0s - loss: 1.2733 - mse: 1.2733\n",
      "Epoch 464/500\n",
      "2/2 - 0s - loss: 1.2803 - mse: 1.2803\n",
      "Epoch 465/500\n",
      "2/2 - 0s - loss: 1.2955 - mse: 1.2955\n",
      "Epoch 466/500\n",
      "2/2 - 0s - loss: 1.2444 - mse: 1.2444\n",
      "Epoch 467/500\n",
      "2/2 - 0s - loss: 1.2491 - mse: 1.2491\n",
      "Epoch 468/500\n",
      "2/2 - 0s - loss: 1.6539 - mse: 1.6539\n",
      "Epoch 469/500\n",
      "2/2 - 0s - loss: 5.4521 - mse: 5.4521\n",
      "Epoch 470/500\n",
      "2/2 - 0s - loss: 1.2927 - mse: 1.2927\n",
      "Epoch 471/500\n",
      "2/2 - 0s - loss: 1.4821 - mse: 1.4821\n",
      "Epoch 472/500\n",
      "2/2 - 0s - loss: 1.3442 - mse: 1.3442\n",
      "Epoch 473/500\n",
      "2/2 - 0s - loss: 2.0089 - mse: 2.0089\n",
      "Epoch 474/500\n",
      "2/2 - 0s - loss: 3.5968 - mse: 3.5968\n",
      "Epoch 475/500\n",
      "2/2 - 0s - loss: 1.7476 - mse: 1.7476\n",
      "Epoch 476/500\n",
      "2/2 - 0s - loss: 1.2767 - mse: 1.2767\n",
      "Epoch 477/500\n",
      "2/2 - 0s - loss: 1.2604 - mse: 1.2604\n",
      "Epoch 478/500\n",
      "2/2 - 0s - loss: 1.6081 - mse: 1.6081\n",
      "Epoch 479/500\n",
      "2/2 - 0s - loss: 2.5080 - mse: 2.5080\n",
      "Epoch 480/500\n",
      "2/2 - 0s - loss: 2.3013 - mse: 2.3013\n",
      "Epoch 481/500\n",
      "2/2 - 0s - loss: 1.5792 - mse: 1.5792\n",
      "Epoch 482/500\n",
      "2/2 - 0s - loss: 1.2281 - mse: 1.2281\n",
      "Epoch 483/500\n",
      "2/2 - 0s - loss: 1.4278 - mse: 1.4278\n",
      "Epoch 484/500\n",
      "2/2 - 0s - loss: 1.5902 - mse: 1.5902\n",
      "Epoch 485/500\n",
      "2/2 - 0s - loss: 1.2012 - mse: 1.2012\n",
      "Epoch 486/500\n",
      "2/2 - 0s - loss: 1.3797 - mse: 1.3797\n",
      "Epoch 487/500\n",
      "2/2 - 0s - loss: 2.1690 - mse: 2.1690\n",
      "Epoch 488/500\n",
      "2/2 - 0s - loss: 2.6328 - mse: 2.6328\n",
      "Epoch 489/500\n",
      "2/2 - 0s - loss: 1.2191 - mse: 1.2191\n",
      "Epoch 490/500\n",
      "2/2 - 0s - loss: 1.4258 - mse: 1.4258\n",
      "Epoch 491/500\n",
      "2/2 - 0s - loss: 2.5756 - mse: 2.5756\n",
      "Epoch 492/500\n",
      "2/2 - 0s - loss: 3.8859 - mse: 3.8859\n",
      "Epoch 493/500\n",
      "2/2 - 0s - loss: 2.4327 - mse: 2.4327\n",
      "Epoch 494/500\n",
      "2/2 - 0s - loss: 1.6529 - mse: 1.6529\n",
      "Epoch 495/500\n",
      "2/2 - 0s - loss: 1.4519 - mse: 1.4519\n",
      "Epoch 496/500\n",
      "2/2 - 0s - loss: 1.2529 - mse: 1.2529\n",
      "Epoch 497/500\n",
      "2/2 - 0s - loss: 1.4874 - mse: 1.4874\n",
      "Epoch 498/500\n",
      "2/2 - 0s - loss: 1.8867 - mse: 1.8867\n",
      "Epoch 499/500\n",
      "2/2 - 0s - loss: 4.3094 - mse: 4.3094\n",
      "Epoch 500/500\n",
      "2/2 - 0s - loss: 2.4183 - mse: 2.4183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17dff6b80>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observe the numbers for the `weights`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.15157871,  0.15006189, -0.14974315],\n",
       "        [ 0.29294756,  0.29112825, -0.2907222 ],\n",
       "        [ 0.21797644,  0.21632607, -0.21596937],\n",
       "        [ 0.31826466,  0.31647795, -0.3160798 ],\n",
       "        [-0.00179686, -0.00092771,  0.00065475],\n",
       "        [ 0.01179831,  0.01225254, -0.01242991]], dtype=float32),\n",
       " array([ 0.13434592,  0.13393463, -0.13389426], dtype=float32),\n",
       " array([[ 0.24216445],\n",
       "        [ 0.49543723],\n",
       "        [-0.75170743]], dtype=float32),\n",
       " array([0.13389555], dtype=float32)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros_after_fit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>18.889677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>18.213333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>18.270931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>22.034506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>13.092728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros_after_fit\n",
       "abbrev                             \n",
       "AL       18.8             18.889677\n",
       "AK       18.1             18.213333\n",
       "AZ       18.6             18.270931\n",
       "AR       22.4             22.034506\n",
       "CA       12.0             13.092728"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsel = df[['total']].copy()\n",
    "dfsel['pred_zeros_after_fit'] = y_pred\n",
    "dfsel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 - 0s - loss: 138470.4219 - mse: 138470.4219 - 280ms/epoch - 140ms/step\n",
      "Epoch 2/500\n",
      "2/2 - 0s - loss: 128906.5469 - mse: 128906.5469 - 3ms/epoch - 2ms/step\n",
      "Epoch 3/500\n",
      "2/2 - 0s - loss: 122611.1953 - mse: 122611.1953 - 3ms/epoch - 1ms/step\n",
      "Epoch 4/500\n",
      "2/2 - 0s - loss: 117505.8828 - mse: 117505.8906 - 2ms/epoch - 995us/step\n",
      "Epoch 5/500\n",
      "2/2 - 0s - loss: 112954.6875 - mse: 112954.6875 - 3ms/epoch - 1ms/step\n",
      "Epoch 6/500\n",
      "2/2 - 0s - loss: 108741.2734 - mse: 108741.2734 - 2ms/epoch - 1ms/step\n",
      "Epoch 7/500\n",
      "2/2 - 0s - loss: 104877.2422 - mse: 104877.2422 - 3ms/epoch - 2ms/step\n",
      "Epoch 8/500\n",
      "2/2 - 0s - loss: 101275.9688 - mse: 101275.9688 - 3ms/epoch - 2ms/step\n",
      "Epoch 9/500\n",
      "2/2 - 0s - loss: 97826.2188 - mse: 97826.2188 - 3ms/epoch - 2ms/step\n",
      "Epoch 10/500\n",
      "2/2 - 0s - loss: 94505.4531 - mse: 94505.4531 - 3ms/epoch - 2ms/step\n",
      "Epoch 11/500\n",
      "2/2 - 0s - loss: 91268.3984 - mse: 91268.3984 - 3ms/epoch - 2ms/step\n",
      "Epoch 12/500\n",
      "2/2 - 0s - loss: 88062.6953 - mse: 88062.7031 - 4ms/epoch - 2ms/step\n",
      "Epoch 13/500\n",
      "2/2 - 0s - loss: 85006.1094 - mse: 85006.1094 - 2ms/epoch - 1ms/step\n",
      "Epoch 14/500\n",
      "2/2 - 0s - loss: 82017.3594 - mse: 82017.3594 - 2ms/epoch - 1ms/step\n",
      "Epoch 15/500\n",
      "2/2 - 0s - loss: 79121.2734 - mse: 79121.2734 - 2ms/epoch - 1ms/step\n",
      "Epoch 16/500\n",
      "2/2 - 0s - loss: 76302.2188 - mse: 76302.2188 - 3ms/epoch - 2ms/step\n",
      "Epoch 17/500\n",
      "2/2 - 0s - loss: 73539.8047 - mse: 73539.8047 - 2ms/epoch - 1000us/step\n",
      "Epoch 18/500\n",
      "2/2 - 0s - loss: 70828.3906 - mse: 70828.3906 - 2ms/epoch - 1ms/step\n",
      "Epoch 19/500\n",
      "2/2 - 0s - loss: 68164.0234 - mse: 68164.0234 - 3ms/epoch - 1ms/step\n",
      "Epoch 20/500\n",
      "2/2 - 0s - loss: 65561.7578 - mse: 65561.7578 - 3ms/epoch - 2ms/step\n",
      "Epoch 21/500\n",
      "2/2 - 0s - loss: 63024.7617 - mse: 63024.7617 - 2ms/epoch - 1ms/step\n",
      "Epoch 22/500\n",
      "2/2 - 0s - loss: 60532.1289 - mse: 60532.1289 - 3ms/epoch - 2ms/step\n",
      "Epoch 23/500\n",
      "2/2 - 0s - loss: 58066.9688 - mse: 58066.9688 - 4ms/epoch - 2ms/step\n",
      "Epoch 24/500\n",
      "2/2 - 0s - loss: 55632.3711 - mse: 55632.3711 - 3ms/epoch - 2ms/step\n",
      "Epoch 25/500\n",
      "2/2 - 0s - loss: 53338.6719 - mse: 53338.6719 - 3ms/epoch - 1ms/step\n",
      "Epoch 26/500\n",
      "2/2 - 0s - loss: 51098.6016 - mse: 51098.6016 - 3ms/epoch - 2ms/step\n",
      "Epoch 27/500\n",
      "2/2 - 0s - loss: 48882.6953 - mse: 48882.6953 - 3ms/epoch - 1ms/step\n",
      "Epoch 28/500\n",
      "2/2 - 0s - loss: 46725.8594 - mse: 46725.8633 - 2ms/epoch - 1ms/step\n",
      "Epoch 29/500\n",
      "2/2 - 0s - loss: 44621.4805 - mse: 44621.4805 - 3ms/epoch - 1ms/step\n",
      "Epoch 30/500\n",
      "2/2 - 0s - loss: 42583.2656 - mse: 42583.2656 - 4ms/epoch - 2ms/step\n",
      "Epoch 31/500\n",
      "2/2 - 0s - loss: 40589.1406 - mse: 40589.1406 - 3ms/epoch - 2ms/step\n",
      "Epoch 32/500\n",
      "2/2 - 0s - loss: 38623.9297 - mse: 38623.9297 - 3ms/epoch - 1ms/step\n",
      "Epoch 33/500\n",
      "2/2 - 0s - loss: 36695.5820 - mse: 36695.5820 - 3ms/epoch - 1ms/step\n",
      "Epoch 34/500\n",
      "2/2 - 0s - loss: 34824.9375 - mse: 34824.9375 - 2ms/epoch - 1ms/step\n",
      "Epoch 35/500\n",
      "2/2 - 0s - loss: 33046.1484 - mse: 33046.1484 - 3ms/epoch - 1ms/step\n",
      "Epoch 36/500\n",
      "2/2 - 0s - loss: 31289.2031 - mse: 31289.2031 - 2ms/epoch - 999us/step\n",
      "Epoch 37/500\n",
      "2/2 - 0s - loss: 29565.3477 - mse: 29565.3477 - 2ms/epoch - 973us/step\n",
      "Epoch 38/500\n",
      "2/2 - 0s - loss: 27920.3770 - mse: 27920.3770 - 3ms/epoch - 1ms/step\n",
      "Epoch 39/500\n",
      "2/2 - 0s - loss: 26311.8262 - mse: 26311.8262 - 3ms/epoch - 2ms/step\n",
      "Epoch 40/500\n",
      "2/2 - 0s - loss: 24737.8379 - mse: 24737.8379 - 2ms/epoch - 970us/step\n",
      "Epoch 41/500\n",
      "2/2 - 0s - loss: 23202.1660 - mse: 23202.1660 - 3ms/epoch - 2ms/step\n",
      "Epoch 42/500\n",
      "2/2 - 0s - loss: 21737.3145 - mse: 21737.3145 - 3ms/epoch - 1ms/step\n",
      "Epoch 43/500\n",
      "2/2 - 0s - loss: 20333.7520 - mse: 20333.7520 - 3ms/epoch - 2ms/step\n",
      "Epoch 44/500\n",
      "2/2 - 0s - loss: 18992.3535 - mse: 18992.3535 - 2ms/epoch - 972us/step\n",
      "Epoch 45/500\n",
      "2/2 - 0s - loss: 17710.6562 - mse: 17710.6562 - 2ms/epoch - 1ms/step\n",
      "Epoch 46/500\n",
      "2/2 - 0s - loss: 16475.1660 - mse: 16475.1660 - 3ms/epoch - 2ms/step\n",
      "Epoch 47/500\n",
      "2/2 - 0s - loss: 15286.9561 - mse: 15286.9561 - 3ms/epoch - 1ms/step\n",
      "Epoch 48/500\n",
      "2/2 - 0s - loss: 14156.2451 - mse: 14156.2451 - 2ms/epoch - 972us/step\n",
      "Epoch 49/500\n",
      "2/2 - 0s - loss: 13050.8555 - mse: 13050.8555 - 2ms/epoch - 1ms/step\n",
      "Epoch 50/500\n",
      "2/2 - 0s - loss: 11993.4561 - mse: 11993.4561 - 3ms/epoch - 2ms/step\n",
      "Epoch 51/500\n",
      "2/2 - 0s - loss: 10994.9658 - mse: 10994.9658 - 3ms/epoch - 2ms/step\n",
      "Epoch 52/500\n",
      "2/2 - 0s - loss: 10040.7578 - mse: 10040.7578 - 3ms/epoch - 1ms/step\n",
      "Epoch 53/500\n",
      "2/2 - 0s - loss: 9144.1426 - mse: 9144.1426 - 3ms/epoch - 2ms/step\n",
      "Epoch 54/500\n",
      "2/2 - 0s - loss: 8297.7705 - mse: 8297.7705 - 2ms/epoch - 1ms/step\n",
      "Epoch 55/500\n",
      "2/2 - 0s - loss: 7501.9727 - mse: 7501.9727 - 4ms/epoch - 2ms/step\n",
      "Epoch 56/500\n",
      "2/2 - 0s - loss: 6757.6699 - mse: 6757.6699 - 4ms/epoch - 2ms/step\n",
      "Epoch 57/500\n",
      "2/2 - 0s - loss: 6060.0977 - mse: 6060.0977 - 3ms/epoch - 1ms/step\n",
      "Epoch 58/500\n",
      "2/2 - 0s - loss: 5399.9155 - mse: 5399.9155 - 3ms/epoch - 1ms/step\n",
      "Epoch 59/500\n",
      "2/2 - 0s - loss: 4777.9004 - mse: 4777.9004 - 4ms/epoch - 2ms/step\n",
      "Epoch 60/500\n",
      "2/2 - 0s - loss: 4210.0586 - mse: 4210.0586 - 2ms/epoch - 1ms/step\n",
      "Epoch 61/500\n",
      "2/2 - 0s - loss: 3690.7581 - mse: 3690.7581 - 2ms/epoch - 998us/step\n",
      "Epoch 62/500\n",
      "2/2 - 0s - loss: 3208.8945 - mse: 3208.8945 - 3ms/epoch - 1ms/step\n",
      "Epoch 63/500\n",
      "2/2 - 0s - loss: 2763.9565 - mse: 2763.9568 - 2ms/epoch - 1ms/step\n",
      "Epoch 64/500\n",
      "2/2 - 0s - loss: 2366.1614 - mse: 2366.1614 - 2ms/epoch - 1ms/step\n",
      "Epoch 65/500\n",
      "2/2 - 0s - loss: 2004.6382 - mse: 2004.6382 - 3ms/epoch - 2ms/step\n",
      "Epoch 66/500\n",
      "2/2 - 0s - loss: 1681.6136 - mse: 1681.6136 - 3ms/epoch - 1ms/step\n",
      "Epoch 67/500\n",
      "2/2 - 0s - loss: 1397.0455 - mse: 1397.0455 - 2ms/epoch - 1ms/step\n",
      "Epoch 68/500\n",
      "2/2 - 0s - loss: 1150.0864 - mse: 1150.0864 - 2ms/epoch - 1ms/step\n",
      "Epoch 69/500\n",
      "2/2 - 0s - loss: 939.7429 - mse: 939.7429 - 3ms/epoch - 1ms/step\n",
      "Epoch 70/500\n",
      "2/2 - 0s - loss: 757.2774 - mse: 757.2774 - 4ms/epoch - 2ms/step\n",
      "Epoch 71/500\n",
      "2/2 - 0s - loss: 602.2896 - mse: 602.2896 - 2ms/epoch - 1ms/step\n",
      "Epoch 72/500\n",
      "2/2 - 0s - loss: 474.9796 - mse: 474.9796 - 3ms/epoch - 1ms/step\n",
      "Epoch 73/500\n",
      "2/2 - 0s - loss: 371.7102 - mse: 371.7102 - 2ms/epoch - 1ms/step\n",
      "Epoch 74/500\n",
      "2/2 - 0s - loss: 289.8520 - mse: 289.8520 - 2ms/epoch - 1ms/step\n",
      "Epoch 75/500\n",
      "2/2 - 0s - loss: 224.5910 - mse: 224.5910 - 2ms/epoch - 980us/step\n",
      "Epoch 76/500\n",
      "2/2 - 0s - loss: 177.1088 - mse: 177.1088 - 3ms/epoch - 2ms/step\n",
      "Epoch 77/500\n",
      "2/2 - 0s - loss: 144.4401 - mse: 144.4401 - 948us/epoch - 474us/step\n",
      "Epoch 78/500\n",
      "2/2 - 0s - loss: 122.3640 - mse: 122.3640 - 4ms/epoch - 2ms/step\n",
      "Epoch 79/500\n",
      "2/2 - 0s - loss: 106.8639 - mse: 106.8639 - 3ms/epoch - 2ms/step\n",
      "Epoch 80/500\n",
      "2/2 - 0s - loss: 96.5951 - mse: 96.5951 - 3ms/epoch - 1ms/step\n",
      "Epoch 81/500\n",
      "2/2 - 0s - loss: 90.7576 - mse: 90.7576 - 2ms/epoch - 1ms/step\n",
      "Epoch 82/500\n",
      "2/2 - 0s - loss: 88.7668 - mse: 88.7668 - 3ms/epoch - 2ms/step\n",
      "Epoch 83/500\n",
      "2/2 - 0s - loss: 86.1013 - mse: 86.1013 - 3ms/epoch - 1ms/step\n",
      "Epoch 84/500\n",
      "2/2 - 0s - loss: 86.2339 - mse: 86.2339 - 2ms/epoch - 977us/step\n",
      "Epoch 85/500\n",
      "2/2 - 0s - loss: 85.9240 - mse: 85.9240 - 4ms/epoch - 2ms/step\n",
      "Epoch 86/500\n",
      "2/2 - 0s - loss: 85.3766 - mse: 85.3766 - 2ms/epoch - 1ms/step\n",
      "Epoch 87/500\n",
      "2/2 - 0s - loss: 85.2857 - mse: 85.2857 - 2ms/epoch - 1ms/step\n",
      "Epoch 88/500\n",
      "2/2 - 0s - loss: 84.9340 - mse: 84.9340 - 3ms/epoch - 1ms/step\n",
      "Epoch 89/500\n",
      "2/2 - 0s - loss: 84.6894 - mse: 84.6894 - 3ms/epoch - 1ms/step\n",
      "Epoch 90/500\n",
      "2/2 - 0s - loss: 84.8312 - mse: 84.8312 - 2ms/epoch - 1ms/step\n",
      "Epoch 91/500\n",
      "2/2 - 0s - loss: 84.5725 - mse: 84.5725 - 3ms/epoch - 1ms/step\n",
      "Epoch 92/500\n",
      "2/2 - 0s - loss: 84.2493 - mse: 84.2493 - 4ms/epoch - 2ms/step\n",
      "Epoch 93/500\n",
      "2/2 - 0s - loss: 83.6157 - mse: 83.6157 - 3ms/epoch - 2ms/step\n",
      "Epoch 94/500\n",
      "2/2 - 0s - loss: 83.0709 - mse: 83.0709 - 3ms/epoch - 1ms/step\n",
      "Epoch 95/500\n",
      "2/2 - 0s - loss: 90.8578 - mse: 90.8578 - 2ms/epoch - 1ms/step\n",
      "Epoch 96/500\n",
      "2/2 - 0s - loss: 85.1197 - mse: 85.1197 - 3ms/epoch - 1ms/step\n",
      "Epoch 97/500\n",
      "2/2 - 0s - loss: 82.0178 - mse: 82.0178 - 2ms/epoch - 954us/step\n",
      "Epoch 98/500\n",
      "2/2 - 0s - loss: 81.3555 - mse: 81.3555 - 3ms/epoch - 2ms/step\n",
      "Epoch 99/500\n",
      "2/2 - 0s - loss: 80.4320 - mse: 80.4320 - 2ms/epoch - 985us/step\n",
      "Epoch 100/500\n",
      "2/2 - 0s - loss: 80.9144 - mse: 80.9144 - 3ms/epoch - 2ms/step\n",
      "Epoch 101/500\n",
      "2/2 - 0s - loss: 80.5075 - mse: 80.5075 - 2ms/epoch - 1ms/step\n",
      "Epoch 102/500\n",
      "2/2 - 0s - loss: 81.1389 - mse: 81.1389 - 3ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/500\n",
      "2/2 - 0s - loss: 79.6693 - mse: 79.6693 - 2ms/epoch - 1ms/step\n",
      "Epoch 104/500\n",
      "2/2 - 0s - loss: 86.8442 - mse: 86.8442 - 3ms/epoch - 1ms/step\n",
      "Epoch 105/500\n",
      "2/2 - 0s - loss: 80.9263 - mse: 80.9263 - 2ms/epoch - 973us/step\n",
      "Epoch 106/500\n",
      "2/2 - 0s - loss: 76.0352 - mse: 76.0352 - 2ms/epoch - 1ms/step\n",
      "Epoch 107/500\n",
      "2/2 - 0s - loss: 75.9283 - mse: 75.9283 - 2ms/epoch - 996us/step\n",
      "Epoch 108/500\n",
      "2/2 - 0s - loss: 77.9791 - mse: 77.9791 - 3ms/epoch - 1ms/step\n",
      "Epoch 109/500\n",
      "2/2 - 0s - loss: 74.1040 - mse: 74.1040 - 2ms/epoch - 1ms/step\n",
      "Epoch 110/500\n",
      "2/2 - 0s - loss: 74.6254 - mse: 74.6254 - 2ms/epoch - 989us/step\n",
      "Epoch 111/500\n",
      "2/2 - 0s - loss: 81.8334 - mse: 81.8334 - 2ms/epoch - 1ms/step\n",
      "Epoch 112/500\n",
      "2/2 - 0s - loss: 73.2889 - mse: 73.2889 - 2ms/epoch - 978us/step\n",
      "Epoch 113/500\n",
      "2/2 - 0s - loss: 72.0271 - mse: 72.0271 - 3ms/epoch - 1ms/step\n",
      "Epoch 114/500\n",
      "2/2 - 0s - loss: 75.9497 - mse: 75.9497 - 2ms/epoch - 1ms/step\n",
      "Epoch 115/500\n",
      "2/2 - 0s - loss: 76.5237 - mse: 76.5237 - 2ms/epoch - 977us/step\n",
      "Epoch 116/500\n",
      "2/2 - 0s - loss: 74.1500 - mse: 74.1500 - 3ms/epoch - 1ms/step\n",
      "Epoch 117/500\n",
      "2/2 - 0s - loss: 70.2021 - mse: 70.2021 - 2ms/epoch - 919us/step\n",
      "Epoch 118/500\n",
      "2/2 - 0s - loss: 67.7540 - mse: 67.7540 - 2ms/epoch - 1ms/step\n",
      "Epoch 119/500\n",
      "2/2 - 0s - loss: 67.9494 - mse: 67.9494 - 2ms/epoch - 810us/step\n",
      "Epoch 120/500\n",
      "2/2 - 0s - loss: 66.1174 - mse: 66.1174 - 3ms/epoch - 1ms/step\n",
      "Epoch 121/500\n",
      "2/2 - 0s - loss: 67.3652 - mse: 67.3652 - 2ms/epoch - 1ms/step\n",
      "Epoch 122/500\n",
      "2/2 - 0s - loss: 66.2723 - mse: 66.2723 - 3ms/epoch - 1ms/step\n",
      "Epoch 123/500\n",
      "2/2 - 0s - loss: 66.4935 - mse: 66.4935 - 3ms/epoch - 2ms/step\n",
      "Epoch 124/500\n",
      "2/2 - 0s - loss: 68.3756 - mse: 68.3756 - 2ms/epoch - 976us/step\n",
      "Epoch 125/500\n",
      "2/2 - 0s - loss: 63.7639 - mse: 63.7639 - 952us/epoch - 476us/step\n",
      "Epoch 126/500\n",
      "2/2 - 0s - loss: 62.3741 - mse: 62.3741 - 986us/epoch - 493us/step\n",
      "Epoch 127/500\n",
      "2/2 - 0s - loss: 66.1819 - mse: 66.1819 - 3ms/epoch - 1ms/step\n",
      "Epoch 128/500\n",
      "2/2 - 0s - loss: 64.3510 - mse: 64.3510 - 2ms/epoch - 972us/step\n",
      "Epoch 129/500\n",
      "2/2 - 0s - loss: 61.8545 - mse: 61.8545 - 2ms/epoch - 988us/step\n",
      "Epoch 130/500\n",
      "2/2 - 0s - loss: 65.3872 - mse: 65.3872 - 2ms/epoch - 993us/step\n",
      "Epoch 131/500\n",
      "2/2 - 0s - loss: 63.6499 - mse: 63.6499 - 2ms/epoch - 1ms/step\n",
      "Epoch 132/500\n",
      "2/2 - 0s - loss: 68.8074 - mse: 68.8074 - 3ms/epoch - 1ms/step\n",
      "Epoch 133/500\n",
      "2/2 - 0s - loss: 59.2559 - mse: 59.2559 - 2ms/epoch - 1000us/step\n",
      "Epoch 134/500\n",
      "2/2 - 0s - loss: 61.2410 - mse: 61.2410 - 3ms/epoch - 1ms/step\n",
      "Epoch 135/500\n",
      "2/2 - 0s - loss: 63.6631 - mse: 63.6631 - 2ms/epoch - 992us/step\n",
      "Epoch 136/500\n",
      "2/2 - 0s - loss: 57.4080 - mse: 57.4080 - 2ms/epoch - 1ms/step\n",
      "Epoch 137/500\n",
      "2/2 - 0s - loss: 59.9087 - mse: 59.9087 - 2ms/epoch - 1ms/step\n",
      "Epoch 138/500\n",
      "2/2 - 0s - loss: 55.5174 - mse: 55.5174 - 2ms/epoch - 972us/step\n",
      "Epoch 139/500\n",
      "2/2 - 0s - loss: 55.5570 - mse: 55.5570 - 3ms/epoch - 2ms/step\n",
      "Epoch 140/500\n",
      "2/2 - 0s - loss: 64.6790 - mse: 64.6790 - 2ms/epoch - 1ms/step\n",
      "Epoch 141/500\n",
      "2/2 - 0s - loss: 54.6545 - mse: 54.6545 - 2ms/epoch - 971us/step\n",
      "Epoch 142/500\n",
      "2/2 - 0s - loss: 54.0636 - mse: 54.0636 - 2ms/epoch - 1000us/step\n",
      "Epoch 143/500\n",
      "2/2 - 0s - loss: 52.5948 - mse: 52.5948 - 3ms/epoch - 1ms/step\n",
      "Epoch 144/500\n",
      "2/2 - 0s - loss: 52.4938 - mse: 52.4938 - 2ms/epoch - 1ms/step\n",
      "Epoch 145/500\n",
      "2/2 - 0s - loss: 52.8479 - mse: 52.8479 - 2ms/epoch - 1ms/step\n",
      "Epoch 146/500\n",
      "2/2 - 0s - loss: 51.4400 - mse: 51.4400 - 2ms/epoch - 1000us/step\n",
      "Epoch 147/500\n",
      "2/2 - 0s - loss: 51.6325 - mse: 51.6325 - 2ms/epoch - 966us/step\n",
      "Epoch 148/500\n",
      "2/2 - 0s - loss: 49.5482 - mse: 49.5482 - 2ms/epoch - 1ms/step\n",
      "Epoch 149/500\n",
      "2/2 - 0s - loss: 52.6188 - mse: 52.6188 - 2ms/epoch - 993us/step\n",
      "Epoch 150/500\n",
      "2/2 - 0s - loss: 48.6539 - mse: 48.6539 - 2ms/epoch - 975us/step\n",
      "Epoch 151/500\n",
      "2/2 - 0s - loss: 52.8466 - mse: 52.8466 - 954us/epoch - 477us/step\n",
      "Epoch 152/500\n",
      "2/2 - 0s - loss: 53.7320 - mse: 53.7320 - 2ms/epoch - 1ms/step\n",
      "Epoch 153/500\n",
      "2/2 - 0s - loss: 50.6019 - mse: 50.6019 - 2ms/epoch - 1ms/step\n",
      "Epoch 154/500\n",
      "2/2 - 0s - loss: 52.2178 - mse: 52.2178 - 3ms/epoch - 1ms/step\n",
      "Epoch 155/500\n",
      "2/2 - 0s - loss: 49.5869 - mse: 49.5869 - 935us/epoch - 467us/step\n",
      "Epoch 156/500\n",
      "2/2 - 0s - loss: 48.9580 - mse: 48.9580 - 2ms/epoch - 969us/step\n",
      "Epoch 157/500\n",
      "2/2 - 0s - loss: 52.6157 - mse: 52.6157 - 952us/epoch - 476us/step\n",
      "Epoch 158/500\n",
      "2/2 - 0s - loss: 47.2254 - mse: 47.2254 - 2ms/epoch - 999us/step\n",
      "Epoch 159/500\n",
      "2/2 - 0s - loss: 46.5067 - mse: 46.5067 - 2ms/epoch - 1ms/step\n",
      "Epoch 160/500\n",
      "2/2 - 0s - loss: 45.4288 - mse: 45.4288 - 2ms/epoch - 1ms/step\n",
      "Epoch 161/500\n",
      "2/2 - 0s - loss: 45.1422 - mse: 45.1422 - 3ms/epoch - 1ms/step\n",
      "Epoch 162/500\n",
      "2/2 - 0s - loss: 51.9644 - mse: 51.9644 - 2ms/epoch - 1ms/step\n",
      "Epoch 163/500\n",
      "2/2 - 0s - loss: 43.3710 - mse: 43.3710 - 2ms/epoch - 1ms/step\n",
      "Epoch 164/500\n",
      "2/2 - 0s - loss: 42.1561 - mse: 42.1561 - 1ms/epoch - 710us/step\n",
      "Epoch 165/500\n",
      "2/2 - 0s - loss: 42.3033 - mse: 42.3033 - 2ms/epoch - 1ms/step\n",
      "Epoch 166/500\n",
      "2/2 - 0s - loss: 42.4503 - mse: 42.4503 - 2ms/epoch - 982us/step\n",
      "Epoch 167/500\n",
      "2/2 - 0s - loss: 43.6700 - mse: 43.6700 - 2ms/epoch - 998us/step\n",
      "Epoch 168/500\n",
      "2/2 - 0s - loss: 55.8205 - mse: 55.8205 - 2ms/epoch - 1ms/step\n",
      "Epoch 169/500\n",
      "2/2 - 0s - loss: 41.1048 - mse: 41.1048 - 3ms/epoch - 1ms/step\n",
      "Epoch 170/500\n",
      "2/2 - 0s - loss: 41.6617 - mse: 41.6617 - 4ms/epoch - 2ms/step\n",
      "Epoch 171/500\n",
      "2/2 - 0s - loss: 43.6869 - mse: 43.6869 - 3ms/epoch - 1ms/step\n",
      "Epoch 172/500\n",
      "2/2 - 0s - loss: 41.0047 - mse: 41.0047 - 3ms/epoch - 1ms/step\n",
      "Epoch 173/500\n",
      "2/2 - 0s - loss: 38.6272 - mse: 38.6272 - 2ms/epoch - 1ms/step\n",
      "Epoch 174/500\n",
      "2/2 - 0s - loss: 48.0533 - mse: 48.0533 - 2ms/epoch - 976us/step\n",
      "Epoch 175/500\n",
      "2/2 - 0s - loss: 48.0700 - mse: 48.0700 - 2ms/epoch - 980us/step\n",
      "Epoch 176/500\n",
      "2/2 - 0s - loss: 39.3320 - mse: 39.3320 - 2ms/epoch - 1000us/step\n",
      "Epoch 177/500\n",
      "2/2 - 0s - loss: 41.3079 - mse: 41.3079 - 2ms/epoch - 1ms/step\n",
      "Epoch 178/500\n",
      "2/2 - 0s - loss: 36.8798 - mse: 36.8798 - 1000us/epoch - 500us/step\n",
      "Epoch 179/500\n",
      "2/2 - 0s - loss: 37.3310 - mse: 37.3310 - 2ms/epoch - 995us/step\n",
      "Epoch 180/500\n",
      "2/2 - 0s - loss: 36.2732 - mse: 36.2732 - 3ms/epoch - 2ms/step\n",
      "Epoch 181/500\n",
      "2/2 - 0s - loss: 36.2483 - mse: 36.2483 - 3ms/epoch - 2ms/step\n",
      "Epoch 182/500\n",
      "2/2 - 0s - loss: 39.2082 - mse: 39.2082 - 2ms/epoch - 1ms/step\n",
      "Epoch 183/500\n",
      "2/2 - 0s - loss: 34.7509 - mse: 34.7509 - 2ms/epoch - 1ms/step\n",
      "Epoch 184/500\n",
      "2/2 - 0s - loss: 34.6425 - mse: 34.6425 - 2ms/epoch - 1ms/step\n",
      "Epoch 185/500\n",
      "2/2 - 0s - loss: 33.9943 - mse: 33.9943 - 2ms/epoch - 986us/step\n",
      "Epoch 186/500\n",
      "2/2 - 0s - loss: 35.9516 - mse: 35.9516 - 2ms/epoch - 1ms/step\n",
      "Epoch 187/500\n",
      "2/2 - 0s - loss: 36.2018 - mse: 36.2018 - 2ms/epoch - 1ms/step\n",
      "Epoch 188/500\n",
      "2/2 - 0s - loss: 44.0790 - mse: 44.0790 - 2ms/epoch - 983us/step\n",
      "Epoch 189/500\n",
      "2/2 - 0s - loss: 36.2313 - mse: 36.2313 - 2ms/epoch - 992us/step\n",
      "Epoch 190/500\n",
      "2/2 - 0s - loss: 42.2173 - mse: 42.2173 - 3ms/epoch - 1ms/step\n",
      "Epoch 191/500\n",
      "2/2 - 0s - loss: 47.4306 - mse: 47.4306 - 2ms/epoch - 1ms/step\n",
      "Epoch 192/500\n",
      "2/2 - 0s - loss: 33.2349 - mse: 33.2349 - 3ms/epoch - 1ms/step\n",
      "Epoch 193/500\n",
      "2/2 - 0s - loss: 31.4078 - mse: 31.4078 - 2ms/epoch - 984us/step\n",
      "Epoch 194/500\n",
      "2/2 - 0s - loss: 31.1557 - mse: 31.1557 - 2ms/epoch - 1ms/step\n",
      "Epoch 195/500\n",
      "2/2 - 0s - loss: 30.7252 - mse: 30.7252 - 3ms/epoch - 2ms/step\n",
      "Epoch 196/500\n",
      "2/2 - 0s - loss: 30.4710 - mse: 30.4710 - 2ms/epoch - 968us/step\n",
      "Epoch 197/500\n",
      "2/2 - 0s - loss: 30.1466 - mse: 30.1466 - 2ms/epoch - 1ms/step\n",
      "Epoch 198/500\n",
      "2/2 - 0s - loss: 34.7772 - mse: 34.7772 - 2ms/epoch - 992us/step\n",
      "Epoch 199/500\n",
      "2/2 - 0s - loss: 42.8589 - mse: 42.8589 - 2ms/epoch - 976us/step\n",
      "Epoch 200/500\n",
      "2/2 - 0s - loss: 29.6254 - mse: 29.6254 - 3ms/epoch - 2ms/step\n",
      "Epoch 201/500\n",
      "2/2 - 0s - loss: 36.2966 - mse: 36.2966 - 3ms/epoch - 2ms/step\n",
      "Epoch 202/500\n",
      "2/2 - 0s - loss: 34.2600 - mse: 34.2600 - 2ms/epoch - 1ms/step\n",
      "Epoch 203/500\n",
      "2/2 - 0s - loss: 31.3649 - mse: 31.3649 - 3ms/epoch - 1ms/step\n",
      "Epoch 204/500\n",
      "2/2 - 0s - loss: 29.5215 - mse: 29.5215 - 957us/epoch - 479us/step\n",
      "Epoch 205/500\n",
      "2/2 - 0s - loss: 27.9972 - mse: 27.9972 - 2ms/epoch - 971us/step\n",
      "Epoch 206/500\n",
      "2/2 - 0s - loss: 27.8908 - mse: 27.8908 - 2ms/epoch - 971us/step\n",
      "Epoch 207/500\n",
      "2/2 - 0s - loss: 29.0883 - mse: 29.0883 - 2ms/epoch - 964us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/500\n",
      "2/2 - 0s - loss: 26.9630 - mse: 26.9630 - 2ms/epoch - 1ms/step\n",
      "Epoch 209/500\n",
      "2/2 - 0s - loss: 26.9109 - mse: 26.9109 - 2ms/epoch - 976us/step\n",
      "Epoch 210/500\n",
      "2/2 - 0s - loss: 27.8875 - mse: 27.8875 - 2ms/epoch - 1ms/step\n",
      "Epoch 211/500\n",
      "2/2 - 0s - loss: 30.5262 - mse: 30.5262 - 2ms/epoch - 1ms/step\n",
      "Epoch 212/500\n",
      "2/2 - 0s - loss: 26.9403 - mse: 26.9403 - 998us/epoch - 499us/step\n",
      "Epoch 213/500\n",
      "2/2 - 0s - loss: 26.3666 - mse: 26.3666 - 3ms/epoch - 2ms/step\n",
      "Epoch 214/500\n",
      "2/2 - 0s - loss: 29.9473 - mse: 29.9473 - 2ms/epoch - 990us/step\n",
      "Epoch 215/500\n",
      "2/2 - 0s - loss: 29.5603 - mse: 29.5603 - 2ms/epoch - 1ms/step\n",
      "Epoch 216/500\n",
      "2/2 - 0s - loss: 25.4085 - mse: 25.4085 - 2ms/epoch - 1ms/step\n",
      "Epoch 217/500\n",
      "2/2 - 0s - loss: 27.2380 - mse: 27.2380 - 2ms/epoch - 1ms/step\n",
      "Epoch 218/500\n",
      "2/2 - 0s - loss: 23.8667 - mse: 23.8667 - 2ms/epoch - 991us/step\n",
      "Epoch 219/500\n",
      "2/2 - 0s - loss: 23.6946 - mse: 23.6946 - 2ms/epoch - 998us/step\n",
      "Epoch 220/500\n",
      "2/2 - 0s - loss: 25.6541 - mse: 25.6541 - 2ms/epoch - 1ms/step\n",
      "Epoch 221/500\n",
      "2/2 - 0s - loss: 22.9131 - mse: 22.9131 - 3ms/epoch - 2ms/step\n",
      "Epoch 222/500\n",
      "2/2 - 0s - loss: 24.3156 - mse: 24.3156 - 2ms/epoch - 977us/step\n",
      "Epoch 223/500\n",
      "2/2 - 0s - loss: 27.6042 - mse: 27.6042 - 3ms/epoch - 2ms/step\n",
      "Epoch 224/500\n",
      "2/2 - 0s - loss: 21.9095 - mse: 21.9095 - 2ms/epoch - 994us/step\n",
      "Epoch 225/500\n",
      "2/2 - 0s - loss: 23.0808 - mse: 23.0808 - 1ms/epoch - 503us/step\n",
      "Epoch 226/500\n",
      "2/2 - 0s - loss: 31.0222 - mse: 31.0222 - 2ms/epoch - 1ms/step\n",
      "Epoch 227/500\n",
      "2/2 - 0s - loss: 24.3561 - mse: 24.3561 - 2ms/epoch - 998us/step\n",
      "Epoch 228/500\n",
      "2/2 - 0s - loss: 21.1024 - mse: 21.1024 - 3ms/epoch - 2ms/step\n",
      "Epoch 229/500\n",
      "2/2 - 0s - loss: 20.7228 - mse: 20.7228 - 2ms/epoch - 999us/step\n",
      "Epoch 230/500\n",
      "2/2 - 0s - loss: 21.3007 - mse: 21.3007 - 3ms/epoch - 1ms/step\n",
      "Epoch 231/500\n",
      "2/2 - 0s - loss: 20.7350 - mse: 20.7350 - 1ms/epoch - 512us/step\n",
      "Epoch 232/500\n",
      "2/2 - 0s - loss: 19.9851 - mse: 19.9851 - 2ms/epoch - 1000us/step\n",
      "Epoch 233/500\n",
      "2/2 - 0s - loss: 32.2944 - mse: 32.2944 - 2ms/epoch - 998us/step\n",
      "Epoch 234/500\n",
      "2/2 - 0s - loss: 22.0903 - mse: 22.0903 - 2ms/epoch - 1000us/step\n",
      "Epoch 235/500\n",
      "2/2 - 0s - loss: 19.6166 - mse: 19.6166 - 2ms/epoch - 999us/step\n",
      "Epoch 236/500\n",
      "2/2 - 0s - loss: 19.1833 - mse: 19.1833 - 2ms/epoch - 1ms/step\n",
      "Epoch 237/500\n",
      "2/2 - 0s - loss: 21.7463 - mse: 21.7463 - 2ms/epoch - 999us/step\n",
      "Epoch 238/500\n",
      "2/2 - 0s - loss: 20.7164 - mse: 20.7164 - 995us/epoch - 498us/step\n",
      "Epoch 239/500\n",
      "2/2 - 0s - loss: 19.5229 - mse: 19.5229 - 994us/epoch - 497us/step\n",
      "Epoch 240/500\n",
      "2/2 - 0s - loss: 26.2717 - mse: 26.2717 - 2ms/epoch - 999us/step\n",
      "Epoch 241/500\n",
      "2/2 - 0s - loss: 18.1749 - mse: 18.1749 - 3ms/epoch - 2ms/step\n",
      "Epoch 242/500\n",
      "2/2 - 0s - loss: 22.0423 - mse: 22.0423 - 2ms/epoch - 1ms/step\n",
      "Epoch 243/500\n",
      "2/2 - 0s - loss: 21.0045 - mse: 21.0045 - 994us/epoch - 497us/step\n",
      "Epoch 244/500\n",
      "2/2 - 0s - loss: 19.0952 - mse: 19.0952 - 3ms/epoch - 2ms/step\n",
      "Epoch 245/500\n",
      "2/2 - 0s - loss: 21.1509 - mse: 21.1509 - 2ms/epoch - 1ms/step\n",
      "Epoch 246/500\n",
      "2/2 - 0s - loss: 25.6434 - mse: 25.6434 - 2ms/epoch - 1ms/step\n",
      "Epoch 247/500\n",
      "2/2 - 0s - loss: 18.0868 - mse: 18.0868 - 3ms/epoch - 2ms/step\n",
      "Epoch 248/500\n",
      "2/2 - 0s - loss: 18.3543 - mse: 18.3543 - 4ms/epoch - 2ms/step\n",
      "Epoch 249/500\n",
      "2/2 - 0s - loss: 17.5231 - mse: 17.5231 - 3ms/epoch - 2ms/step\n",
      "Epoch 250/500\n",
      "2/2 - 0s - loss: 17.2828 - mse: 17.2828 - 2ms/epoch - 1000us/step\n",
      "Epoch 251/500\n",
      "2/2 - 0s - loss: 16.7131 - mse: 16.7131 - 3ms/epoch - 2ms/step\n",
      "Epoch 252/500\n",
      "2/2 - 0s - loss: 16.6269 - mse: 16.6269 - 2ms/epoch - 1ms/step\n",
      "Epoch 253/500\n",
      "2/2 - 0s - loss: 25.1936 - mse: 25.1936 - 2ms/epoch - 1000us/step\n",
      "Epoch 254/500\n",
      "2/2 - 0s - loss: 18.7181 - mse: 18.7181 - 4ms/epoch - 2ms/step\n",
      "Epoch 255/500\n",
      "2/2 - 0s - loss: 15.9038 - mse: 15.9038 - 3ms/epoch - 1ms/step\n",
      "Epoch 256/500\n",
      "2/2 - 0s - loss: 16.0007 - mse: 16.0007 - 2ms/epoch - 966us/step\n",
      "Epoch 257/500\n",
      "2/2 - 0s - loss: 15.9029 - mse: 15.9029 - 2ms/epoch - 1000us/step\n",
      "Epoch 258/500\n",
      "2/2 - 0s - loss: 14.8491 - mse: 14.8491 - 3ms/epoch - 2ms/step\n",
      "Epoch 259/500\n",
      "2/2 - 0s - loss: 17.0211 - mse: 17.0211 - 3ms/epoch - 2ms/step\n",
      "Epoch 260/500\n",
      "2/2 - 0s - loss: 19.5703 - mse: 19.5703 - 3ms/epoch - 2ms/step\n",
      "Epoch 261/500\n",
      "2/2 - 0s - loss: 17.5039 - mse: 17.5039 - 2ms/epoch - 1ms/step\n",
      "Epoch 262/500\n",
      "2/2 - 0s - loss: 17.3830 - mse: 17.3830 - 3ms/epoch - 2ms/step\n",
      "Epoch 263/500\n",
      "2/2 - 0s - loss: 29.1684 - mse: 29.1684 - 3ms/epoch - 1ms/step\n",
      "Epoch 264/500\n",
      "2/2 - 0s - loss: 16.2341 - mse: 16.2341 - 2ms/epoch - 764us/step\n",
      "Epoch 265/500\n",
      "2/2 - 0s - loss: 14.0221 - mse: 14.0221 - 3ms/epoch - 2ms/step\n",
      "Epoch 266/500\n",
      "2/2 - 0s - loss: 14.1684 - mse: 14.1684 - 2ms/epoch - 1ms/step\n",
      "Epoch 267/500\n",
      "2/2 - 0s - loss: 13.6944 - mse: 13.6944 - 3ms/epoch - 2ms/step\n",
      "Epoch 268/500\n",
      "2/2 - 0s - loss: 14.6940 - mse: 14.6940 - 3ms/epoch - 1ms/step\n",
      "Epoch 269/500\n",
      "2/2 - 0s - loss: 13.6179 - mse: 13.6179 - 2ms/epoch - 1ms/step\n",
      "Epoch 270/500\n",
      "2/2 - 0s - loss: 18.2662 - mse: 18.2662 - 2ms/epoch - 1ms/step\n",
      "Epoch 271/500\n",
      "2/2 - 0s - loss: 19.6442 - mse: 19.6442 - 3ms/epoch - 2ms/step\n",
      "Epoch 272/500\n",
      "2/2 - 0s - loss: 13.6413 - mse: 13.6413 - 2ms/epoch - 1ms/step\n",
      "Epoch 273/500\n",
      "2/2 - 0s - loss: 14.1039 - mse: 14.1039 - 2ms/epoch - 1000us/step\n",
      "Epoch 274/500\n",
      "2/2 - 0s - loss: 13.3062 - mse: 13.3062 - 2ms/epoch - 1ms/step\n",
      "Epoch 275/500\n",
      "2/2 - 0s - loss: 12.3243 - mse: 12.3243 - 3ms/epoch - 2ms/step\n",
      "Epoch 276/500\n",
      "2/2 - 0s - loss: 17.3468 - mse: 17.3468 - 2ms/epoch - 1ms/step\n",
      "Epoch 277/500\n",
      "2/2 - 0s - loss: 14.6944 - mse: 14.6944 - 2ms/epoch - 1ms/step\n",
      "Epoch 278/500\n",
      "2/2 - 0s - loss: 13.3063 - mse: 13.3063 - 3ms/epoch - 2ms/step\n",
      "Epoch 279/500\n",
      "2/2 - 0s - loss: 11.8776 - mse: 11.8776 - 3ms/epoch - 2ms/step\n",
      "Epoch 280/500\n",
      "2/2 - 0s - loss: 18.7721 - mse: 18.7721 - 3ms/epoch - 2ms/step\n",
      "Epoch 281/500\n",
      "2/2 - 0s - loss: 19.5256 - mse: 19.5256 - 2ms/epoch - 1ms/step\n",
      "Epoch 282/500\n",
      "2/2 - 0s - loss: 12.1028 - mse: 12.1028 - 2ms/epoch - 980us/step\n",
      "Epoch 283/500\n",
      "2/2 - 0s - loss: 14.2410 - mse: 14.2410 - 3ms/epoch - 1ms/step\n",
      "Epoch 284/500\n",
      "2/2 - 0s - loss: 11.2057 - mse: 11.2057 - 3ms/epoch - 2ms/step\n",
      "Epoch 285/500\n",
      "2/2 - 0s - loss: 11.8795 - mse: 11.8795 - 2ms/epoch - 1000us/step\n",
      "Epoch 286/500\n",
      "2/2 - 0s - loss: 15.2641 - mse: 15.2641 - 2ms/epoch - 974us/step\n",
      "Epoch 287/500\n",
      "2/2 - 0s - loss: 19.6495 - mse: 19.6495 - 2ms/epoch - 999us/step\n",
      "Epoch 288/500\n",
      "2/2 - 0s - loss: 13.0665 - mse: 13.0665 - 2ms/epoch - 997us/step\n",
      "Epoch 289/500\n",
      "2/2 - 0s - loss: 10.7193 - mse: 10.7193 - 2ms/epoch - 1ms/step\n",
      "Epoch 290/500\n",
      "2/2 - 0s - loss: 11.3997 - mse: 11.3997 - 2ms/epoch - 997us/step\n",
      "Epoch 291/500\n",
      "2/2 - 0s - loss: 14.1814 - mse: 14.1814 - 2ms/epoch - 1ms/step\n",
      "Epoch 292/500\n",
      "2/2 - 0s - loss: 10.3300 - mse: 10.3300 - 3ms/epoch - 2ms/step\n",
      "Epoch 293/500\n",
      "2/2 - 0s - loss: 13.4572 - mse: 13.4572 - 2ms/epoch - 1ms/step\n",
      "Epoch 294/500\n",
      "2/2 - 0s - loss: 27.4272 - mse: 27.4272 - 2ms/epoch - 992us/step\n",
      "Epoch 295/500\n",
      "2/2 - 0s - loss: 13.2128 - mse: 13.2128 - 2ms/epoch - 1ms/step\n",
      "Epoch 296/500\n",
      "2/2 - 0s - loss: 10.1688 - mse: 10.1688 - 3ms/epoch - 1ms/step\n",
      "Epoch 297/500\n",
      "2/2 - 0s - loss: 9.7404 - mse: 9.7404 - 2ms/epoch - 975us/step\n",
      "Epoch 298/500\n",
      "2/2 - 0s - loss: 9.6647 - mse: 9.6647 - 2ms/epoch - 1ms/step\n",
      "Epoch 299/500\n",
      "2/2 - 0s - loss: 9.7846 - mse: 9.7846 - 2ms/epoch - 1ms/step\n",
      "Epoch 300/500\n",
      "2/2 - 0s - loss: 15.5299 - mse: 15.5299 - 2ms/epoch - 1ms/step\n",
      "Epoch 301/500\n",
      "2/2 - 0s - loss: 12.2534 - mse: 12.2534 - 3ms/epoch - 2ms/step\n",
      "Epoch 302/500\n",
      "2/2 - 0s - loss: 10.6573 - mse: 10.6573 - 2ms/epoch - 1ms/step\n",
      "Epoch 303/500\n",
      "2/2 - 0s - loss: 13.3378 - mse: 13.3378 - 2ms/epoch - 976us/step\n",
      "Epoch 304/500\n",
      "2/2 - 0s - loss: 9.1975 - mse: 9.1975 - 2ms/epoch - 984us/step\n",
      "Epoch 305/500\n",
      "2/2 - 0s - loss: 10.4430 - mse: 10.4430 - 2ms/epoch - 1000us/step\n",
      "Epoch 306/500\n",
      "2/2 - 0s - loss: 12.1842 - mse: 12.1842 - 2ms/epoch - 978us/step\n",
      "Epoch 307/500\n",
      "2/2 - 0s - loss: 9.8378 - mse: 9.8378 - 2ms/epoch - 1ms/step\n",
      "Epoch 308/500\n",
      "2/2 - 0s - loss: 12.2282 - mse: 12.2282 - 2ms/epoch - 979us/step\n",
      "Epoch 309/500\n",
      "2/2 - 0s - loss: 17.1263 - mse: 17.1263 - 2ms/epoch - 1ms/step\n",
      "Epoch 310/500\n",
      "2/2 - 0s - loss: 11.8419 - mse: 11.8419 - 3ms/epoch - 1ms/step\n",
      "Epoch 311/500\n",
      "2/2 - 0s - loss: 11.0558 - mse: 11.0558 - 2ms/epoch - 999us/step\n",
      "Epoch 312/500\n",
      "2/2 - 0s - loss: 9.0801 - mse: 9.0801 - 2ms/epoch - 1ms/step\n",
      "Epoch 313/500\n",
      "2/2 - 0s - loss: 9.5742 - mse: 9.5742 - 962us/epoch - 481us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 314/500\n",
      "2/2 - 0s - loss: 11.0150 - mse: 11.0150 - 2ms/epoch - 998us/step\n",
      "Epoch 315/500\n",
      "2/2 - 0s - loss: 9.4810 - mse: 9.4810 - 2ms/epoch - 1ms/step\n",
      "Epoch 316/500\n",
      "2/2 - 0s - loss: 7.9735 - mse: 7.9735 - 2ms/epoch - 1ms/step\n",
      "Epoch 317/500\n",
      "2/2 - 0s - loss: 7.8433 - mse: 7.8433 - 3ms/epoch - 1ms/step\n",
      "Epoch 318/500\n",
      "2/2 - 0s - loss: 8.6207 - mse: 8.6207 - 2ms/epoch - 1ms/step\n",
      "Epoch 319/500\n",
      "2/2 - 0s - loss: 15.5915 - mse: 15.5915 - 2ms/epoch - 999us/step\n",
      "Epoch 320/500\n",
      "2/2 - 0s - loss: 14.3036 - mse: 14.3036 - 1ms/epoch - 526us/step\n",
      "Epoch 321/500\n",
      "2/2 - 0s - loss: 10.2126 - mse: 10.2126 - 2ms/epoch - 1ms/step\n",
      "Epoch 322/500\n",
      "2/2 - 0s - loss: 11.7012 - mse: 11.7012 - 2ms/epoch - 1ms/step\n",
      "Epoch 323/500\n",
      "2/2 - 0s - loss: 7.3867 - mse: 7.3867 - 2ms/epoch - 998us/step\n",
      "Epoch 324/500\n",
      "2/2 - 0s - loss: 7.6905 - mse: 7.6905 - 995us/epoch - 497us/step\n",
      "Epoch 325/500\n",
      "2/2 - 0s - loss: 9.6775 - mse: 9.6775 - 1ms/epoch - 531us/step\n",
      "Epoch 326/500\n",
      "2/2 - 0s - loss: 7.7426 - mse: 7.7426 - 2ms/epoch - 1ms/step\n",
      "Epoch 327/500\n",
      "2/2 - 0s - loss: 7.1798 - mse: 7.1798 - 2ms/epoch - 1ms/step\n",
      "Epoch 328/500\n",
      "2/2 - 0s - loss: 7.1597 - mse: 7.1597 - 2ms/epoch - 997us/step\n",
      "Epoch 329/500\n",
      "2/2 - 0s - loss: 6.8444 - mse: 6.8444 - 2ms/epoch - 997us/step\n",
      "Epoch 330/500\n",
      "2/2 - 0s - loss: 7.1933 - mse: 7.1933 - 2ms/epoch - 1ms/step\n",
      "Epoch 331/500\n",
      "2/2 - 0s - loss: 10.8588 - mse: 10.8588 - 2ms/epoch - 1ms/step\n",
      "Epoch 332/500\n",
      "2/2 - 0s - loss: 9.2751 - mse: 9.2751 - 2ms/epoch - 998us/step\n",
      "Epoch 333/500\n",
      "2/2 - 0s - loss: 6.9004 - mse: 6.9004 - 2ms/epoch - 967us/step\n",
      "Epoch 334/500\n",
      "2/2 - 0s - loss: 6.7425 - mse: 6.7425 - 2ms/epoch - 1000us/step\n",
      "Epoch 335/500\n",
      "2/2 - 0s - loss: 9.3043 - mse: 9.3043 - 2ms/epoch - 999us/step\n",
      "Epoch 336/500\n",
      "2/2 - 0s - loss: 10.4205 - mse: 10.4205 - 2ms/epoch - 997us/step\n",
      "Epoch 337/500\n",
      "2/2 - 0s - loss: 10.9220 - mse: 10.9220 - 2ms/epoch - 1ms/step\n",
      "Epoch 338/500\n",
      "2/2 - 0s - loss: 8.3668 - mse: 8.3668 - 2ms/epoch - 1ms/step\n",
      "Epoch 339/500\n",
      "2/2 - 0s - loss: 6.8434 - mse: 6.8434 - 994us/epoch - 497us/step\n",
      "Epoch 340/500\n",
      "2/2 - 0s - loss: 7.6098 - mse: 7.6098 - 2ms/epoch - 1ms/step\n",
      "Epoch 341/500\n",
      "2/2 - 0s - loss: 10.1772 - mse: 10.1772 - 2ms/epoch - 1000us/step\n",
      "Epoch 342/500\n",
      "2/2 - 0s - loss: 11.9725 - mse: 11.9725 - 2ms/epoch - 1ms/step\n",
      "Epoch 343/500\n",
      "2/2 - 0s - loss: 5.9303 - mse: 5.9303 - 2ms/epoch - 999us/step\n",
      "Epoch 344/500\n",
      "2/2 - 0s - loss: 7.1054 - mse: 7.1054 - 2ms/epoch - 1000us/step\n",
      "Epoch 345/500\n",
      "2/2 - 0s - loss: 10.0275 - mse: 10.0275 - 3ms/epoch - 1ms/step\n",
      "Epoch 346/500\n",
      "2/2 - 0s - loss: 6.7957 - mse: 6.7957 - 3ms/epoch - 1ms/step\n",
      "Epoch 347/500\n",
      "2/2 - 0s - loss: 5.9324 - mse: 5.9324 - 2ms/epoch - 1ms/step\n",
      "Epoch 348/500\n",
      "2/2 - 0s - loss: 5.7024 - mse: 5.7024 - 994us/epoch - 497us/step\n",
      "Epoch 349/500\n",
      "2/2 - 0s - loss: 5.5868 - mse: 5.5868 - 2ms/epoch - 1000us/step\n",
      "Epoch 350/500\n",
      "2/2 - 0s - loss: 5.4458 - mse: 5.4458 - 2ms/epoch - 1ms/step\n",
      "Epoch 351/500\n",
      "2/2 - 0s - loss: 7.5396 - mse: 7.5396 - 3ms/epoch - 1ms/step\n",
      "Epoch 352/500\n",
      "2/2 - 0s - loss: 11.4618 - mse: 11.4618 - 999us/epoch - 500us/step\n",
      "Epoch 353/500\n",
      "2/2 - 0s - loss: 7.7355 - mse: 7.7355 - 2ms/epoch - 999us/step\n",
      "Epoch 354/500\n",
      "2/2 - 0s - loss: 6.6224 - mse: 6.6224 - 2ms/epoch - 996us/step\n",
      "Epoch 355/500\n",
      "2/2 - 0s - loss: 6.5944 - mse: 6.5944 - 2ms/epoch - 999us/step\n",
      "Epoch 356/500\n",
      "2/2 - 0s - loss: 5.4278 - mse: 5.4278 - 1000us/epoch - 500us/step\n",
      "Epoch 357/500\n",
      "2/2 - 0s - loss: 5.2390 - mse: 5.2390 - 2ms/epoch - 1ms/step\n",
      "Epoch 358/500\n",
      "2/2 - 0s - loss: 7.8352 - mse: 7.8352 - 2ms/epoch - 1000us/step\n",
      "Epoch 359/500\n",
      "2/2 - 0s - loss: 17.0046 - mse: 17.0046 - 3ms/epoch - 2ms/step\n",
      "Epoch 360/500\n",
      "2/2 - 0s - loss: 7.6678 - mse: 7.6678 - 2ms/epoch - 1000us/step\n",
      "Epoch 361/500\n",
      "2/2 - 0s - loss: 4.8266 - mse: 4.8266 - 999us/epoch - 500us/step\n",
      "Epoch 362/500\n",
      "2/2 - 0s - loss: 4.7389 - mse: 4.7389 - 2ms/epoch - 1ms/step\n",
      "Epoch 363/500\n",
      "2/2 - 0s - loss: 5.4424 - mse: 5.4424 - 2ms/epoch - 997us/step\n",
      "Epoch 364/500\n",
      "2/2 - 0s - loss: 10.6911 - mse: 10.6911 - 2ms/epoch - 991us/step\n",
      "Epoch 365/500\n",
      "2/2 - 0s - loss: 7.2952 - mse: 7.2952 - 2ms/epoch - 1ms/step\n",
      "Epoch 366/500\n",
      "2/2 - 0s - loss: 5.6195 - mse: 5.6195 - 995us/epoch - 497us/step\n",
      "Epoch 367/500\n",
      "2/2 - 0s - loss: 5.4522 - mse: 5.4522 - 2ms/epoch - 1000us/step\n",
      "Epoch 368/500\n",
      "2/2 - 0s - loss: 5.3616 - mse: 5.3616 - 2ms/epoch - 1ms/step\n",
      "Epoch 369/500\n",
      "2/2 - 0s - loss: 4.9929 - mse: 4.9929 - 2ms/epoch - 1ms/step\n",
      "Epoch 370/500\n",
      "2/2 - 0s - loss: 4.5207 - mse: 4.5207 - 2ms/epoch - 1ms/step\n",
      "Epoch 371/500\n",
      "2/2 - 0s - loss: 6.2324 - mse: 6.2324 - 2ms/epoch - 998us/step\n",
      "Epoch 372/500\n",
      "2/2 - 0s - loss: 11.2288 - mse: 11.2288 - 2ms/epoch - 990us/step\n",
      "Epoch 373/500\n",
      "2/2 - 0s - loss: 7.9325 - mse: 7.9325 - 2ms/epoch - 971us/step\n",
      "Epoch 374/500\n",
      "2/2 - 0s - loss: 5.7841 - mse: 5.7841 - 3ms/epoch - 2ms/step\n",
      "Epoch 375/500\n",
      "2/2 - 0s - loss: 4.9291 - mse: 4.9291 - 2ms/epoch - 1ms/step\n",
      "Epoch 376/500\n",
      "2/2 - 0s - loss: 4.4732 - mse: 4.4732 - 989us/epoch - 494us/step\n",
      "Epoch 377/500\n",
      "2/2 - 0s - loss: 4.9823 - mse: 4.9823 - 2ms/epoch - 976us/step\n",
      "Epoch 378/500\n",
      "2/2 - 0s - loss: 4.6330 - mse: 4.6330 - 2ms/epoch - 970us/step\n",
      "Epoch 379/500\n",
      "2/2 - 0s - loss: 7.0375 - mse: 7.0375 - 2ms/epoch - 799us/step\n",
      "Epoch 380/500\n",
      "2/2 - 0s - loss: 12.2256 - mse: 12.2256 - 2ms/epoch - 998us/step\n",
      "Epoch 381/500\n",
      "2/2 - 0s - loss: 5.3496 - mse: 5.3496 - 2ms/epoch - 1ms/step\n",
      "Epoch 382/500\n",
      "2/2 - 0s - loss: 4.3778 - mse: 4.3778 - 2ms/epoch - 996us/step\n",
      "Epoch 383/500\n",
      "2/2 - 0s - loss: 3.8607 - mse: 3.8607 - 2ms/epoch - 1ms/step\n",
      "Epoch 384/500\n",
      "2/2 - 0s - loss: 8.9717 - mse: 8.9717 - 3ms/epoch - 2ms/step\n",
      "Epoch 385/500\n",
      "2/2 - 0s - loss: 7.5586 - mse: 7.5586 - 3ms/epoch - 2ms/step\n",
      "Epoch 386/500\n",
      "2/2 - 0s - loss: 5.6088 - mse: 5.6088 - 934us/epoch - 467us/step\n",
      "Epoch 387/500\n",
      "2/2 - 0s - loss: 4.3398 - mse: 4.3398 - 2ms/epoch - 972us/step\n",
      "Epoch 388/500\n",
      "2/2 - 0s - loss: 4.6670 - mse: 4.6670 - 2ms/epoch - 1ms/step\n",
      "Epoch 389/500\n",
      "2/2 - 0s - loss: 7.1887 - mse: 7.1887 - 1ms/epoch - 501us/step\n",
      "Epoch 390/500\n",
      "2/2 - 0s - loss: 4.1796 - mse: 4.1796 - 1ms/epoch - 695us/step\n",
      "Epoch 391/500\n",
      "2/2 - 0s - loss: 3.8460 - mse: 3.8460 - 2ms/epoch - 972us/step\n",
      "Epoch 392/500\n",
      "2/2 - 0s - loss: 3.5167 - mse: 3.5167 - 3ms/epoch - 1ms/step\n",
      "Epoch 393/500\n",
      "2/2 - 0s - loss: 4.9596 - mse: 4.9596 - 2ms/epoch - 1ms/step\n",
      "Epoch 394/500\n",
      "2/2 - 0s - loss: 7.3538 - mse: 7.3538 - 3ms/epoch - 1ms/step\n",
      "Epoch 395/500\n",
      "2/2 - 0s - loss: 10.2978 - mse: 10.2978 - 2ms/epoch - 999us/step\n",
      "Epoch 396/500\n",
      "2/2 - 0s - loss: 7.7951 - mse: 7.7951 - 2ms/epoch - 999us/step\n",
      "Epoch 397/500\n",
      "2/2 - 0s - loss: 3.7375 - mse: 3.7375 - 2ms/epoch - 998us/step\n",
      "Epoch 398/500\n",
      "2/2 - 0s - loss: 3.4526 - mse: 3.4526 - 3ms/epoch - 2ms/step\n",
      "Epoch 399/500\n",
      "2/2 - 0s - loss: 3.7105 - mse: 3.7105 - 2ms/epoch - 943us/step\n",
      "Epoch 400/500\n",
      "2/2 - 0s - loss: 11.2286 - mse: 11.2286 - 2ms/epoch - 1ms/step\n",
      "Epoch 401/500\n",
      "2/2 - 0s - loss: 6.5363 - mse: 6.5363 - 2ms/epoch - 1ms/step\n",
      "Epoch 402/500\n",
      "2/2 - 0s - loss: 3.6057 - mse: 3.6057 - 2ms/epoch - 961us/step\n",
      "Epoch 403/500\n",
      "2/2 - 0s - loss: 3.7072 - mse: 3.7072 - 3ms/epoch - 2ms/step\n",
      "Epoch 404/500\n",
      "2/2 - 0s - loss: 3.2311 - mse: 3.2311 - 2ms/epoch - 998us/step\n",
      "Epoch 405/500\n",
      "2/2 - 0s - loss: 3.4625 - mse: 3.4625 - 2ms/epoch - 1ms/step\n",
      "Epoch 406/500\n",
      "2/2 - 0s - loss: 5.0283 - mse: 5.0283 - 2ms/epoch - 980us/step\n",
      "Epoch 407/500\n",
      "2/2 - 0s - loss: 5.8524 - mse: 5.8524 - 3ms/epoch - 1ms/step\n",
      "Epoch 408/500\n",
      "2/2 - 0s - loss: 9.6753 - mse: 9.6753 - 2ms/epoch - 1ms/step\n",
      "Epoch 409/500\n",
      "2/2 - 0s - loss: 7.7281 - mse: 7.7281 - 2ms/epoch - 1ms/step\n",
      "Epoch 410/500\n",
      "2/2 - 0s - loss: 4.2664 - mse: 4.2664 - 2ms/epoch - 1ms/step\n",
      "Epoch 411/500\n",
      "2/2 - 0s - loss: 3.6710 - mse: 3.6710 - 2ms/epoch - 1ms/step\n",
      "Epoch 412/500\n",
      "2/2 - 0s - loss: 4.6715 - mse: 4.6715 - 2ms/epoch - 974us/step\n",
      "Epoch 413/500\n",
      "2/2 - 0s - loss: 7.6264 - mse: 7.6264 - 2ms/epoch - 998us/step\n",
      "Epoch 414/500\n",
      "2/2 - 0s - loss: 4.8529 - mse: 4.8529 - 3ms/epoch - 1ms/step\n",
      "Epoch 415/500\n",
      "2/2 - 0s - loss: 4.3826 - mse: 4.3826 - 3ms/epoch - 1ms/step\n",
      "Epoch 416/500\n",
      "2/2 - 0s - loss: 4.5915 - mse: 4.5915 - 2ms/epoch - 998us/step\n",
      "Epoch 417/500\n",
      "2/2 - 0s - loss: 3.4808 - mse: 3.4808 - 2ms/epoch - 1000us/step\n",
      "Epoch 418/500\n",
      "2/2 - 0s - loss: 2.9008 - mse: 2.9008 - 1ms/epoch - 574us/step\n",
      "Epoch 419/500\n",
      "2/2 - 0s - loss: 3.1194 - mse: 3.1194 - 2ms/epoch - 1ms/step\n",
      "Epoch 420/500\n",
      "2/2 - 0s - loss: 6.1596 - mse: 6.1596 - 2ms/epoch - 1ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 421/500\n",
      "2/2 - 0s - loss: 6.8361 - mse: 6.8361 - 2ms/epoch - 969us/step\n",
      "Epoch 422/500\n",
      "2/2 - 0s - loss: 3.7652 - mse: 3.7652 - 949us/epoch - 475us/step\n",
      "Epoch 423/500\n",
      "2/2 - 0s - loss: 3.1515 - mse: 3.1515 - 2ms/epoch - 1000us/step\n",
      "Epoch 424/500\n",
      "2/2 - 0s - loss: 3.2545 - mse: 3.2545 - 2ms/epoch - 1ms/step\n",
      "Epoch 425/500\n",
      "2/2 - 0s - loss: 8.5555 - mse: 8.5555 - 2ms/epoch - 998us/step\n",
      "Epoch 426/500\n",
      "2/2 - 0s - loss: 8.3217 - mse: 8.3217 - 2ms/epoch - 977us/step\n",
      "Epoch 427/500\n",
      "2/2 - 0s - loss: 4.3421 - mse: 4.3421 - 937us/epoch - 468us/step\n",
      "Epoch 428/500\n",
      "2/2 - 0s - loss: 2.9164 - mse: 2.9164 - 2ms/epoch - 998us/step\n",
      "Epoch 429/500\n",
      "2/2 - 0s - loss: 3.1677 - mse: 3.1677 - 3ms/epoch - 1ms/step\n",
      "Epoch 430/500\n",
      "2/2 - 0s - loss: 4.1620 - mse: 4.1620 - 3ms/epoch - 1ms/step\n",
      "Epoch 431/500\n",
      "2/2 - 0s - loss: 4.3183 - mse: 4.3183 - 945us/epoch - 472us/step\n",
      "Epoch 432/500\n",
      "2/2 - 0s - loss: 4.9664 - mse: 4.9664 - 2ms/epoch - 977us/step\n",
      "Epoch 433/500\n",
      "2/2 - 0s - loss: 5.0766 - mse: 5.0766 - 2ms/epoch - 1ms/step\n",
      "Epoch 434/500\n",
      "2/2 - 0s - loss: 3.1781 - mse: 3.1781 - 2ms/epoch - 978us/step\n",
      "Epoch 435/500\n",
      "2/2 - 0s - loss: 3.9595 - mse: 3.9595 - 2ms/epoch - 976us/step\n",
      "Epoch 436/500\n",
      "2/2 - 0s - loss: 5.6586 - mse: 5.6586 - 2ms/epoch - 970us/step\n",
      "Epoch 437/500\n",
      "2/2 - 0s - loss: 5.0746 - mse: 5.0746 - 944us/epoch - 472us/step\n",
      "Epoch 438/500\n",
      "2/2 - 0s - loss: 4.8746 - mse: 4.8746 - 2ms/epoch - 997us/step\n",
      "Epoch 439/500\n",
      "2/2 - 0s - loss: 3.0930 - mse: 3.0930 - 2ms/epoch - 1ms/step\n",
      "Epoch 440/500\n",
      "2/2 - 0s - loss: 2.4766 - mse: 2.4766 - 2ms/epoch - 1ms/step\n",
      "Epoch 441/500\n",
      "2/2 - 0s - loss: 4.5105 - mse: 4.5105 - 2ms/epoch - 979us/step\n",
      "Epoch 442/500\n",
      "2/2 - 0s - loss: 10.5692 - mse: 10.5692 - 2ms/epoch - 976us/step\n",
      "Epoch 443/500\n",
      "2/2 - 0s - loss: 3.1044 - mse: 3.1044 - 989us/epoch - 495us/step\n",
      "Epoch 444/500\n",
      "2/2 - 0s - loss: 2.4353 - mse: 2.4353 - 2ms/epoch - 1000us/step\n",
      "Epoch 445/500\n",
      "2/2 - 0s - loss: 2.4112 - mse: 2.4112 - 3ms/epoch - 1ms/step\n",
      "Epoch 446/500\n",
      "2/2 - 0s - loss: 2.4918 - mse: 2.4918 - 999us/epoch - 500us/step\n",
      "Epoch 447/500\n",
      "2/2 - 0s - loss: 2.3506 - mse: 2.3506 - 2ms/epoch - 1ms/step\n",
      "Epoch 448/500\n",
      "2/2 - 0s - loss: 2.6158 - mse: 2.6158 - 2ms/epoch - 980us/step\n",
      "Epoch 449/500\n",
      "2/2 - 0s - loss: 10.2521 - mse: 10.2521 - 2ms/epoch - 962us/step\n",
      "Epoch 450/500\n",
      "2/2 - 0s - loss: 7.0400 - mse: 7.0400 - 1ms/epoch - 501us/step\n",
      "Epoch 451/500\n",
      "2/2 - 0s - loss: 2.8189 - mse: 2.8189 - 2ms/epoch - 1ms/step\n",
      "Epoch 452/500\n",
      "2/2 - 0s - loss: 2.8579 - mse: 2.8579 - 2ms/epoch - 999us/step\n",
      "Epoch 453/500\n",
      "2/2 - 0s - loss: 2.8525 - mse: 2.8525 - 2ms/epoch - 966us/step\n",
      "Epoch 454/500\n",
      "2/2 - 0s - loss: 3.3124 - mse: 3.3124 - 2ms/epoch - 999us/step\n",
      "Epoch 455/500\n",
      "2/2 - 0s - loss: 6.0886 - mse: 6.0886 - 2ms/epoch - 1ms/step\n",
      "Epoch 456/500\n",
      "2/2 - 0s - loss: 6.7902 - mse: 6.7902 - 2ms/epoch - 1ms/step\n",
      "Epoch 457/500\n",
      "2/2 - 0s - loss: 3.1511 - mse: 3.1511 - 3ms/epoch - 1ms/step\n",
      "Epoch 458/500\n",
      "2/2 - 0s - loss: 4.6056 - mse: 4.6056 - 2ms/epoch - 1ms/step\n",
      "Epoch 459/500\n",
      "2/2 - 0s - loss: 5.6663 - mse: 5.6663 - 2ms/epoch - 976us/step\n",
      "Epoch 460/500\n",
      "2/2 - 0s - loss: 3.9705 - mse: 3.9705 - 942us/epoch - 471us/step\n",
      "Epoch 461/500\n",
      "2/2 - 0s - loss: 2.3842 - mse: 2.3842 - 3ms/epoch - 1ms/step\n",
      "Epoch 462/500\n",
      "2/2 - 0s - loss: 2.2017 - mse: 2.2017 - 2ms/epoch - 999us/step\n",
      "Epoch 463/500\n",
      "2/2 - 0s - loss: 2.1391 - mse: 2.1391 - 3ms/epoch - 2ms/step\n",
      "Epoch 464/500\n",
      "2/2 - 0s - loss: 2.5716 - mse: 2.5716 - 2ms/epoch - 1ms/step\n",
      "Epoch 465/500\n",
      "2/2 - 0s - loss: 7.9428 - mse: 7.9428 - 2ms/epoch - 1ms/step\n",
      "Epoch 466/500\n",
      "2/2 - 0s - loss: 9.1860 - mse: 9.1860 - 2ms/epoch - 988us/step\n",
      "Epoch 467/500\n",
      "2/2 - 0s - loss: 2.6305 - mse: 2.6305 - 2ms/epoch - 999us/step\n",
      "Epoch 468/500\n",
      "2/2 - 0s - loss: 2.7030 - mse: 2.7030 - 2ms/epoch - 1ms/step\n",
      "Epoch 469/500\n",
      "2/2 - 0s - loss: 3.6491 - mse: 3.6491 - 2ms/epoch - 971us/step\n",
      "Epoch 470/500\n",
      "2/2 - 0s - loss: 4.3305 - mse: 4.3305 - 2ms/epoch - 1ms/step\n",
      "Epoch 471/500\n",
      "2/2 - 0s - loss: 4.5799 - mse: 4.5799 - 2ms/epoch - 1ms/step\n",
      "Epoch 472/500\n",
      "2/2 - 0s - loss: 2.2655 - mse: 2.2655 - 2ms/epoch - 1ms/step\n",
      "Epoch 473/500\n",
      "2/2 - 0s - loss: 2.6884 - mse: 2.6884 - 2ms/epoch - 1ms/step\n",
      "Epoch 474/500\n",
      "2/2 - 0s - loss: 6.5201 - mse: 6.5201 - 1ms/epoch - 530us/step\n",
      "Epoch 475/500\n",
      "2/2 - 0s - loss: 3.0084 - mse: 3.0084 - 2ms/epoch - 1000us/step\n",
      "Epoch 476/500\n",
      "2/2 - 0s - loss: 2.2249 - mse: 2.2249 - 996us/epoch - 498us/step\n",
      "Epoch 477/500\n",
      "2/2 - 0s - loss: 3.9300 - mse: 3.9300 - 2ms/epoch - 997us/step\n",
      "Epoch 478/500\n",
      "2/2 - 0s - loss: 7.5232 - mse: 7.5232 - 2ms/epoch - 999us/step\n",
      "Epoch 479/500\n",
      "2/2 - 0s - loss: 5.8139 - mse: 5.8139 - 2ms/epoch - 1ms/step\n",
      "Epoch 480/500\n",
      "2/2 - 0s - loss: 3.5294 - mse: 3.5294 - 2ms/epoch - 1ms/step\n",
      "Epoch 481/500\n",
      "2/2 - 0s - loss: 2.7048 - mse: 2.7048 - 2ms/epoch - 1ms/step\n",
      "Epoch 482/500\n",
      "2/2 - 0s - loss: 2.1095 - mse: 2.1095 - 2ms/epoch - 997us/step\n",
      "Epoch 483/500\n",
      "2/2 - 0s - loss: 1.9516 - mse: 1.9516 - 2ms/epoch - 1ms/step\n",
      "Epoch 484/500\n",
      "2/2 - 0s - loss: 3.7809 - mse: 3.7809 - 1ms/epoch - 501us/step\n",
      "Epoch 485/500\n",
      "2/2 - 0s - loss: 10.1852 - mse: 10.1852 - 2ms/epoch - 997us/step\n",
      "Epoch 486/500\n",
      "2/2 - 0s - loss: 4.7192 - mse: 4.7192 - 2ms/epoch - 1ms/step\n",
      "Epoch 487/500\n",
      "2/2 - 0s - loss: 2.1378 - mse: 2.1378 - 2ms/epoch - 1ms/step\n",
      "Epoch 488/500\n",
      "2/2 - 0s - loss: 2.1793 - mse: 2.1793 - 2ms/epoch - 1ms/step\n",
      "Epoch 489/500\n",
      "2/2 - 0s - loss: 3.7989 - mse: 3.7989 - 2ms/epoch - 1ms/step\n",
      "Epoch 490/500\n",
      "2/2 - 0s - loss: 7.5085 - mse: 7.5085 - 2ms/epoch - 1ms/step\n",
      "Epoch 491/500\n",
      "2/2 - 0s - loss: 4.5047 - mse: 4.5047 - 992us/epoch - 496us/step\n",
      "Epoch 492/500\n",
      "2/2 - 0s - loss: 3.1110 - mse: 3.1110 - 2ms/epoch - 1ms/step\n",
      "Epoch 493/500\n",
      "2/2 - 0s - loss: 1.9244 - mse: 1.9244 - 2ms/epoch - 1ms/step\n",
      "Epoch 494/500\n",
      "2/2 - 0s - loss: 1.9865 - mse: 1.9865 - 1ms/epoch - 500us/step\n",
      "Epoch 495/500\n",
      "2/2 - 0s - loss: 1.9056 - mse: 1.9056 - 999us/epoch - 499us/step\n",
      "Epoch 496/500\n",
      "2/2 - 0s - loss: 2.9075 - mse: 2.9075 - 2ms/epoch - 999us/step\n",
      "Epoch 497/500\n",
      "2/2 - 0s - loss: 4.2304 - mse: 4.2304 - 1ms/epoch - 501us/step\n",
      "Epoch 498/500\n",
      "2/2 - 0s - loss: 7.4258 - mse: 7.4258 - 2ms/epoch - 997us/step\n",
      "Epoch 499/500\n",
      "2/2 - 0s - loss: 5.8471 - mse: 5.8471 - 2ms/epoch - 1ms/step\n",
      "Epoch 500/500\n",
      "2/2 - 0s - loss: 2.7697 - mse: 2.7697 - 2ms/epoch - 1000us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_zeros_after_fit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>18.049759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>19.093185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>19.213364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>22.133011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>11.159378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_zeros_after_fit\n",
       "abbrev                             \n",
       "AL       18.8             18.049759\n",
       "AK       18.1             19.093185\n",
       "AZ       18.6             19.213364\n",
       "AR       22.4             22.133011\n",
       "CA       12.0             11.159378"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# en resumidas cuentas, ser√≠a todo as√≠:\n",
    "\n",
    "# 1) librerias\n",
    "from keras.models import Sequential # para crear el modelo secuencial\n",
    "from keras.layers import Dense, Input # para colocar el dense y el input de RRNN\n",
    "\n",
    "# 2) Definir el modelo\n",
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,))) # Es 6 pq hay 6 variables explicativas en el dataset\n",
    "# (el total no se cuenta porque es precisamente la variable objetiva, la que buscamos)\n",
    "model.add(layer=Dense(3)) # Ponemos 3 porque hemos querido poner 3 neuronas (se pueden\n",
    "# modificar y poner los que se quiera)\n",
    "model.add(layer=Dense(1, )) # Este ser√≠a la variable objetiva (el total)\n",
    "# Ni el input ni el dense final se pueden modificar, si no fallar√≠a el modelo\n",
    "\n",
    "# 3) Definimos las variables explicativas y objetiva\n",
    "X = df.drop(columns='total')\n",
    "y = df.total\n",
    "\n",
    "# 4) Ajustamos el modelo y lo lanzamos\n",
    "model.compile(loss='mse', metrics=['mse'])\n",
    "model.fit(X, y, epochs=500, verbose=2) # el verbose permite ver el loss y el mse que\n",
    "# definimos justo arriba de esta funci√≥n y que se ve en el lanzamiento\n",
    "\n",
    "# 5) Observamos los n√∫meros para los weights\n",
    "model.get_weights()\n",
    "\n",
    "# 6) Comparamos con los datos del dataset\n",
    "y_pred = model.predict(X)\n",
    "dfsel = df[['total']].copy()\n",
    "dfsel['pred_zeros_after_fit'] = y_pred\n",
    "dfsel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_init_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>20.272116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>20.923376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>20.144960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>22.679586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>13.580787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_init_1\n",
       "abbrev                    \n",
       "AL       18.8    20.272116\n",
       "AK       18.1    20.923376\n",
       "AZ       18.6    20.144960\n",
       "AR       22.4    22.679586\n",
       "CA       12.0    13.580787"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AL = X[:1]\n",
    "\n",
    "model.predict(x=AL)\n",
    "model.get_weights()\n",
    "dfsel = df[['total']].copy()\n",
    "dfsel['pred_init_1'] = model.predict(X)\n",
    "dfsel.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to `kernel_initializer` the weights to `glorot_uniform` (default)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - https://keras.io/api/layers/activations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=558\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w?start=558\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Use `sigmoid` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='sigmoid')) # aqu√≠ se realiza el cambio\n",
    "\n",
    "model.compile(loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `fit()` the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 - 0s - loss: 1.9051 - mse: 1.9051 - 8ms/epoch - 4ms/step\n",
      "Epoch 2/500\n",
      "2/2 - 0s - loss: 1.9447 - mse: 1.9447 - 3ms/epoch - 2ms/step\n",
      "Epoch 3/500\n",
      "2/2 - 0s - loss: 2.0441 - mse: 2.0441 - 2ms/epoch - 1ms/step\n",
      "Epoch 4/500\n",
      "2/2 - 0s - loss: 2.5711 - mse: 2.5711 - 2ms/epoch - 1ms/step\n",
      "Epoch 5/500\n",
      "2/2 - 0s - loss: 2.2043 - mse: 2.2043 - 2ms/epoch - 1ms/step\n",
      "Epoch 6/500\n",
      "2/2 - 0s - loss: 2.3807 - mse: 2.3807 - 5ms/epoch - 2ms/step\n",
      "Epoch 7/500\n",
      "2/2 - 0s - loss: 2.0328 - mse: 2.0328 - 5ms/epoch - 3ms/step\n",
      "Epoch 8/500\n",
      "2/2 - 0s - loss: 2.0667 - mse: 2.0667 - 2ms/epoch - 997us/step\n",
      "Epoch 9/500\n",
      "2/2 - 0s - loss: 3.4533 - mse: 3.4533 - 3ms/epoch - 2ms/step\n",
      "Epoch 10/500\n",
      "2/2 - 0s - loss: 1.9191 - mse: 1.9191 - 2ms/epoch - 946us/step\n",
      "Epoch 11/500\n",
      "2/2 - 0s - loss: 2.6989 - mse: 2.6989 - 3ms/epoch - 2ms/step\n",
      "Epoch 12/500\n",
      "2/2 - 0s - loss: 1.9701 - mse: 1.9701 - 2ms/epoch - 1ms/step\n",
      "Epoch 13/500\n",
      "2/2 - 0s - loss: 1.8632 - mse: 1.8632 - 2ms/epoch - 971us/step\n",
      "Epoch 14/500\n",
      "2/2 - 0s - loss: 1.8643 - mse: 1.8643 - 4ms/epoch - 2ms/step\n",
      "Epoch 15/500\n",
      "2/2 - 0s - loss: 2.1417 - mse: 2.1417 - 4ms/epoch - 2ms/step\n",
      "Epoch 16/500\n",
      "2/2 - 0s - loss: 2.0028 - mse: 2.0028 - 3ms/epoch - 1ms/step\n",
      "Epoch 17/500\n",
      "2/2 - 0s - loss: 2.2614 - mse: 2.2614 - 2ms/epoch - 1ms/step\n",
      "Epoch 18/500\n",
      "2/2 - 0s - loss: 2.1847 - mse: 2.1847 - 3ms/epoch - 1ms/step\n",
      "Epoch 19/500\n",
      "2/2 - 0s - loss: 1.9978 - mse: 1.9978 - 3ms/epoch - 2ms/step\n",
      "Epoch 20/500\n",
      "2/2 - 0s - loss: 2.5142 - mse: 2.5142 - 2ms/epoch - 1ms/step\n",
      "Epoch 21/500\n",
      "2/2 - 0s - loss: 2.4711 - mse: 2.4711 - 3ms/epoch - 2ms/step\n",
      "Epoch 22/500\n",
      "2/2 - 0s - loss: 2.1612 - mse: 2.1612 - 3ms/epoch - 1ms/step\n",
      "Epoch 23/500\n",
      "2/2 - 0s - loss: 2.4986 - mse: 2.4986 - 2ms/epoch - 837us/step\n",
      "Epoch 24/500\n",
      "2/2 - 0s - loss: 1.9148 - mse: 1.9148 - 3ms/epoch - 1ms/step\n",
      "Epoch 25/500\n",
      "2/2 - 0s - loss: 2.1817 - mse: 2.1817 - 3ms/epoch - 1ms/step\n",
      "Epoch 26/500\n",
      "2/2 - 0s - loss: 2.7228 - mse: 2.7228 - 4ms/epoch - 2ms/step\n",
      "Epoch 27/500\n",
      "2/2 - 0s - loss: 1.8514 - mse: 1.8514 - 2ms/epoch - 1ms/step\n",
      "Epoch 28/500\n",
      "2/2 - 0s - loss: 2.0652 - mse: 2.0652 - 3ms/epoch - 1ms/step\n",
      "Epoch 29/500\n",
      "2/2 - 0s - loss: 1.8185 - mse: 1.8185 - 3ms/epoch - 1ms/step\n",
      "Epoch 30/500\n",
      "2/2 - 0s - loss: 2.0680 - mse: 2.0680 - 3ms/epoch - 2ms/step\n",
      "Epoch 31/500\n",
      "2/2 - 0s - loss: 1.8855 - mse: 1.8855 - 3ms/epoch - 1ms/step\n",
      "Epoch 32/500\n",
      "2/2 - 0s - loss: 2.8031 - mse: 2.8031 - 4ms/epoch - 2ms/step\n",
      "Epoch 33/500\n",
      "2/2 - 0s - loss: 2.1126 - mse: 2.1126 - 3ms/epoch - 2ms/step\n",
      "Epoch 34/500\n",
      "2/2 - 0s - loss: 1.8066 - mse: 1.8066 - 3ms/epoch - 1ms/step\n",
      "Epoch 35/500\n",
      "2/2 - 0s - loss: 2.0880 - mse: 2.0880 - 3ms/epoch - 2ms/step\n",
      "Epoch 36/500\n",
      "2/2 - 0s - loss: 2.4214 - mse: 2.4214 - 2ms/epoch - 1ms/step\n",
      "Epoch 37/500\n",
      "2/2 - 0s - loss: 2.6280 - mse: 2.6280 - 2ms/epoch - 981us/step\n",
      "Epoch 38/500\n",
      "2/2 - 0s - loss: 1.9091 - mse: 1.9091 - 2ms/epoch - 1ms/step\n",
      "Epoch 39/500\n",
      "2/2 - 0s - loss: 1.7942 - mse: 1.7942 - 3ms/epoch - 2ms/step\n",
      "Epoch 40/500\n",
      "2/2 - 0s - loss: 2.0510 - mse: 2.0510 - 2ms/epoch - 1ms/step\n",
      "Epoch 41/500\n",
      "2/2 - 0s - loss: 2.6026 - mse: 2.6026 - 2ms/epoch - 1ms/step\n",
      "Epoch 42/500\n",
      "2/2 - 0s - loss: 2.1348 - mse: 2.1348 - 2ms/epoch - 975us/step\n",
      "Epoch 43/500\n",
      "2/2 - 0s - loss: 1.8429 - mse: 1.8429 - 2ms/epoch - 1ms/step\n",
      "Epoch 44/500\n",
      "2/2 - 0s - loss: 2.0615 - mse: 2.0615 - 2ms/epoch - 1ms/step\n",
      "Epoch 45/500\n",
      "2/2 - 0s - loss: 1.8669 - mse: 1.8669 - 2ms/epoch - 971us/step\n",
      "Epoch 46/500\n",
      "2/2 - 0s - loss: 1.8172 - mse: 1.8172 - 2ms/epoch - 1ms/step\n",
      "Epoch 47/500\n",
      "2/2 - 0s - loss: 2.2536 - mse: 2.2536 - 2ms/epoch - 1ms/step\n",
      "Epoch 48/500\n",
      "2/2 - 0s - loss: 1.8171 - mse: 1.8171 - 4ms/epoch - 2ms/step\n",
      "Epoch 49/500\n",
      "2/2 - 0s - loss: 1.8559 - mse: 1.8559 - 2ms/epoch - 999us/step\n",
      "Epoch 50/500\n",
      "2/2 - 0s - loss: 2.4824 - mse: 2.4824 - 2ms/epoch - 999us/step\n",
      "Epoch 51/500\n",
      "2/2 - 0s - loss: 2.1991 - mse: 2.1991 - 3ms/epoch - 1ms/step\n",
      "Epoch 52/500\n",
      "2/2 - 0s - loss: 2.7757 - mse: 2.7757 - 2ms/epoch - 1ms/step\n",
      "Epoch 53/500\n",
      "2/2 - 0s - loss: 2.0761 - mse: 2.0761 - 2ms/epoch - 1ms/step\n",
      "Epoch 54/500\n",
      "2/2 - 0s - loss: 2.2572 - mse: 2.2572 - 2ms/epoch - 1ms/step\n",
      "Epoch 55/500\n",
      "2/2 - 0s - loss: 1.8105 - mse: 1.8105 - 2ms/epoch - 981us/step\n",
      "Epoch 56/500\n",
      "2/2 - 0s - loss: 1.7616 - mse: 1.7616 - 3ms/epoch - 2ms/step\n",
      "Epoch 57/500\n",
      "2/2 - 0s - loss: 1.7590 - mse: 1.7590 - 3ms/epoch - 2ms/step\n",
      "Epoch 58/500\n",
      "2/2 - 0s - loss: 2.0056 - mse: 2.0056 - 2ms/epoch - 991us/step\n",
      "Epoch 59/500\n",
      "2/2 - 0s - loss: 2.6560 - mse: 2.6560 - 2ms/epoch - 1ms/step\n",
      "Epoch 60/500\n",
      "2/2 - 0s - loss: 1.8626 - mse: 1.8626 - 2ms/epoch - 1ms/step\n",
      "Epoch 61/500\n",
      "2/2 - 0s - loss: 1.8474 - mse: 1.8474 - 3ms/epoch - 2ms/step\n",
      "Epoch 62/500\n",
      "2/2 - 0s - loss: 2.0979 - mse: 2.0979 - 2ms/epoch - 1ms/step\n",
      "Epoch 63/500\n",
      "2/2 - 0s - loss: 1.8830 - mse: 1.8830 - 2ms/epoch - 1ms/step\n",
      "Epoch 64/500\n",
      "2/2 - 0s - loss: 2.2828 - mse: 2.2828 - 3ms/epoch - 1ms/step\n",
      "Epoch 65/500\n",
      "2/2 - 0s - loss: 2.1851 - mse: 2.1851 - 3ms/epoch - 2ms/step\n",
      "Epoch 66/500\n",
      "2/2 - 0s - loss: 2.2025 - mse: 2.2025 - 3ms/epoch - 1ms/step\n",
      "Epoch 67/500\n",
      "2/2 - 0s - loss: 2.2092 - mse: 2.2092 - 926us/epoch - 463us/step\n",
      "Epoch 68/500\n",
      "2/2 - 0s - loss: 1.7526 - mse: 1.7526 - 2ms/epoch - 976us/step\n",
      "Epoch 69/500\n",
      "2/2 - 0s - loss: 1.8378 - mse: 1.8378 - 3ms/epoch - 1ms/step\n",
      "Epoch 70/500\n",
      "2/2 - 0s - loss: 2.4068 - mse: 2.4068 - 2ms/epoch - 1000us/step\n",
      "Epoch 71/500\n",
      "2/2 - 0s - loss: 1.8931 - mse: 1.8931 - 2ms/epoch - 999us/step\n",
      "Epoch 72/500\n",
      "2/2 - 0s - loss: 2.5681 - mse: 2.5681 - 2ms/epoch - 1000us/step\n",
      "Epoch 73/500\n",
      "2/2 - 0s - loss: 2.2760 - mse: 2.2760 - 2ms/epoch - 1ms/step\n",
      "Epoch 74/500\n",
      "2/2 - 0s - loss: 2.0704 - mse: 2.0704 - 2ms/epoch - 977us/step\n",
      "Epoch 75/500\n",
      "2/2 - 0s - loss: 2.2141 - mse: 2.2141 - 2ms/epoch - 977us/step\n",
      "Epoch 76/500\n",
      "2/2 - 0s - loss: 1.9598 - mse: 1.9598 - 2ms/epoch - 976us/step\n",
      "Epoch 77/500\n",
      "2/2 - 0s - loss: 1.7416 - mse: 1.7416 - 2ms/epoch - 1ms/step\n",
      "Epoch 78/500\n",
      "2/2 - 0s - loss: 2.1193 - mse: 2.1193 - 2ms/epoch - 1ms/step\n",
      "Epoch 79/500\n",
      "2/2 - 0s - loss: 2.7147 - mse: 2.7147 - 2ms/epoch - 999us/step\n",
      "Epoch 80/500\n",
      "2/2 - 0s - loss: 2.0830 - mse: 2.0830 - 2ms/epoch - 1ms/step\n",
      "Epoch 81/500\n",
      "2/2 - 0s - loss: 2.1643 - mse: 2.1643 - 3ms/epoch - 2ms/step\n",
      "Epoch 82/500\n",
      "2/2 - 0s - loss: 1.8386 - mse: 1.8386 - 2ms/epoch - 999us/step\n",
      "Epoch 83/500\n",
      "2/2 - 0s - loss: 1.7232 - mse: 1.7232 - 3ms/epoch - 2ms/step\n",
      "Epoch 84/500\n",
      "2/2 - 0s - loss: 1.7277 - mse: 1.7277 - 2ms/epoch - 1000us/step\n",
      "Epoch 85/500\n",
      "2/2 - 0s - loss: 2.0863 - mse: 2.0863 - 3ms/epoch - 1ms/step\n",
      "Epoch 86/500\n",
      "2/2 - 0s - loss: 2.5015 - mse: 2.5015 - 3ms/epoch - 2ms/step\n",
      "Epoch 87/500\n",
      "2/2 - 0s - loss: 2.3022 - mse: 2.3022 - 2ms/epoch - 993us/step\n",
      "Epoch 88/500\n",
      "2/2 - 0s - loss: 2.1425 - mse: 2.1425 - 1000us/epoch - 500us/step\n",
      "Epoch 89/500\n",
      "2/2 - 0s - loss: 1.7327 - mse: 1.7327 - 2ms/epoch - 1ms/step\n",
      "Epoch 90/500\n",
      "2/2 - 0s - loss: 1.7340 - mse: 1.7340 - 2ms/epoch - 998us/step\n",
      "Epoch 91/500\n",
      "2/2 - 0s - loss: 1.7170 - mse: 1.7170 - 3ms/epoch - 1ms/step\n",
      "Epoch 92/500\n",
      "2/2 - 0s - loss: 1.9838 - mse: 1.9838 - 2ms/epoch - 1000us/step\n",
      "Epoch 93/500\n",
      "2/2 - 0s - loss: 1.7359 - mse: 1.7359 - 3ms/epoch - 2ms/step\n",
      "Epoch 94/500\n",
      "2/2 - 0s - loss: 2.1457 - mse: 2.1457 - 2ms/epoch - 999us/step\n",
      "Epoch 95/500\n",
      "2/2 - 0s - loss: 2.5388 - mse: 2.5388 - 2ms/epoch - 1ms/step\n",
      "Epoch 96/500\n",
      "2/2 - 0s - loss: 1.7547 - mse: 1.7547 - 3ms/epoch - 1ms/step\n",
      "Epoch 97/500\n",
      "2/2 - 0s - loss: 1.7605 - mse: 1.7605 - 2ms/epoch - 996us/step\n",
      "Epoch 98/500\n",
      "2/2 - 0s - loss: 2.3775 - mse: 2.3775 - 3ms/epoch - 2ms/step\n",
      "Epoch 99/500\n",
      "2/2 - 0s - loss: 2.6019 - mse: 2.6019 - 997us/epoch - 498us/step\n",
      "Epoch 100/500\n",
      "2/2 - 0s - loss: 1.8803 - mse: 1.8803 - 2ms/epoch - 1000us/step\n",
      "Epoch 101/500\n",
      "2/2 - 0s - loss: 1.7025 - mse: 1.7025 - 2ms/epoch - 997us/step\n",
      "Epoch 102/500\n",
      "2/2 - 0s - loss: 1.7339 - mse: 1.7339 - 996us/epoch - 498us/step\n",
      "Epoch 103/500\n",
      "2/2 - 0s - loss: 1.8271 - mse: 1.8271 - 2ms/epoch - 997us/step\n",
      "Epoch 104/500\n",
      "2/2 - 0s - loss: 2.7397 - mse: 2.7397 - 2ms/epoch - 1ms/step\n",
      "Epoch 105/500\n",
      "2/2 - 0s - loss: 1.8771 - mse: 1.8771 - 2ms/epoch - 1ms/step\n",
      "Epoch 106/500\n",
      "2/2 - 0s - loss: 2.2690 - mse: 2.2690 - 2ms/epoch - 1ms/step\n",
      "Epoch 107/500\n",
      "2/2 - 0s - loss: 2.3314 - mse: 2.3314 - 1ms/epoch - 503us/step\n",
      "Epoch 108/500\n",
      "2/2 - 0s - loss: 1.9247 - mse: 1.9247 - 2ms/epoch - 1ms/step\n",
      "Epoch 109/500\n",
      "2/2 - 0s - loss: 2.6321 - mse: 2.6321 - 2ms/epoch - 1000us/step\n",
      "Epoch 110/500\n",
      "2/2 - 0s - loss: 2.4565 - mse: 2.4565 - 2ms/epoch - 997us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/500\n",
      "2/2 - 0s - loss: 2.3741 - mse: 2.3741 - 2ms/epoch - 1ms/step\n",
      "Epoch 112/500\n",
      "2/2 - 0s - loss: 1.7542 - mse: 1.7542 - 2ms/epoch - 997us/step\n",
      "Epoch 113/500\n",
      "2/2 - 0s - loss: 2.7257 - mse: 2.7257 - 2ms/epoch - 1ms/step\n",
      "Epoch 114/500\n",
      "2/2 - 0s - loss: 2.6195 - mse: 2.6195 - 2ms/epoch - 991us/step\n",
      "Epoch 115/500\n",
      "2/2 - 0s - loss: 1.7656 - mse: 1.7656 - 1ms/epoch - 503us/step\n",
      "Epoch 116/500\n",
      "2/2 - 0s - loss: 1.7190 - mse: 1.7190 - 2ms/epoch - 1ms/step\n",
      "Epoch 117/500\n",
      "2/2 - 0s - loss: 2.2863 - mse: 2.2863 - 2ms/epoch - 1000us/step\n",
      "Epoch 118/500\n",
      "2/2 - 0s - loss: 1.7933 - mse: 1.7933 - 2ms/epoch - 998us/step\n",
      "Epoch 119/500\n",
      "2/2 - 0s - loss: 2.1355 - mse: 2.1355 - 3ms/epoch - 1ms/step\n",
      "Epoch 120/500\n",
      "2/2 - 0s - loss: 2.2342 - mse: 2.2342 - 2ms/epoch - 996us/step\n",
      "Epoch 121/500\n",
      "2/2 - 0s - loss: 1.7548 - mse: 1.7548 - 2ms/epoch - 1000us/step\n",
      "Epoch 122/500\n",
      "2/2 - 0s - loss: 1.9819 - mse: 1.9819 - 2ms/epoch - 997us/step\n",
      "Epoch 123/500\n",
      "2/2 - 0s - loss: 1.9241 - mse: 1.9241 - 1ms/epoch - 500us/step\n",
      "Epoch 124/500\n",
      "2/2 - 0s - loss: 2.1909 - mse: 2.1909 - 2ms/epoch - 998us/step\n",
      "Epoch 125/500\n",
      "2/2 - 0s - loss: 2.6607 - mse: 2.6607 - 2ms/epoch - 999us/step\n",
      "Epoch 126/500\n",
      "2/2 - 0s - loss: 1.7408 - mse: 1.7408 - 3ms/epoch - 1ms/step\n",
      "Epoch 127/500\n",
      "2/2 - 0s - loss: 1.7304 - mse: 1.7304 - 2ms/epoch - 796us/step\n",
      "Epoch 128/500\n",
      "2/2 - 0s - loss: 2.1119 - mse: 2.1119 - 2ms/epoch - 1ms/step\n",
      "Epoch 129/500\n",
      "2/2 - 0s - loss: 1.7017 - mse: 1.7017 - 2ms/epoch - 789us/step\n",
      "Epoch 130/500\n",
      "2/2 - 0s - loss: 1.7014 - mse: 1.7014 - 1ms/epoch - 522us/step\n",
      "Epoch 131/500\n",
      "2/2 - 0s - loss: 2.0193 - mse: 2.0193 - 2ms/epoch - 996us/step\n",
      "Epoch 132/500\n",
      "2/2 - 0s - loss: 1.6579 - mse: 1.6579 - 2ms/epoch - 1ms/step\n",
      "Epoch 133/500\n",
      "2/2 - 0s - loss: 2.6031 - mse: 2.6031 - 1ms/epoch - 501us/step\n",
      "Epoch 134/500\n",
      "2/2 - 0s - loss: 2.0487 - mse: 2.0487 - 2ms/epoch - 1000us/step\n",
      "Epoch 135/500\n",
      "2/2 - 0s - loss: 1.7358 - mse: 1.7358 - 997us/epoch - 498us/step\n",
      "Epoch 136/500\n",
      "2/2 - 0s - loss: 2.0694 - mse: 2.0694 - 2ms/epoch - 1000us/step\n",
      "Epoch 137/500\n",
      "2/2 - 0s - loss: 1.6831 - mse: 1.6831 - 2ms/epoch - 992us/step\n",
      "Epoch 138/500\n",
      "2/2 - 0s - loss: 1.8072 - mse: 1.8072 - 2ms/epoch - 1ms/step\n",
      "Epoch 139/500\n",
      "2/2 - 0s - loss: 1.9179 - mse: 1.9179 - 2ms/epoch - 999us/step\n",
      "Epoch 140/500\n",
      "2/2 - 0s - loss: 1.8091 - mse: 1.8091 - 994us/epoch - 497us/step\n",
      "Epoch 141/500\n",
      "2/2 - 0s - loss: 1.6602 - mse: 1.6602 - 2ms/epoch - 1000us/step\n",
      "Epoch 142/500\n",
      "2/2 - 0s - loss: 1.6384 - mse: 1.6384 - 2ms/epoch - 997us/step\n",
      "Epoch 143/500\n",
      "2/2 - 0s - loss: 2.3078 - mse: 2.3078 - 2ms/epoch - 999us/step\n",
      "Epoch 144/500\n",
      "2/2 - 0s - loss: 2.1579 - mse: 2.1579 - 996us/epoch - 498us/step\n",
      "Epoch 145/500\n",
      "2/2 - 0s - loss: 2.1864 - mse: 2.1864 - 3ms/epoch - 2ms/step\n",
      "Epoch 146/500\n",
      "2/2 - 0s - loss: 1.8080 - mse: 1.8080 - 1ms/epoch - 500us/step\n",
      "Epoch 147/500\n",
      "2/2 - 0s - loss: 1.6816 - mse: 1.6816 - 2ms/epoch - 1ms/step\n",
      "Epoch 148/500\n",
      "2/2 - 0s - loss: 2.3310 - mse: 2.3310 - 2ms/epoch - 997us/step\n",
      "Epoch 149/500\n",
      "2/2 - 0s - loss: 2.3271 - mse: 2.3271 - 3ms/epoch - 2ms/step\n",
      "Epoch 150/500\n",
      "2/2 - 0s - loss: 2.0022 - mse: 2.0022 - 2ms/epoch - 1ms/step\n",
      "Epoch 151/500\n",
      "2/2 - 0s - loss: 1.6950 - mse: 1.6950 - 2ms/epoch - 997us/step\n",
      "Epoch 152/500\n",
      "2/2 - 0s - loss: 1.6444 - mse: 1.6444 - 2ms/epoch - 1000us/step\n",
      "Epoch 153/500\n",
      "2/2 - 0s - loss: 2.8931 - mse: 2.8931 - 2ms/epoch - 1000us/step\n",
      "Epoch 154/500\n",
      "2/2 - 0s - loss: 2.0937 - mse: 2.0937 - 2ms/epoch - 1ms/step\n",
      "Epoch 155/500\n",
      "2/2 - 0s - loss: 1.7989 - mse: 1.7989 - 2ms/epoch - 1ms/step\n",
      "Epoch 156/500\n",
      "2/2 - 0s - loss: 2.3509 - mse: 2.3509 - 2ms/epoch - 998us/step\n",
      "Epoch 157/500\n",
      "2/2 - 0s - loss: 1.7289 - mse: 1.7289 - 1ms/epoch - 501us/step\n",
      "Epoch 158/500\n",
      "2/2 - 0s - loss: 1.9044 - mse: 1.9044 - 2ms/epoch - 1ms/step\n",
      "Epoch 159/500\n",
      "2/2 - 0s - loss: 2.5879 - mse: 2.5879 - 1ms/epoch - 500us/step\n",
      "Epoch 160/500\n",
      "2/2 - 0s - loss: 1.7289 - mse: 1.7289 - 2ms/epoch - 1ms/step\n",
      "Epoch 161/500\n",
      "2/2 - 0s - loss: 1.6564 - mse: 1.6564 - 2ms/epoch - 1ms/step\n",
      "Epoch 162/500\n",
      "2/2 - 0s - loss: 1.7535 - mse: 1.7535 - 2ms/epoch - 1000us/step\n",
      "Epoch 163/500\n",
      "2/2 - 0s - loss: 1.6826 - mse: 1.6826 - 998us/epoch - 499us/step\n",
      "Epoch 164/500\n",
      "2/2 - 0s - loss: 1.8501 - mse: 1.8501 - 982us/epoch - 491us/step\n",
      "Epoch 165/500\n",
      "2/2 - 0s - loss: 2.2005 - mse: 2.2005 - 2ms/epoch - 997us/step\n",
      "Epoch 166/500\n",
      "2/2 - 0s - loss: 2.0324 - mse: 2.0324 - 2ms/epoch - 999us/step\n",
      "Epoch 167/500\n",
      "2/2 - 0s - loss: 1.8440 - mse: 1.8440 - 995us/epoch - 497us/step\n",
      "Epoch 168/500\n",
      "2/2 - 0s - loss: 1.6686 - mse: 1.6686 - 1000us/epoch - 500us/step\n",
      "Epoch 169/500\n",
      "2/2 - 0s - loss: 1.6091 - mse: 1.6091 - 2ms/epoch - 1ms/step\n",
      "Epoch 170/500\n",
      "2/2 - 0s - loss: 2.0128 - mse: 2.0128 - 2ms/epoch - 1ms/step\n",
      "Epoch 171/500\n",
      "2/2 - 0s - loss: 3.1215 - mse: 3.1215 - 997us/epoch - 499us/step\n",
      "Epoch 172/500\n",
      "2/2 - 0s - loss: 1.8278 - mse: 1.8278 - 2ms/epoch - 1ms/step\n",
      "Epoch 173/500\n",
      "2/2 - 0s - loss: 2.0017 - mse: 2.0017 - 2ms/epoch - 1ms/step\n",
      "Epoch 174/500\n",
      "2/2 - 0s - loss: 1.6500 - mse: 1.6500 - 2ms/epoch - 1ms/step\n",
      "Epoch 175/500\n",
      "2/2 - 0s - loss: 1.6792 - mse: 1.6792 - 1000us/epoch - 500us/step\n",
      "Epoch 176/500\n",
      "2/2 - 0s - loss: 1.6488 - mse: 1.6488 - 2ms/epoch - 997us/step\n",
      "Epoch 177/500\n",
      "2/2 - 0s - loss: 1.6097 - mse: 1.6097 - 994us/epoch - 497us/step\n",
      "Epoch 178/500\n",
      "2/2 - 0s - loss: 1.8203 - mse: 1.8203 - 994us/epoch - 497us/step\n",
      "Epoch 179/500\n",
      "2/2 - 0s - loss: 2.1051 - mse: 2.1051 - 2ms/epoch - 998us/step\n",
      "Epoch 180/500\n",
      "2/2 - 0s - loss: 2.2238 - mse: 2.2238 - 2ms/epoch - 1ms/step\n",
      "Epoch 181/500\n",
      "2/2 - 0s - loss: 1.6664 - mse: 1.6664 - 2ms/epoch - 1ms/step\n",
      "Epoch 182/500\n",
      "2/2 - 0s - loss: 1.7512 - mse: 1.7512 - 996us/epoch - 498us/step\n",
      "Epoch 183/500\n",
      "2/2 - 0s - loss: 1.6187 - mse: 1.6187 - 998us/epoch - 499us/step\n",
      "Epoch 184/500\n",
      "2/2 - 0s - loss: 2.4041 - mse: 2.4041 - 1ms/epoch - 501us/step\n",
      "Epoch 185/500\n",
      "2/2 - 0s - loss: 2.2220 - mse: 2.2220 - 2ms/epoch - 978us/step\n",
      "Epoch 186/500\n",
      "2/2 - 0s - loss: 2.1387 - mse: 2.1387 - 2ms/epoch - 1ms/step\n",
      "Epoch 187/500\n",
      "2/2 - 0s - loss: 1.6436 - mse: 1.6436 - 2ms/epoch - 1ms/step\n",
      "Epoch 188/500\n",
      "2/2 - 0s - loss: 1.7433 - mse: 1.7433 - 2ms/epoch - 1ms/step\n",
      "Epoch 189/500\n",
      "2/2 - 0s - loss: 3.9069 - mse: 3.9069 - 2ms/epoch - 1ms/step\n",
      "Epoch 190/500\n",
      "2/2 - 0s - loss: 1.7850 - mse: 1.7850 - 2ms/epoch - 967us/step\n",
      "Epoch 191/500\n",
      "2/2 - 0s - loss: 1.8861 - mse: 1.8861 - 2ms/epoch - 976us/step\n",
      "Epoch 192/500\n",
      "2/2 - 0s - loss: 1.9217 - mse: 1.9217 - 3ms/epoch - 2ms/step\n",
      "Epoch 193/500\n",
      "2/2 - 0s - loss: 1.5876 - mse: 1.5876 - 961us/epoch - 481us/step\n",
      "Epoch 194/500\n",
      "2/2 - 0s - loss: 1.6860 - mse: 1.6860 - 2ms/epoch - 1ms/step\n",
      "Epoch 195/500\n",
      "2/2 - 0s - loss: 1.7252 - mse: 1.7252 - 2ms/epoch - 963us/step\n",
      "Epoch 196/500\n",
      "2/2 - 0s - loss: 1.8616 - mse: 1.8616 - 998us/epoch - 499us/step\n",
      "Epoch 197/500\n",
      "2/2 - 0s - loss: 1.8428 - mse: 1.8428 - 998us/epoch - 499us/step\n",
      "Epoch 198/500\n",
      "2/2 - 0s - loss: 1.8272 - mse: 1.8272 - 2ms/epoch - 997us/step\n",
      "Epoch 199/500\n",
      "2/2 - 0s - loss: 2.2273 - mse: 2.2273 - 2ms/epoch - 1ms/step\n",
      "Epoch 200/500\n",
      "2/2 - 0s - loss: 2.0394 - mse: 2.0394 - 2ms/epoch - 1000us/step\n",
      "Epoch 201/500\n",
      "2/2 - 0s - loss: 1.5736 - mse: 1.5736 - 998us/epoch - 499us/step\n",
      "Epoch 202/500\n",
      "2/2 - 0s - loss: 1.5719 - mse: 1.5719 - 1ms/epoch - 502us/step\n",
      "Epoch 203/500\n",
      "2/2 - 0s - loss: 1.6396 - mse: 1.6396 - 994us/epoch - 497us/step\n",
      "Epoch 204/500\n",
      "2/2 - 0s - loss: 1.6155 - mse: 1.6155 - 1ms/epoch - 503us/step\n",
      "Epoch 205/500\n",
      "2/2 - 0s - loss: 1.5818 - mse: 1.5818 - 2ms/epoch - 997us/step\n",
      "Epoch 206/500\n",
      "2/2 - 0s - loss: 2.8859 - mse: 2.8859 - 993us/epoch - 497us/step\n",
      "Epoch 207/500\n",
      "2/2 - 0s - loss: 3.1413 - mse: 3.1413 - 2ms/epoch - 1ms/step\n",
      "Epoch 208/500\n",
      "2/2 - 0s - loss: 1.6785 - mse: 1.6785 - 3ms/epoch - 1ms/step\n",
      "Epoch 209/500\n",
      "2/2 - 0s - loss: 1.8027 - mse: 1.8027 - 2ms/epoch - 1ms/step\n",
      "Epoch 210/500\n",
      "2/2 - 0s - loss: 1.5812 - mse: 1.5812 - 2ms/epoch - 1ms/step\n",
      "Epoch 211/500\n",
      "2/2 - 0s - loss: 1.5860 - mse: 1.5860 - 993us/epoch - 497us/step\n",
      "Epoch 212/500\n",
      "2/2 - 0s - loss: 1.5656 - mse: 1.5656 - 2ms/epoch - 1ms/step\n",
      "Epoch 213/500\n",
      "2/2 - 0s - loss: 1.7215 - mse: 1.7215 - 1ms/epoch - 660us/step\n",
      "Epoch 214/500\n",
      "2/2 - 0s - loss: 2.1171 - mse: 2.1171 - 3ms/epoch - 2ms/step\n",
      "Epoch 215/500\n",
      "2/2 - 0s - loss: 2.0302 - mse: 2.0302 - 2ms/epoch - 999us/step\n",
      "Epoch 216/500\n",
      "2/2 - 0s - loss: 1.5638 - mse: 1.5638 - 2ms/epoch - 968us/step\n",
      "Epoch 217/500\n",
      "2/2 - 0s - loss: 1.8980 - mse: 1.8980 - 995us/epoch - 498us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218/500\n",
      "2/2 - 0s - loss: 2.0844 - mse: 2.0844 - 2ms/epoch - 999us/step\n",
      "Epoch 219/500\n",
      "2/2 - 0s - loss: 2.8012 - mse: 2.8012 - 2ms/epoch - 1000us/step\n",
      "Epoch 220/500\n",
      "2/2 - 0s - loss: 2.6839 - mse: 2.6839 - 1ms/epoch - 503us/step\n",
      "Epoch 221/500\n",
      "2/2 - 0s - loss: 2.1046 - mse: 2.1046 - 1ms/epoch - 503us/step\n",
      "Epoch 222/500\n",
      "2/2 - 0s - loss: 1.5706 - mse: 1.5706 - 3ms/epoch - 2ms/step\n",
      "Epoch 223/500\n",
      "2/2 - 0s - loss: 1.7070 - mse: 1.7070 - 2ms/epoch - 1ms/step\n",
      "Epoch 224/500\n",
      "2/2 - 0s - loss: 1.6453 - mse: 1.6453 - 2ms/epoch - 1000us/step\n",
      "Epoch 225/500\n",
      "2/2 - 0s - loss: 1.9361 - mse: 1.9361 - 2ms/epoch - 1ms/step\n",
      "Epoch 226/500\n",
      "2/2 - 0s - loss: 1.6105 - mse: 1.6105 - 2ms/epoch - 974us/step\n",
      "Epoch 227/500\n",
      "2/2 - 0s - loss: 2.2983 - mse: 2.2983 - 2ms/epoch - 1ms/step\n",
      "Epoch 228/500\n",
      "2/2 - 0s - loss: 1.7680 - mse: 1.7680 - 2ms/epoch - 1ms/step\n",
      "Epoch 229/500\n",
      "2/2 - 0s - loss: 1.5397 - mse: 1.5397 - 2ms/epoch - 997us/step\n",
      "Epoch 230/500\n",
      "2/2 - 0s - loss: 1.6111 - mse: 1.6111 - 2ms/epoch - 1ms/step\n",
      "Epoch 231/500\n",
      "2/2 - 0s - loss: 2.4419 - mse: 2.4419 - 2ms/epoch - 1ms/step\n",
      "Epoch 232/500\n",
      "2/2 - 0s - loss: 1.5905 - mse: 1.5905 - 2ms/epoch - 996us/step\n",
      "Epoch 233/500\n",
      "2/2 - 0s - loss: 1.6088 - mse: 1.6088 - 1ms/epoch - 642us/step\n",
      "Epoch 234/500\n",
      "2/2 - 0s - loss: 1.9505 - mse: 1.9505 - 2ms/epoch - 1ms/step\n",
      "Epoch 235/500\n",
      "2/2 - 0s - loss: 2.2661 - mse: 2.2661 - 3ms/epoch - 2ms/step\n",
      "Epoch 236/500\n",
      "2/2 - 0s - loss: 2.1256 - mse: 2.1256 - 989us/epoch - 494us/step\n",
      "Epoch 237/500\n",
      "2/2 - 0s - loss: 1.5815 - mse: 1.5815 - 1ms/epoch - 502us/step\n",
      "Epoch 238/500\n",
      "2/2 - 0s - loss: 1.7565 - mse: 1.7565 - 2ms/epoch - 974us/step\n",
      "Epoch 239/500\n",
      "2/2 - 0s - loss: 1.6779 - mse: 1.6779 - 2ms/epoch - 999us/step\n",
      "Epoch 240/500\n",
      "2/2 - 0s - loss: 1.6928 - mse: 1.6928 - 2ms/epoch - 960us/step\n",
      "Epoch 241/500\n",
      "2/2 - 0s - loss: 2.2368 - mse: 2.2368 - 2ms/epoch - 1ms/step\n",
      "Epoch 242/500\n",
      "2/2 - 0s - loss: 2.4146 - mse: 2.4146 - 3ms/epoch - 1ms/step\n",
      "Epoch 243/500\n",
      "2/2 - 0s - loss: 1.9590 - mse: 1.9590 - 2ms/epoch - 1ms/step\n",
      "Epoch 244/500\n",
      "2/2 - 0s - loss: 1.8741 - mse: 1.8741 - 988us/epoch - 494us/step\n",
      "Epoch 245/500\n",
      "2/2 - 0s - loss: 1.5794 - mse: 1.5794 - 2ms/epoch - 1ms/step\n",
      "Epoch 246/500\n",
      "2/2 - 0s - loss: 1.7903 - mse: 1.7903 - 3ms/epoch - 2ms/step\n",
      "Epoch 247/500\n",
      "2/2 - 0s - loss: 2.4736 - mse: 2.4736 - 938us/epoch - 469us/step\n",
      "Epoch 248/500\n",
      "2/2 - 0s - loss: 1.8010 - mse: 1.8010 - 2ms/epoch - 981us/step\n",
      "Epoch 249/500\n",
      "2/2 - 0s - loss: 1.5175 - mse: 1.5175 - 2ms/epoch - 1ms/step\n",
      "Epoch 250/500\n",
      "2/2 - 0s - loss: 1.5845 - mse: 1.5845 - 2ms/epoch - 948us/step\n",
      "Epoch 251/500\n",
      "2/2 - 0s - loss: 1.8047 - mse: 1.8047 - 2ms/epoch - 1ms/step\n",
      "Epoch 252/500\n",
      "2/2 - 0s - loss: 1.8324 - mse: 1.8324 - 2ms/epoch - 1ms/step\n",
      "Epoch 253/500\n",
      "2/2 - 0s - loss: 2.1916 - mse: 2.1916 - 2ms/epoch - 969us/step\n",
      "Epoch 254/500\n",
      "2/2 - 0s - loss: 1.8700 - mse: 1.8700 - 2ms/epoch - 975us/step\n",
      "Epoch 255/500\n",
      "2/2 - 0s - loss: 1.7055 - mse: 1.7055 - 3ms/epoch - 1ms/step\n",
      "Epoch 256/500\n",
      "2/2 - 0s - loss: 1.7077 - mse: 1.7077 - 2ms/epoch - 1ms/step\n",
      "Epoch 257/500\n",
      "2/2 - 0s - loss: 2.6769 - mse: 2.6769 - 2ms/epoch - 1ms/step\n",
      "Epoch 258/500\n",
      "2/2 - 0s - loss: 1.6276 - mse: 1.6276 - 2ms/epoch - 968us/step\n",
      "Epoch 259/500\n",
      "2/2 - 0s - loss: 1.6491 - mse: 1.6491 - 2ms/epoch - 967us/step\n",
      "Epoch 260/500\n",
      "2/2 - 0s - loss: 2.0971 - mse: 2.0971 - 2ms/epoch - 1ms/step\n",
      "Epoch 261/500\n",
      "2/2 - 0s - loss: 1.5151 - mse: 1.5151 - 2ms/epoch - 1ms/step\n",
      "Epoch 262/500\n",
      "2/2 - 0s - loss: 1.6045 - mse: 1.6045 - 3ms/epoch - 2ms/step\n",
      "Epoch 263/500\n",
      "2/2 - 0s - loss: 1.5044 - mse: 1.5044 - 2ms/epoch - 1ms/step\n",
      "Epoch 264/500\n",
      "2/2 - 0s - loss: 2.2279 - mse: 2.2279 - 2ms/epoch - 957us/step\n",
      "Epoch 265/500\n",
      "2/2 - 0s - loss: 2.2390 - mse: 2.2390 - 2ms/epoch - 1ms/step\n",
      "Epoch 266/500\n",
      "2/2 - 0s - loss: 1.6045 - mse: 1.6045 - 2ms/epoch - 961us/step\n",
      "Epoch 267/500\n",
      "2/2 - 0s - loss: 1.9968 - mse: 1.9968 - 3ms/epoch - 1ms/step\n",
      "Epoch 268/500\n",
      "2/2 - 0s - loss: 1.7672 - mse: 1.7672 - 1000us/epoch - 500us/step\n",
      "Epoch 269/500\n",
      "2/2 - 0s - loss: 1.7740 - mse: 1.7740 - 2ms/epoch - 1000us/step\n",
      "Epoch 270/500\n",
      "2/2 - 0s - loss: 1.7179 - mse: 1.7179 - 3ms/epoch - 1ms/step\n",
      "Epoch 271/500\n",
      "2/2 - 0s - loss: 1.5203 - mse: 1.5203 - 4ms/epoch - 2ms/step\n",
      "Epoch 272/500\n",
      "2/2 - 0s - loss: 1.5738 - mse: 1.5738 - 3ms/epoch - 2ms/step\n",
      "Epoch 273/500\n",
      "2/2 - 0s - loss: 1.7891 - mse: 1.7891 - 3ms/epoch - 2ms/step\n",
      "Epoch 274/500\n",
      "2/2 - 0s - loss: 1.6870 - mse: 1.6870 - 3ms/epoch - 2ms/step\n",
      "Epoch 275/500\n",
      "2/2 - 0s - loss: 1.8328 - mse: 1.8328 - 3ms/epoch - 1ms/step\n",
      "Epoch 276/500\n",
      "2/2 - 0s - loss: 1.7145 - mse: 1.7145 - 2ms/epoch - 1ms/step\n",
      "Epoch 277/500\n",
      "2/2 - 0s - loss: 1.9638 - mse: 1.9638 - 3ms/epoch - 2ms/step\n",
      "Epoch 278/500\n",
      "2/2 - 0s - loss: 1.5138 - mse: 1.5138 - 2ms/epoch - 1ms/step\n",
      "Epoch 279/500\n",
      "2/2 - 0s - loss: 1.4849 - mse: 1.4849 - 3ms/epoch - 1ms/step\n",
      "Epoch 280/500\n",
      "2/2 - 0s - loss: 1.5307 - mse: 1.5307 - 3ms/epoch - 1ms/step\n",
      "Epoch 281/500\n",
      "2/2 - 0s - loss: 1.6808 - mse: 1.6808 - 2ms/epoch - 980us/step\n",
      "Epoch 282/500\n",
      "2/2 - 0s - loss: 2.2149 - mse: 2.2149 - 2ms/epoch - 1ms/step\n",
      "Epoch 283/500\n",
      "2/2 - 0s - loss: 1.9092 - mse: 1.9092 - 3ms/epoch - 2ms/step\n",
      "Epoch 284/500\n",
      "2/2 - 0s - loss: 1.4920 - mse: 1.4920 - 3ms/epoch - 1ms/step\n",
      "Epoch 285/500\n",
      "2/2 - 0s - loss: 1.7940 - mse: 1.7940 - 4ms/epoch - 2ms/step\n",
      "Epoch 286/500\n",
      "2/2 - 0s - loss: 1.7397 - mse: 1.7397 - 4ms/epoch - 2ms/step\n",
      "Epoch 287/500\n",
      "2/2 - 0s - loss: 1.5858 - mse: 1.5858 - 3ms/epoch - 1ms/step\n",
      "Epoch 288/500\n",
      "2/2 - 0s - loss: 2.0538 - mse: 2.0538 - 2ms/epoch - 1ms/step\n",
      "Epoch 289/500\n",
      "2/2 - 0s - loss: 1.6938 - mse: 1.6938 - 2ms/epoch - 999us/step\n",
      "Epoch 290/500\n",
      "2/2 - 0s - loss: 1.4908 - mse: 1.4908 - 2ms/epoch - 957us/step\n",
      "Epoch 291/500\n",
      "2/2 - 0s - loss: 1.8220 - mse: 1.8220 - 3ms/epoch - 1ms/step\n",
      "Epoch 292/500\n",
      "2/2 - 0s - loss: 2.4909 - mse: 2.4909 - 3ms/epoch - 1ms/step\n",
      "Epoch 293/500\n",
      "2/2 - 0s - loss: 1.6002 - mse: 1.6002 - 2ms/epoch - 998us/step\n",
      "Epoch 294/500\n",
      "2/2 - 0s - loss: 1.7158 - mse: 1.7158 - 3ms/epoch - 1ms/step\n",
      "Epoch 295/500\n",
      "2/2 - 0s - loss: 2.4079 - mse: 2.4079 - 3ms/epoch - 2ms/step\n",
      "Epoch 296/500\n",
      "2/2 - 0s - loss: 1.6073 - mse: 1.6073 - 1ms/epoch - 689us/step\n",
      "Epoch 297/500\n",
      "2/2 - 0s - loss: 1.5461 - mse: 1.5461 - 2ms/epoch - 1ms/step\n",
      "Epoch 298/500\n",
      "2/2 - 0s - loss: 1.4691 - mse: 1.4691 - 2ms/epoch - 1ms/step\n",
      "Epoch 299/500\n",
      "2/2 - 0s - loss: 1.6645 - mse: 1.6645 - 2ms/epoch - 988us/step\n",
      "Epoch 300/500\n",
      "2/2 - 0s - loss: 1.4479 - mse: 1.4479 - 2ms/epoch - 1ms/step\n",
      "Epoch 301/500\n",
      "2/2 - 0s - loss: 2.0845 - mse: 2.0845 - 2ms/epoch - 976us/step\n",
      "Epoch 302/500\n",
      "2/2 - 0s - loss: 1.6258 - mse: 1.6258 - 2ms/epoch - 999us/step\n",
      "Epoch 303/500\n",
      "2/2 - 0s - loss: 1.4680 - mse: 1.4680 - 2ms/epoch - 1ms/step\n",
      "Epoch 304/500\n",
      "2/2 - 0s - loss: 1.5488 - mse: 1.5488 - 2ms/epoch - 1ms/step\n",
      "Epoch 305/500\n",
      "2/2 - 0s - loss: 1.9596 - mse: 1.9596 - 2ms/epoch - 974us/step\n",
      "Epoch 306/500\n",
      "2/2 - 0s - loss: 2.2048 - mse: 2.2048 - 2ms/epoch - 975us/step\n",
      "Epoch 307/500\n",
      "2/2 - 0s - loss: 1.5790 - mse: 1.5790 - 2ms/epoch - 980us/step\n",
      "Epoch 308/500\n",
      "2/2 - 0s - loss: 1.5663 - mse: 1.5663 - 2ms/epoch - 850us/step\n",
      "Epoch 309/500\n",
      "2/2 - 0s - loss: 1.6017 - mse: 1.6017 - 2ms/epoch - 967us/step\n",
      "Epoch 310/500\n",
      "2/2 - 0s - loss: 1.4478 - mse: 1.4478 - 2ms/epoch - 1ms/step\n",
      "Epoch 311/500\n",
      "2/2 - 0s - loss: 1.6741 - mse: 1.6741 - 2ms/epoch - 974us/step\n",
      "Epoch 312/500\n",
      "2/2 - 0s - loss: 1.4592 - mse: 1.4592 - 2ms/epoch - 1ms/step\n",
      "Epoch 313/500\n",
      "2/2 - 0s - loss: 1.7181 - mse: 1.7181 - 2ms/epoch - 1ms/step\n",
      "Epoch 314/500\n",
      "2/2 - 0s - loss: 1.7525 - mse: 1.7525 - 2ms/epoch - 1ms/step\n",
      "Epoch 315/500\n",
      "2/2 - 0s - loss: 2.8602 - mse: 2.8602 - 2ms/epoch - 1ms/step\n",
      "Epoch 316/500\n",
      "2/2 - 0s - loss: 1.5755 - mse: 1.5755 - 2ms/epoch - 1000us/step\n",
      "Epoch 317/500\n",
      "2/2 - 0s - loss: 1.4469 - mse: 1.4469 - 2ms/epoch - 1000us/step\n",
      "Epoch 318/500\n",
      "2/2 - 0s - loss: 1.4476 - mse: 1.4476 - 2ms/epoch - 1ms/step\n",
      "Epoch 319/500\n",
      "2/2 - 0s - loss: 1.5734 - mse: 1.5734 - 3ms/epoch - 1ms/step\n",
      "Epoch 320/500\n",
      "2/2 - 0s - loss: 1.6085 - mse: 1.6085 - 2ms/epoch - 1ms/step\n",
      "Epoch 321/500\n",
      "2/2 - 0s - loss: 1.8483 - mse: 1.8483 - 2ms/epoch - 1ms/step\n",
      "Epoch 322/500\n",
      "2/2 - 0s - loss: 1.4792 - mse: 1.4792 - 1ms/epoch - 747us/step\n",
      "Epoch 323/500\n",
      "2/2 - 0s - loss: 1.5124 - mse: 1.5124 - 2ms/epoch - 1ms/step\n",
      "Epoch 324/500\n",
      "2/2 - 0s - loss: 2.4301 - mse: 2.4301 - 2ms/epoch - 999us/step\n",
      "Epoch 325/500\n",
      "2/2 - 0s - loss: 2.8236 - mse: 2.8236 - 994us/epoch - 497us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 326/500\n",
      "2/2 - 0s - loss: 1.4791 - mse: 1.4791 - 2ms/epoch - 993us/step\n",
      "Epoch 327/500\n",
      "2/2 - 0s - loss: 1.6266 - mse: 1.6266 - 2ms/epoch - 1ms/step\n",
      "Epoch 328/500\n",
      "2/2 - 0s - loss: 1.4479 - mse: 1.4479 - 3ms/epoch - 1ms/step\n",
      "Epoch 329/500\n",
      "2/2 - 0s - loss: 1.4590 - mse: 1.4590 - 2ms/epoch - 1ms/step\n",
      "Epoch 330/500\n",
      "2/2 - 0s - loss: 1.4991 - mse: 1.4991 - 2ms/epoch - 1ms/step\n",
      "Epoch 331/500\n",
      "2/2 - 0s - loss: 1.9879 - mse: 1.9879 - 2ms/epoch - 1ms/step\n",
      "Epoch 332/500\n",
      "2/2 - 0s - loss: 1.8026 - mse: 1.8026 - 1000us/epoch - 500us/step\n",
      "Epoch 333/500\n",
      "2/2 - 0s - loss: 1.5137 - mse: 1.5137 - 2ms/epoch - 1000us/step\n",
      "Epoch 334/500\n",
      "2/2 - 0s - loss: 1.5524 - mse: 1.5524 - 2ms/epoch - 1ms/step\n",
      "Epoch 335/500\n",
      "2/2 - 0s - loss: 1.9952 - mse: 1.9952 - 2ms/epoch - 1ms/step\n",
      "Epoch 336/500\n",
      "2/2 - 0s - loss: 1.7564 - mse: 1.7564 - 2ms/epoch - 1ms/step\n",
      "Epoch 337/500\n",
      "2/2 - 0s - loss: 1.4398 - mse: 1.4398 - 2ms/epoch - 990us/step\n",
      "Epoch 338/500\n",
      "2/2 - 0s - loss: 1.4540 - mse: 1.4540 - 2ms/epoch - 1ms/step\n",
      "Epoch 339/500\n",
      "2/2 - 0s - loss: 1.4223 - mse: 1.4223 - 2ms/epoch - 966us/step\n",
      "Epoch 340/500\n",
      "2/2 - 0s - loss: 1.4253 - mse: 1.4253 - 2ms/epoch - 999us/step\n",
      "Epoch 341/500\n",
      "2/2 - 0s - loss: 1.4338 - mse: 1.4338 - 2ms/epoch - 1ms/step\n",
      "Epoch 342/500\n",
      "2/2 - 0s - loss: 1.9302 - mse: 1.9302 - 2ms/epoch - 962us/step\n",
      "Epoch 343/500\n",
      "2/2 - 0s - loss: 2.8797 - mse: 2.8797 - 2ms/epoch - 1ms/step\n",
      "Epoch 344/500\n",
      "2/2 - 0s - loss: 1.4476 - mse: 1.4476 - 2ms/epoch - 997us/step\n",
      "Epoch 345/500\n",
      "2/2 - 0s - loss: 1.8424 - mse: 1.8424 - 3ms/epoch - 2ms/step\n",
      "Epoch 346/500\n",
      "2/2 - 0s - loss: 1.8867 - mse: 1.8867 - 2ms/epoch - 999us/step\n",
      "Epoch 347/500\n",
      "2/2 - 0s - loss: 1.5137 - mse: 1.5137 - 2ms/epoch - 1ms/step\n",
      "Epoch 348/500\n",
      "2/2 - 0s - loss: 1.4845 - mse: 1.4845 - 2ms/epoch - 969us/step\n",
      "Epoch 349/500\n",
      "2/2 - 0s - loss: 2.1528 - mse: 2.1528 - 2ms/epoch - 1000us/step\n",
      "Epoch 350/500\n",
      "2/2 - 0s - loss: 2.3118 - mse: 2.3118 - 2ms/epoch - 1ms/step\n",
      "Epoch 351/500\n",
      "2/2 - 0s - loss: 1.7434 - mse: 1.7434 - 2ms/epoch - 1000us/step\n",
      "Epoch 352/500\n",
      "2/2 - 0s - loss: 1.6627 - mse: 1.6627 - 2ms/epoch - 1ms/step\n",
      "Epoch 353/500\n",
      "2/2 - 0s - loss: 1.4808 - mse: 1.4808 - 998us/epoch - 499us/step\n",
      "Epoch 354/500\n",
      "2/2 - 0s - loss: 1.6120 - mse: 1.6120 - 2ms/epoch - 997us/step\n",
      "Epoch 355/500\n",
      "2/2 - 0s - loss: 2.5222 - mse: 2.5222 - 2ms/epoch - 1ms/step\n",
      "Epoch 356/500\n",
      "2/2 - 0s - loss: 2.1621 - mse: 2.1621 - 2ms/epoch - 1ms/step\n",
      "Epoch 357/500\n",
      "2/2 - 0s - loss: 1.4600 - mse: 1.4600 - 2ms/epoch - 981us/step\n",
      "Epoch 358/500\n",
      "2/2 - 0s - loss: 1.4086 - mse: 1.4086 - 2ms/epoch - 1ms/step\n",
      "Epoch 359/500\n",
      "2/2 - 0s - loss: 1.7621 - mse: 1.7621 - 2ms/epoch - 1ms/step\n",
      "Epoch 360/500\n",
      "2/2 - 0s - loss: 2.0407 - mse: 2.0407 - 2ms/epoch - 999us/step\n",
      "Epoch 361/500\n",
      "2/2 - 0s - loss: 1.6432 - mse: 1.6432 - 2ms/epoch - 1000us/step\n",
      "Epoch 362/500\n",
      "2/2 - 0s - loss: 1.4359 - mse: 1.4359 - 3ms/epoch - 2ms/step\n",
      "Epoch 363/500\n",
      "2/2 - 0s - loss: 1.6208 - mse: 1.6208 - 2ms/epoch - 999us/step\n",
      "Epoch 364/500\n",
      "2/2 - 0s - loss: 1.4632 - mse: 1.4632 - 925us/epoch - 462us/step\n",
      "Epoch 365/500\n",
      "2/2 - 0s - loss: 1.6941 - mse: 1.6941 - 3ms/epoch - 1ms/step\n",
      "Epoch 366/500\n",
      "2/2 - 0s - loss: 1.9094 - mse: 1.9094 - 2ms/epoch - 1ms/step\n",
      "Epoch 367/500\n",
      "2/2 - 0s - loss: 1.5664 - mse: 1.5664 - 2ms/epoch - 1ms/step\n",
      "Epoch 368/500\n",
      "2/2 - 0s - loss: 1.8283 - mse: 1.8283 - 2ms/epoch - 1ms/step\n",
      "Epoch 369/500\n",
      "2/2 - 0s - loss: 1.9807 - mse: 1.9807 - 2ms/epoch - 1ms/step\n",
      "Epoch 370/500\n",
      "2/2 - 0s - loss: 1.4053 - mse: 1.4053 - 2ms/epoch - 976us/step\n",
      "Epoch 371/500\n",
      "2/2 - 0s - loss: 1.6442 - mse: 1.6442 - 3ms/epoch - 2ms/step\n",
      "Epoch 372/500\n",
      "2/2 - 0s - loss: 2.5571 - mse: 2.5571 - 2ms/epoch - 997us/step\n",
      "Epoch 373/500\n",
      "2/2 - 0s - loss: 1.8718 - mse: 1.8718 - 2ms/epoch - 973us/step\n",
      "Epoch 374/500\n",
      "2/2 - 0s - loss: 1.4616 - mse: 1.4616 - 2ms/epoch - 971us/step\n",
      "Epoch 375/500\n",
      "2/2 - 0s - loss: 1.4564 - mse: 1.4564 - 2ms/epoch - 1ms/step\n",
      "Epoch 376/500\n",
      "2/2 - 0s - loss: 1.7557 - mse: 1.7557 - 2ms/epoch - 1ms/step\n",
      "Epoch 377/500\n",
      "2/2 - 0s - loss: 1.9114 - mse: 1.9114 - 2ms/epoch - 1000us/step\n",
      "Epoch 378/500\n",
      "2/2 - 0s - loss: 1.6467 - mse: 1.6467 - 2ms/epoch - 1ms/step\n",
      "Epoch 379/500\n",
      "2/2 - 0s - loss: 1.4041 - mse: 1.4041 - 2ms/epoch - 1ms/step\n",
      "Epoch 380/500\n",
      "2/2 - 0s - loss: 1.4270 - mse: 1.4270 - 1ms/epoch - 502us/step\n",
      "Epoch 381/500\n",
      "2/2 - 0s - loss: 2.0966 - mse: 2.0966 - 2ms/epoch - 927us/step\n",
      "Epoch 382/500\n",
      "2/2 - 0s - loss: 1.7737 - mse: 1.7737 - 2ms/epoch - 1ms/step\n",
      "Epoch 383/500\n",
      "2/2 - 0s - loss: 1.5691 - mse: 1.5691 - 1ms/epoch - 500us/step\n",
      "Epoch 384/500\n",
      "2/2 - 0s - loss: 1.4845 - mse: 1.4845 - 1ms/epoch - 502us/step\n",
      "Epoch 385/500\n",
      "2/2 - 0s - loss: 1.7464 - mse: 1.7464 - 2ms/epoch - 1ms/step\n",
      "Epoch 386/500\n",
      "2/2 - 0s - loss: 1.7364 - mse: 1.7364 - 993us/epoch - 497us/step\n",
      "Epoch 387/500\n",
      "2/2 - 0s - loss: 1.3948 - mse: 1.3948 - 3ms/epoch - 2ms/step\n",
      "Epoch 388/500\n",
      "2/2 - 0s - loss: 1.3998 - mse: 1.3998 - 3ms/epoch - 2ms/step\n",
      "Epoch 389/500\n",
      "2/2 - 0s - loss: 1.7793 - mse: 1.7793 - 3ms/epoch - 1ms/step\n",
      "Epoch 390/500\n",
      "2/2 - 0s - loss: 2.4253 - mse: 2.4253 - 2ms/epoch - 1ms/step\n",
      "Epoch 391/500\n",
      "2/2 - 0s - loss: 2.3272 - mse: 2.3272 - 2ms/epoch - 997us/step\n",
      "Epoch 392/500\n",
      "2/2 - 0s - loss: 1.8707 - mse: 1.8707 - 2ms/epoch - 999us/step\n",
      "Epoch 393/500\n",
      "2/2 - 0s - loss: 1.5296 - mse: 1.5296 - 2ms/epoch - 1ms/step\n",
      "Epoch 394/500\n",
      "2/2 - 0s - loss: 1.3931 - mse: 1.3931 - 2ms/epoch - 1ms/step\n",
      "Epoch 395/500\n",
      "2/2 - 0s - loss: 1.3924 - mse: 1.3924 - 2ms/epoch - 997us/step\n",
      "Epoch 396/500\n",
      "2/2 - 0s - loss: 1.4407 - mse: 1.4407 - 2ms/epoch - 1000us/step\n",
      "Epoch 397/500\n",
      "2/2 - 0s - loss: 1.4639 - mse: 1.4639 - 2ms/epoch - 999us/step\n",
      "Epoch 398/500\n",
      "2/2 - 0s - loss: 2.7627 - mse: 2.7627 - 2ms/epoch - 1000us/step\n",
      "Epoch 399/500\n",
      "2/2 - 0s - loss: 1.9397 - mse: 1.9397 - 2ms/epoch - 1ms/step\n",
      "Epoch 400/500\n",
      "2/2 - 0s - loss: 1.4474 - mse: 1.4474 - 998us/epoch - 499us/step\n",
      "Epoch 401/500\n",
      "2/2 - 0s - loss: 1.4070 - mse: 1.4070 - 2ms/epoch - 1000us/step\n",
      "Epoch 402/500\n",
      "2/2 - 0s - loss: 1.3986 - mse: 1.3986 - 2ms/epoch - 1ms/step\n",
      "Epoch 403/500\n",
      "2/2 - 0s - loss: 1.3783 - mse: 1.3783 - 2ms/epoch - 997us/step\n",
      "Epoch 404/500\n",
      "2/2 - 0s - loss: 2.3083 - mse: 2.3083 - 1ms/epoch - 732us/step\n",
      "Epoch 405/500\n",
      "2/2 - 0s - loss: 1.8657 - mse: 1.8657 - 3ms/epoch - 1ms/step\n",
      "Epoch 406/500\n",
      "2/2 - 0s - loss: 1.3848 - mse: 1.3848 - 2ms/epoch - 942us/step\n",
      "Epoch 407/500\n",
      "2/2 - 0s - loss: 1.4400 - mse: 1.4400 - 2ms/epoch - 999us/step\n",
      "Epoch 408/500\n",
      "2/2 - 0s - loss: 1.6055 - mse: 1.6055 - 2ms/epoch - 998us/step\n",
      "Epoch 409/500\n",
      "2/2 - 0s - loss: 1.4702 - mse: 1.4702 - 2ms/epoch - 996us/step\n",
      "Epoch 410/500\n",
      "2/2 - 0s - loss: 2.0334 - mse: 2.0334 - 2ms/epoch - 1ms/step\n",
      "Epoch 411/500\n",
      "2/2 - 0s - loss: 1.4322 - mse: 1.4322 - 1ms/epoch - 503us/step\n",
      "Epoch 412/500\n",
      "2/2 - 0s - loss: 1.5281 - mse: 1.5281 - 2ms/epoch - 999us/step\n",
      "Epoch 413/500\n",
      "2/2 - 0s - loss: 1.4272 - mse: 1.4272 - 2ms/epoch - 999us/step\n",
      "Epoch 414/500\n",
      "2/2 - 0s - loss: 1.5689 - mse: 1.5689 - 2ms/epoch - 1ms/step\n",
      "Epoch 415/500\n",
      "2/2 - 0s - loss: 1.4056 - mse: 1.4056 - 2ms/epoch - 1ms/step\n",
      "Epoch 416/500\n",
      "2/2 - 0s - loss: 1.3693 - mse: 1.3693 - 2ms/epoch - 997us/step\n",
      "Epoch 417/500\n",
      "2/2 - 0s - loss: 1.6816 - mse: 1.6816 - 2ms/epoch - 1000us/step\n",
      "Epoch 418/500\n",
      "2/2 - 0s - loss: 1.5952 - mse: 1.5952 - 1ms/epoch - 522us/step\n",
      "Epoch 419/500\n",
      "2/2 - 0s - loss: 1.6488 - mse: 1.6488 - 1ms/epoch - 500us/step\n",
      "Epoch 420/500\n",
      "2/2 - 0s - loss: 1.5664 - mse: 1.5664 - 2ms/epoch - 1ms/step\n",
      "Epoch 421/500\n",
      "2/2 - 0s - loss: 2.2957 - mse: 2.2957 - 2ms/epoch - 1ms/step\n",
      "Epoch 422/500\n",
      "2/2 - 0s - loss: 2.0783 - mse: 2.0783 - 999us/epoch - 499us/step\n",
      "Epoch 423/500\n",
      "2/2 - 0s - loss: 1.4120 - mse: 1.4120 - 2ms/epoch - 1ms/step\n",
      "Epoch 424/500\n",
      "2/2 - 0s - loss: 1.6497 - mse: 1.6497 - 2ms/epoch - 1ms/step\n",
      "Epoch 425/500\n",
      "2/2 - 0s - loss: 1.4194 - mse: 1.4194 - 3ms/epoch - 2ms/step\n",
      "Epoch 426/500\n",
      "2/2 - 0s - loss: 2.0864 - mse: 2.0864 - 2ms/epoch - 998us/step\n",
      "Epoch 427/500\n",
      "2/2 - 0s - loss: 2.4692 - mse: 2.4692 - 2ms/epoch - 999us/step\n",
      "Epoch 428/500\n",
      "2/2 - 0s - loss: 1.3555 - mse: 1.3555 - 2ms/epoch - 1ms/step\n",
      "Epoch 429/500\n",
      "2/2 - 0s - loss: 1.7047 - mse: 1.7047 - 2ms/epoch - 1ms/step\n",
      "Epoch 430/500\n",
      "2/2 - 0s - loss: 1.4941 - mse: 1.4941 - 3ms/epoch - 2ms/step\n",
      "Epoch 431/500\n",
      "2/2 - 0s - loss: 1.4961 - mse: 1.4961 - 2ms/epoch - 997us/step\n",
      "Epoch 432/500\n",
      "2/2 - 0s - loss: 1.8657 - mse: 1.8657 - 2ms/epoch - 1ms/step\n",
      "Epoch 433/500\n",
      "2/2 - 0s - loss: 2.5157 - mse: 2.5157 - 2ms/epoch - 996us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 434/500\n",
      "2/2 - 0s - loss: 1.5080 - mse: 1.5080 - 2ms/epoch - 998us/step\n",
      "Epoch 435/500\n",
      "2/2 - 0s - loss: 1.4225 - mse: 1.4225 - 2ms/epoch - 1ms/step\n",
      "Epoch 436/500\n",
      "2/2 - 0s - loss: 1.6395 - mse: 1.6395 - 2ms/epoch - 1ms/step\n",
      "Epoch 437/500\n",
      "2/2 - 0s - loss: 1.4904 - mse: 1.4904 - 2ms/epoch - 1ms/step\n",
      "Epoch 438/500\n",
      "2/2 - 0s - loss: 1.3546 - mse: 1.3546 - 2ms/epoch - 996us/step\n",
      "Epoch 439/500\n",
      "2/2 - 0s - loss: 1.4081 - mse: 1.4081 - 997us/epoch - 498us/step\n",
      "Epoch 440/500\n",
      "2/2 - 0s - loss: 1.6068 - mse: 1.6068 - 2ms/epoch - 759us/step\n",
      "Epoch 441/500\n",
      "2/2 - 0s - loss: 3.0164 - mse: 3.0164 - 2ms/epoch - 1ms/step\n",
      "Epoch 442/500\n",
      "2/2 - 0s - loss: 1.8740 - mse: 1.8740 - 993us/epoch - 497us/step\n",
      "Epoch 443/500\n",
      "2/2 - 0s - loss: 1.3765 - mse: 1.3765 - 2ms/epoch - 998us/step\n",
      "Epoch 444/500\n",
      "2/2 - 0s - loss: 1.3352 - mse: 1.3352 - 1ms/epoch - 500us/step\n",
      "Epoch 445/500\n",
      "2/2 - 0s - loss: 1.3370 - mse: 1.3370 - 3ms/epoch - 1ms/step\n",
      "Epoch 446/500\n",
      "2/2 - 0s - loss: 1.3315 - mse: 1.3315 - 2ms/epoch - 1ms/step\n",
      "Epoch 447/500\n",
      "2/2 - 0s - loss: 1.3309 - mse: 1.3309 - 2ms/epoch - 1ms/step\n",
      "Epoch 448/500\n",
      "2/2 - 0s - loss: 1.5313 - mse: 1.5313 - 999us/epoch - 499us/step\n",
      "Epoch 449/500\n",
      "2/2 - 0s - loss: 1.3329 - mse: 1.3329 - 2ms/epoch - 998us/step\n",
      "Epoch 450/500\n",
      "2/2 - 0s - loss: 1.3245 - mse: 1.3245 - 2ms/epoch - 1ms/step\n",
      "Epoch 451/500\n",
      "2/2 - 0s - loss: 1.6668 - mse: 1.6668 - 2ms/epoch - 1ms/step\n",
      "Epoch 452/500\n",
      "2/2 - 0s - loss: 2.9201 - mse: 2.9201 - 2ms/epoch - 1ms/step\n",
      "Epoch 453/500\n",
      "2/2 - 0s - loss: 1.7265 - mse: 1.7265 - 3ms/epoch - 2ms/step\n",
      "Epoch 454/500\n",
      "2/2 - 0s - loss: 1.4273 - mse: 1.4273 - 901us/epoch - 451us/step\n",
      "Epoch 455/500\n",
      "2/2 - 0s - loss: 1.3240 - mse: 1.3240 - 2ms/epoch - 1ms/step\n",
      "Epoch 456/500\n",
      "2/2 - 0s - loss: 1.3680 - mse: 1.3680 - 3ms/epoch - 2ms/step\n",
      "Epoch 457/500\n",
      "2/2 - 0s - loss: 1.3180 - mse: 1.3180 - 2ms/epoch - 999us/step\n",
      "Epoch 458/500\n",
      "2/2 - 0s - loss: 1.7046 - mse: 1.7046 - 2ms/epoch - 1ms/step\n",
      "Epoch 459/500\n",
      "2/2 - 0s - loss: 2.1017 - mse: 2.1017 - 3ms/epoch - 2ms/step\n",
      "Epoch 460/500\n",
      "2/2 - 0s - loss: 2.5270 - mse: 2.5270 - 2ms/epoch - 1ms/step\n",
      "Epoch 461/500\n",
      "2/2 - 0s - loss: 1.6848 - mse: 1.6848 - 3ms/epoch - 2ms/step\n",
      "Epoch 462/500\n",
      "2/2 - 0s - loss: 1.3323 - mse: 1.3323 - 3ms/epoch - 2ms/step\n",
      "Epoch 463/500\n",
      "2/2 - 0s - loss: 1.5882 - mse: 1.5882 - 3ms/epoch - 1ms/step\n",
      "Epoch 464/500\n",
      "2/2 - 0s - loss: 1.4279 - mse: 1.4279 - 2ms/epoch - 1ms/step\n",
      "Epoch 465/500\n",
      "2/2 - 0s - loss: 1.3537 - mse: 1.3537 - 2ms/epoch - 998us/step\n",
      "Epoch 466/500\n",
      "2/2 - 0s - loss: 1.5045 - mse: 1.5045 - 3ms/epoch - 2ms/step\n",
      "Epoch 467/500\n",
      "2/2 - 0s - loss: 2.2879 - mse: 2.2879 - 3ms/epoch - 2ms/step\n",
      "Epoch 468/500\n",
      "2/2 - 0s - loss: 1.4578 - mse: 1.4578 - 2ms/epoch - 1ms/step\n",
      "Epoch 469/500\n",
      "2/2 - 0s - loss: 1.3162 - mse: 1.3162 - 2ms/epoch - 972us/step\n",
      "Epoch 470/500\n",
      "2/2 - 0s - loss: 1.3294 - mse: 1.3294 - 2ms/epoch - 1ms/step\n",
      "Epoch 471/500\n",
      "2/2 - 0s - loss: 1.5673 - mse: 1.5673 - 3ms/epoch - 2ms/step\n",
      "Epoch 472/500\n",
      "2/2 - 0s - loss: 1.7042 - mse: 1.7042 - 2ms/epoch - 981us/step\n",
      "Epoch 473/500\n",
      "2/2 - 0s - loss: 1.7012 - mse: 1.7012 - 3ms/epoch - 1ms/step\n",
      "Epoch 474/500\n",
      "2/2 - 0s - loss: 1.3349 - mse: 1.3349 - 2ms/epoch - 999us/step\n",
      "Epoch 475/500\n",
      "2/2 - 0s - loss: 1.6146 - mse: 1.6146 - 2ms/epoch - 998us/step\n",
      "Epoch 476/500\n",
      "2/2 - 0s - loss: 2.7085 - mse: 2.7085 - 3ms/epoch - 2ms/step\n",
      "Epoch 477/500\n",
      "2/2 - 0s - loss: 1.4791 - mse: 1.4791 - 2ms/epoch - 999us/step\n",
      "Epoch 478/500\n",
      "2/2 - 0s - loss: 1.3083 - mse: 1.3083 - 2ms/epoch - 979us/step\n",
      "Epoch 479/500\n",
      "2/2 - 0s - loss: 1.3054 - mse: 1.3054 - 945us/epoch - 473us/step\n",
      "Epoch 480/500\n",
      "2/2 - 0s - loss: 1.3300 - mse: 1.3300 - 2ms/epoch - 1ms/step\n",
      "Epoch 481/500\n",
      "2/2 - 0s - loss: 1.3059 - mse: 1.3059 - 2ms/epoch - 1ms/step\n",
      "Epoch 482/500\n",
      "2/2 - 0s - loss: 1.3074 - mse: 1.3074 - 2ms/epoch - 961us/step\n",
      "Epoch 483/500\n",
      "2/2 - 0s - loss: 1.3792 - mse: 1.3792 - 2ms/epoch - 1ms/step\n",
      "Epoch 484/500\n",
      "2/2 - 0s - loss: 1.9211 - mse: 1.9211 - 2ms/epoch - 969us/step\n",
      "Epoch 485/500\n",
      "2/2 - 0s - loss: 1.4866 - mse: 1.4866 - 2ms/epoch - 1ms/step\n",
      "Epoch 486/500\n",
      "2/2 - 0s - loss: 1.2986 - mse: 1.2986 - 1ms/epoch - 501us/step\n",
      "Epoch 487/500\n",
      "2/2 - 0s - loss: 1.4803 - mse: 1.4803 - 2ms/epoch - 992us/step\n",
      "Epoch 488/500\n",
      "2/2 - 0s - loss: 2.6936 - mse: 2.6936 - 1ms/epoch - 723us/step\n",
      "Epoch 489/500\n",
      "2/2 - 0s - loss: 1.8916 - mse: 1.8916 - 2ms/epoch - 1ms/step\n",
      "Epoch 490/500\n",
      "2/2 - 0s - loss: 1.6356 - mse: 1.6356 - 2ms/epoch - 998us/step\n",
      "Epoch 491/500\n",
      "2/2 - 0s - loss: 2.0445 - mse: 2.0445 - 2ms/epoch - 997us/step\n",
      "Epoch 492/500\n",
      "2/2 - 0s - loss: 1.3491 - mse: 1.3491 - 2ms/epoch - 1ms/step\n",
      "Epoch 493/500\n",
      "2/2 - 0s - loss: 1.4733 - mse: 1.4733 - 2ms/epoch - 966us/step\n",
      "Epoch 494/500\n",
      "2/2 - 0s - loss: 1.3295 - mse: 1.3295 - 3ms/epoch - 1ms/step\n",
      "Epoch 495/500\n",
      "2/2 - 0s - loss: 1.5381 - mse: 1.5381 - 1ms/epoch - 501us/step\n",
      "Epoch 496/500\n",
      "2/2 - 0s - loss: 1.6967 - mse: 1.6967 - 998us/epoch - 499us/step\n",
      "Epoch 497/500\n",
      "2/2 - 0s - loss: 1.8209 - mse: 1.8209 - 2ms/epoch - 1ms/step\n",
      "Epoch 498/500\n",
      "2/2 - 0s - loss: 1.4700 - mse: 1.4700 - 2ms/epoch - 1ms/step\n",
      "Epoch 499/500\n",
      "2/2 - 0s - loss: 1.2945 - mse: 1.2945 - 3ms/epoch - 1ms/step\n",
      "Epoch 500/500\n",
      "2/2 - 0s - loss: 1.3064 - mse: 1.3064 - 2ms/epoch - 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16020175e20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=500, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_init_1</th>\n",
       "      <th>pred_sigmoid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>20.272116</td>\n",
       "      <td>20.272116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>20.923376</td>\n",
       "      <td>20.923376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>20.144960</td>\n",
       "      <td>20.144960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>22.679586</td>\n",
       "      <td>22.679586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>13.580787</td>\n",
       "      <td>13.580787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_init_1  pred_sigmoid\n",
       "abbrev                                  \n",
       "AL       18.8    20.272116     20.272116\n",
       "AK       18.1    20.923376     20.923376\n",
       "AZ       18.6    20.144960     20.144960\n",
       "AR       22.4    22.679586     22.679586\n",
       "CA       12.0    13.580787     13.580787"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsel['pred_sigmoid'] = y_pred\n",
    "dfsel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.691730806098838"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfsel.total - dfsel.pred_sigmoid)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe the numbers for the `weights`\n",
    "\n",
    "> - Have they changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.827578  , -0.45941237, -0.3763797 ],\n",
       "        [-0.48245475,  0.08536316, -0.31611   ],\n",
       "        [-0.91175246,  0.03069235, -0.16080949],\n",
       "        [-0.59526706, -0.5959313 ,  0.7179946 ],\n",
       "        [-0.5259173 , -0.86582124,  0.47071943],\n",
       "        [ 0.3168695 ,  0.42715016,  0.01607331]], dtype=float32),\n",
       " array([-0.05608859,  0.05262501,  0.05809495], dtype=float32),\n",
       " array([[-0.6676559 ],\n",
       "        [ 0.45542368],\n",
       "        [ 0.10350178]], dtype=float32),\n",
       " array([0.05511758], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `linear` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16020413c40>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mse', metrics=['mse'])\n",
    "\n",
    "model.fit(X, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_init_1</th>\n",
       "      <th>pred_sigmoid</th>\n",
       "      <th>pred_linear</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>20.272116</td>\n",
       "      <td>20.272116</td>\n",
       "      <td>17.985182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>20.923376</td>\n",
       "      <td>20.923376</td>\n",
       "      <td>16.618864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>20.144960</td>\n",
       "      <td>20.144960</td>\n",
       "      <td>17.495176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>22.679586</td>\n",
       "      <td>22.679586</td>\n",
       "      <td>20.307585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>13.580787</td>\n",
       "      <td>13.580787</td>\n",
       "      <td>13.075163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_init_1  pred_sigmoid  pred_linear\n",
       "abbrev                                               \n",
       "AL       18.8    20.272116     20.272116    17.985182\n",
       "AK       18.1    20.923376     20.923376    16.618864\n",
       "AZ       18.6    20.144960     20.144960    17.495176\n",
       "AR       22.4    22.679586     22.679586    20.307585\n",
       "CA       12.0    13.580787     13.580787    13.075163"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X)\n",
    "\n",
    "dfsel['pred_linear'] = y_pred\n",
    "dfsel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.691730806098838"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfsel.total - dfsel.pred_sigmoid)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `tanh` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x160202e9880>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='tanh'))\n",
    "\n",
    "model.compile(loss='mse', metrics=['mse'])\n",
    "\n",
    "model.fit(X, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_init_1</th>\n",
       "      <th>pred_sigmoid</th>\n",
       "      <th>pred_linear</th>\n",
       "      <th>pred_tanh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>20.272116</td>\n",
       "      <td>20.272116</td>\n",
       "      <td>17.985182</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>20.923376</td>\n",
       "      <td>20.923376</td>\n",
       "      <td>16.618864</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>20.144960</td>\n",
       "      <td>20.144960</td>\n",
       "      <td>17.495176</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>22.679586</td>\n",
       "      <td>22.679586</td>\n",
       "      <td>20.307585</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>13.580787</td>\n",
       "      <td>13.580787</td>\n",
       "      <td>13.075163</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_init_1  pred_sigmoid  pred_linear  pred_tanh\n",
       "abbrev                                                          \n",
       "AL       18.8    20.272116     20.272116    17.985182       -1.0\n",
       "AK       18.1    20.923376     20.923376    16.618864       -1.0\n",
       "AZ       18.6    20.144960     20.144960    17.495176       -1.0\n",
       "AR       22.4    22.679586     22.679586    20.307585       -1.0\n",
       "CA       12.0    13.580787     13.580787    13.075163       -1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X)\n",
    "\n",
    "dfsel['pred_tanh'] = y_pred\n",
    "dfsel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.691730806098838"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfsel.total - dfsel.pred_sigmoid)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `relu` activation in last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x160209edf40>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mse', metrics=['mse'])\n",
    "\n",
    "model.fit(X, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_init_1</th>\n",
       "      <th>pred_sigmoid</th>\n",
       "      <th>pred_linear</th>\n",
       "      <th>pred_tanh</th>\n",
       "      <th>pred_relu</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>20.272116</td>\n",
       "      <td>20.272116</td>\n",
       "      <td>17.985182</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>20.923376</td>\n",
       "      <td>20.923376</td>\n",
       "      <td>16.618864</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>20.144960</td>\n",
       "      <td>20.144960</td>\n",
       "      <td>17.495176</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>22.679586</td>\n",
       "      <td>22.679586</td>\n",
       "      <td>20.307585</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>13.580787</td>\n",
       "      <td>13.580787</td>\n",
       "      <td>13.075163</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_init_1  pred_sigmoid  pred_linear  pred_tanh  pred_relu\n",
       "abbrev                                                                     \n",
       "AL       18.8    20.272116     20.272116    17.985182       -1.0        0.0\n",
       "AK       18.1    20.923376     20.923376    16.618864       -1.0        0.0\n",
       "AZ       18.6    20.144960     20.144960    17.495176       -1.0        0.0\n",
       "AR       22.4    22.679586     22.679586    20.307585       -1.0        0.0\n",
       "CA       12.0    13.580787     13.580787    13.075163       -1.0        0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X)\n",
    "\n",
    "dfsel['pred_relu'] = y_pred\n",
    "dfsel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.691730806098838"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfsel.total - dfsel.pred_sigmoid)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How are the predictions changing? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16023340370>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform', activation='relu'))\n",
    "model.add(layer=Dense(units=1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mse', metrics=['mse'])\n",
    "\n",
    "model.fit(X, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_init_1</th>\n",
       "      <th>pred_sigmoid</th>\n",
       "      <th>pred_linear</th>\n",
       "      <th>pred_tanh</th>\n",
       "      <th>pred_relu</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>20.272116</td>\n",
       "      <td>20.272116</td>\n",
       "      <td>0.973202</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>20.923376</td>\n",
       "      <td>20.923376</td>\n",
       "      <td>0.973202</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>20.144960</td>\n",
       "      <td>20.144960</td>\n",
       "      <td>0.973202</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>22.679586</td>\n",
       "      <td>22.679586</td>\n",
       "      <td>0.973202</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>13.580787</td>\n",
       "      <td>13.580787</td>\n",
       "      <td>0.973202</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_init_1  pred_sigmoid  pred_linear  pred_tanh  pred_relu\n",
       "abbrev                                                                     \n",
       "AL       18.8    20.272116     20.272116     0.973202       -1.0        0.0\n",
       "AK       18.1    20.923376     20.923376     0.973202       -1.0        0.0\n",
       "AZ       18.6    20.144960     20.144960     0.973202       -1.0        0.0\n",
       "AR       22.4    22.679586     22.679586     0.973202       -1.0        0.0\n",
       "CA       12.0    13.580787     13.580787     0.973202       -1.0        0.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X)\n",
    "\n",
    "dfsel['pred_linear'] = y_pred\n",
    "dfsel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.691730806098838"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfsel.total - dfsel.pred_sigmoid)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - https://keras.io/api/optimizers/#available-optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizers comparison in GIF ‚Üí https://mlfromscratch.com/optimizers-explained/#adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tesla's Neural Network Models is composed of 48 models trainned in 70.000 hours of GPU ‚Üí https://tesla.com/ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Year with a 8 GPU Computer ‚Üí https://twitter.com/thirdrowtesla/status/1252723358342377472"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Gradient Descent `SGD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `compile()` the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `fit()` the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X, y, epochs=500, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions vs Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Calculate the Predicted Accidents and\n",
    "> 2. Compare it with the Real Total Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_init_1</th>\n",
       "      <th>pred_sigmoid</th>\n",
       "      <th>pred_linear</th>\n",
       "      <th>pred_tanh</th>\n",
       "      <th>pred_relu</th>\n",
       "      <th>pred_gsd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>20.272116</td>\n",
       "      <td>20.272116</td>\n",
       "      <td>0.973202</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>20.923376</td>\n",
       "      <td>20.923376</td>\n",
       "      <td>0.973202</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>20.144960</td>\n",
       "      <td>20.144960</td>\n",
       "      <td>0.973202</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>22.679586</td>\n",
       "      <td>22.679586</td>\n",
       "      <td>0.973202</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>13.580787</td>\n",
       "      <td>13.580787</td>\n",
       "      <td>0.973202</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_init_1  pred_sigmoid  pred_linear  pred_tanh  pred_relu  \\\n",
       "abbrev                                                                        \n",
       "AL       18.8    20.272116     20.272116     0.973202       -1.0        0.0   \n",
       "AK       18.1    20.923376     20.923376     0.973202       -1.0        0.0   \n",
       "AZ       18.6    20.144960     20.144960     0.973202       -1.0        0.0   \n",
       "AR       22.4    22.679586     22.679586     0.973202       -1.0        0.0   \n",
       "CA       12.0    13.580787     13.580787     0.973202       -1.0        0.0   \n",
       "\n",
       "        pred_gsd  \n",
       "abbrev            \n",
       "AL           0.0  \n",
       "AK           0.0  \n",
       "AZ           0.0  \n",
       "AR           0.0  \n",
       "CA           0.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsel['pred_gsd'] = y_pred\n",
    "dfsel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'pred_sgd'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10668/4078616456.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfsel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdfsel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred_sgd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5485\u001b[0m         ):\n\u001b[0;32m   5486\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'pred_sgd'"
     ]
    }
   ],
   "source": [
    "mse = ((dfsel.total - dfsel.pred_sgd)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe the numbers for the `weights`\n",
    "\n",
    "> - Have they changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.76659054,  0.01941717,  0.6998006 ],\n",
       "        [ 0.27831292, -0.7375144 , -0.23064262],\n",
       "        [-0.18085045,  0.6981566 , -0.4463861 ],\n",
       "        [ 0.54964554,  0.27596498, -0.65408474],\n",
       "        [-0.45607024,  0.72699857, -0.5107513 ],\n",
       "        [ 0.3142885 ,  0.53404367, -0.56087637]], dtype=float32),\n",
       " array([0., 0., 0.], dtype=float32),\n",
       " array([[ 0.30465853],\n",
       "        [-0.1850338 ],\n",
       "        [-0.07273304]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### View History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10668/3041766850.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_loss'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `ADAM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "history = model.fit(X, y, epochs=500, verbose=0, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_init_1</th>\n",
       "      <th>pred_sigmoid</th>\n",
       "      <th>pred_linear</th>\n",
       "      <th>pred_tanh</th>\n",
       "      <th>pred_relu</th>\n",
       "      <th>pred_gsd</th>\n",
       "      <th>pred_adam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>20.272116</td>\n",
       "      <td>20.272116</td>\n",
       "      <td>0.973202</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.502316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>20.923376</td>\n",
       "      <td>20.923376</td>\n",
       "      <td>0.973202</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.745525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>20.144960</td>\n",
       "      <td>20.144960</td>\n",
       "      <td>0.973202</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.255413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>22.679586</td>\n",
       "      <td>22.679586</td>\n",
       "      <td>0.973202</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.887188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>13.580787</td>\n",
       "      <td>13.580787</td>\n",
       "      <td>0.973202</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.768291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_init_1  pred_sigmoid  pred_linear  pred_tanh  pred_relu  \\\n",
       "abbrev                                                                        \n",
       "AL       18.8    20.272116     20.272116     0.973202       -1.0        0.0   \n",
       "AK       18.1    20.923376     20.923376     0.973202       -1.0        0.0   \n",
       "AZ       18.6    20.144960     20.144960     0.973202       -1.0        0.0   \n",
       "AR       22.4    22.679586     22.679586     0.973202       -1.0        0.0   \n",
       "CA       12.0    13.580787     13.580787     0.973202       -1.0        0.0   \n",
       "\n",
       "        pred_gsd  pred_adam  \n",
       "abbrev                       \n",
       "AL           0.0  19.502316  \n",
       "AK           0.0  17.745525  \n",
       "AZ           0.0  17.255413  \n",
       "AR           0.0  19.887188  \n",
       "CA           0.0  13.768291  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X)\n",
    "\n",
    "dfsel['pred_adam'] = y_pred\n",
    "dfsel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5727062906881657"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfsel.total - dfsel.pred_adam)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `RMSPROP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='linear'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['mse'])\n",
    "\n",
    "history = model.fit(X, y, epochs=500, verbose=0, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>pred_init_1</th>\n",
       "      <th>pred_sigmoid</th>\n",
       "      <th>pred_linear</th>\n",
       "      <th>pred_tanh</th>\n",
       "      <th>pred_relu</th>\n",
       "      <th>pred_gsd</th>\n",
       "      <th>pred_adam</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abbrev</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>18.8</td>\n",
       "      <td>20.272116</td>\n",
       "      <td>20.272116</td>\n",
       "      <td>0.973202</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.095829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>18.1</td>\n",
       "      <td>20.923376</td>\n",
       "      <td>20.923376</td>\n",
       "      <td>0.973202</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.338139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>18.6</td>\n",
       "      <td>20.144960</td>\n",
       "      <td>20.144960</td>\n",
       "      <td>0.973202</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.384342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>22.4</td>\n",
       "      <td>22.679586</td>\n",
       "      <td>22.679586</td>\n",
       "      <td>0.973202</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.949863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>12.0</td>\n",
       "      <td>13.580787</td>\n",
       "      <td>13.580787</td>\n",
       "      <td>0.973202</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.331272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        total  pred_init_1  pred_sigmoid  pred_linear  pred_tanh  pred_relu  \\\n",
       "abbrev                                                                        \n",
       "AL       18.8    20.272116     20.272116     0.973202       -1.0        0.0   \n",
       "AK       18.1    20.923376     20.923376     0.973202       -1.0        0.0   \n",
       "AZ       18.6    20.144960     20.144960     0.973202       -1.0        0.0   \n",
       "AR       22.4    22.679586     22.679586     0.973202       -1.0        0.0   \n",
       "CA       12.0    13.580787     13.580787     0.973202       -1.0        0.0   \n",
       "\n",
       "        pred_gsd  pred_adam  \n",
       "abbrev                       \n",
       "AL           0.0  16.095829  \n",
       "AK           0.0  11.338139  \n",
       "AZ           0.0  10.384342  \n",
       "AR           0.0  15.949863  \n",
       "CA           0.0  12.331272  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X)\n",
    "\n",
    "dfsel['pred_adam'] = y_pred\n",
    "dfsel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.014740867368957"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((dfsel.total - dfsel.pred_adam)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAsrElEQVR4nO3de3hd1X3n//dHF0uWZcmyLF+QjO1gk8TYlIsxTknz8IsDOCQBZkJSd3KhKU88DflNkzRtA5Pp0KTDb5Jpp7S0QxoSmJiEQKgTBtoGEscEaCZgMFcbc7HBgOWrfL/KF/n7+2MvmSNFlmX7HB3p6PN6nvOcfb57r33Wkm19vdbae21FBGZmZvlWVuwKmJlZaXKCMTOzgnCCMTOzgnCCMTOzgnCCMTOzgnCCMTOzgnCCMRsAJH1P0n/r47FvSPrAqZ7HrNCcYMzMrCCcYMzMrCCcYMz6KA1N/amkFyTtlXS7pHGSHpS0W9IvJDXkHH+FpBcl7ZD0iKR35+w7V9IzqdyPgOpu3/VhSc+lsr+WdPZJ1vmzklZL2ibpAUmnpbgk3Sxps6SdqU0z0r7LJa1MdVsn6U9O6gdmQ54TjNmJ+ShwCXAm8BHgQeA/A2PI/j39EYCkM4G7gS8CTcBPgX+WNEzSMOD/AN8HRgP/lM5LKnsecAfwH4FG4NvAA5KqTqSikt4P/Hfg48AE4E3gnrT7UuB9qR2jgN8FtqZ9twP/MSJGAjOAh0/ke806OcGYnZi/j4hNEbEO+DdgaUQ8GxEHgPuAc9Nxvwv8a0QsjohDwF8Dw4HfBuYAlcDfRsShiFgEPJXzHZ8Fvh0RSyOiIyIWAgdSuRPxCeCOiHgm1e8G4D2SJgOHgJHAuwBFxEsRsSGVOwRMl1QXEdsj4pkT/F4zwAnG7ERtytne38Pn2rR9GlmPAYCIOAKsBZrTvnXRdaXZN3O2JwFfTsNjOyTtACamcieiex32kPVSmiPiYeAfgP8FbJJ0m6S6dOhHgcuBNyU9Kuk9J/i9ZoATjFmhrCdLFEA250GWJNYBG4DmFOt0es72WuCmiBiV86qJiLtPsQ4jyIbc1gFExC0RcT5wFtlQ2Z+m+FMRcSUwlmwo794T/F4zwAnGrFDuBT4kaa6kSuDLZMNcvwYeBw4DfySpQtK/B2bnlP0O8IeSLkyT8SMkfUjSyBOsww+Bz0g6J83f/H9kQ3pvSLognb8S2Au0Ax1pjugTkurT0N4uoOMUfg42hDnBmBVARLwCfBL4e2AL2QUBH4mIgxFxEPj3wO8D28nma36SU3YZ2TzMP6T9q9OxJ1qHJcCfAz8m6zWdAcxPu+vIEtl2smG0rWTzRACfAt6QtAv4w9QOsxMmP3DMzMwKwT0YMzMrCCcYMzMrCCcYMzMrCCcYMzMriIpiV2CgGDNmTEyePLnY1TAzG1SefvrpLRHR1NM+J5hk8uTJLFu2rNjVMDMbVCS9eax9HiIzM7OCcIIxM7OCcIIxM7OC8BxMLw4dOkRrayvt7e3FrkrBVVdX09LSQmVlZbGrYmYlwgmmF62trYwcOZLJkyfTdeHb0hIRbN26ldbWVqZMmVLs6phZifAQWS/a29tpbGws6eQCIInGxsYh0VMzs/7jBHMcpZ5cOg2VdppZ/3GCOUUdR4KNu9rZd/BwsatiZjagOMGcoohg86529h0szDOZduzYwa233nrC5S6//HJ27NiR/wqZmfWRE8wp6hxaOlKg5+ocK8F0dPSe0H76058yatSogtTJzKwvfBXZKSpLUxeFem7b9ddfz2uvvcY555xDZWUltbW1TJgwgeeee46VK1dy1VVXsXbtWtrb2/nCF77AggULgLeXvtmzZw8f/OAHee9738uvf/1rmpubuf/++xk+fHhhKmxmljjB9NHX/vlFVq7f1eO+vQcPU1lexrDyE+sQTj+tjhs/clavx3zjG99gxYoVPPfcczzyyCN86EMfYsWKFUcvJ77jjjsYPXo0+/fv54ILLuCjH/0ojY2NXc6xatUq7r77br7zne/w8Y9/nB//+Md88pN+Cq6ZFZYTTB4IoJ+ePD179uwu96rccsst3HfffQCsXbuWVatW/UaCmTJlCueccw4A559/Pm+88Ub/VNbMhjQnmD7qraexcsMu6qoraGmoKXg9RowYcXT7kUce4Re/+AWPP/44NTU1XHzxxT3ey1JVVXV0u7y8nP379xe8nmZmnuTPgzIVbg5m5MiR7N69u8d9O3fupKGhgZqaGl5++WWeeOKJwlTCzOwkuAeTB2WoYFeRNTY2ctFFFzFjxgyGDx/OuHHjju6bN28e//iP/8jZZ5/NO9/5TubMmVOQOpiZnQxFof7rPcjMmjUruj9w7KWXXuLd7373ccuu2rSbivIypowZcdxjB7K+ttfMrJOkpyNiVk/7PESWB2USTtRmZl05weSBBEecX8zMuihYgpF0h6TNklb0sO9PJIWkMTmxGyStlvSKpMty4udLWp723aJ067ykKkk/SvGlkibnlLlG0qr0uqZQbexUpsLNwZiZDVaF7MF8D5jXPShpInAJ8FZObDowHzgrlblVUnna/S1gATAtvTrPeS2wPSKmAjcD30znGg3cCFwIzAZulNSQ57Z1a1PhriIzMxusCpZgIuIxYFsPu24G/oyutyZeCdwTEQciYg2wGpgtaQJQFxGPRzbJcSdwVU6ZhWl7ETA39W4uAxZHxLaI2A4spodEl0/uwZiZ/aZ+nYORdAWwLiKe77arGVib87k1xZrTdvd4lzIRcRjYCTT2cq6e6rNA0jJJy9ra2k6qTVDY+2DMzAarfkswkmqArwL/tafdPcSil/jJlukajLgtImZFxKympqaeDukTDaAeTG1tbbGrYGYG9G8P5gxgCvC8pDeAFuAZSePJehkTc45tAdaneEsPcXLLSKoA6smG5I51roLJejDhS5XNzHL0W4KJiOURMTYiJkfEZLJEcF5EbAQeAOanK8OmkE3mPxkRG4Ddkuak+ZVPA/enUz4AdF4hdjXwcJqn+RlwqaSGNLl/aYoVTJlEUJj1Lr/yla90eR7MX/zFX/C1r32NuXPnct555zFz5kzuv//+Xs5gZlYcBVsqRtLdwMXAGEmtwI0RcXtPx0bEi5LuBVYCh4HPR0TnE7U+R3ZF2nDgwfQCuB34vqTVZD2X+elc2yT9JfBUOu7rEdHTxQYn5sHrYePyHnc1dByh5vARqCqn5xG6Yxg/Ez74jV4PmT9/Pl/84he57rrrALj33nt56KGH+NKXvkRdXR1btmxhzpw5XHHFFUcffmZmNhAULMFExO8dZ//kbp9vAm7q4bhlwIwe4u3Ax45x7juAO06guqfk6O/1Y80AnYJzzz2XzZs3s379etra2mhoaGDChAl86Utf4rHHHqOsrIx169axadMmxo8fn98vNzM7BV7ssq966Wnsaz/EG1v2ckZTLSOq8v8jvfrqq1m0aBEbN25k/vz53HXXXbS1tfH0009TWVnJ5MmTe1ym38ysmJxg8qAidWE6CrRezPz58/nsZz/Lli1bePTRR7n33nsZO3YslZWV/PKXv+TNN98syPeamZ0KJ5g8KC9LCaZAV5GdddZZ7N69m+bmZiZMmMAnPvEJPvKRjzBr1izOOecc3vWudxXke83MToUTTB4cTTAFXPFy+fK3LzAYM2YMjz/+eI/H7dmzp2B1MDM7EV5NOQ/6I8GYmQ02TjB5IIlyyQnGzCyHE8xx9PXu/PKywZ1gvAqBmeWbE0wvqqur2bp1a59++Q7mBBMRbN26lerq6mJXxcxKiCf5e9HS0kJrayt9WWl5y+4DBLC/rarwFSuA6upqWlpajn+gmVkfOcH0orKykilTpvTp2OvueppXNu5myZcvLmylzMwGCQ+R5Un98GHs3H+42NUwMxswnGDypH54JTv3H/RkuZlZ4gSTJ6NqKjnUEew/1HH8g83MhgAnmDypH14JwI59h4pcEzOzgcEJJk9GpQSzc78TjJkZOMHkTX1NlmC27ztY5JqYmQ0MTjB50lSb3f+yZY8TjJkZFDDBSLpD0mZJK3JifyXpZUkvSLpP0qicfTdIWi3pFUmX5cTPl7Q87btF6bnAkqok/SjFl0qanFPmGkmr0uuaQrUxV9PILMG07T7QH19nZjbgFbIH8z1gXrfYYmBGRJwNvArcACBpOjAfOCuVuVVSeSrzLWABMC29Os95LbA9IqYCNwPfTOcaDdwIXAjMBm6U1FCA9nVRP7ySynI5wZiZJQVLMBHxGLCtW+znEdF5N+ITQOfaJFcC90TEgYhYA6wGZkuaANRFxOOR3WByJ3BVTpmFaXsRMDf1bi4DFkfEtojYTpbUuie6vJNEU22VE4yZWVLMOZg/AB5M283A2px9rSnWnLa7x7uUSUlrJ9DYy7l+g6QFkpZJWtaX9caOp2lkFW17nGDMzKBICUbSV4HDwF2doR4Oi17iJ1umazDitoiYFRGzmpqaeq90HzSNdA/GzKxTvyeYNOn+YeAT8fa6Kq3AxJzDWoD1Kd7SQ7xLGUkVQD3ZkNyxzlU4R45AxyEnGDOzHP2aYCTNA74CXBER+3J2PQDMT1eGTSGbzH8yIjYAuyXNSfMrnwbuzynTeYXY1cDDKWH9DLhUUkOa3L80xQpj1wb4yzHw7A9oqq1i294Dg/a5MGZm+VSw5fol3Q1cDIyR1Ep2ZdcNQBWwOF1t/ERE/GFEvCjpXmAl2dDZ5yOic1Gvz5FdkTacbM6mc97mduD7klaT9VzmA0TENkl/CTyVjvt6RHS52CCvhjdAdMC+LTSNrOJIwNa9Bxg70g/vMrOhrWAJJiJ+r4fw7b0cfxNwUw/xZcCMHuLtwMeOca47gDv6XNlTUVkNw2ph3zaaWt6+F8YJxsyGOt/Jnw81jbB3i2+2NDPL4QSTDzWN2RBZbdZrcYIxM3OCyY8RY2Df1qM9mM1OMGZmTjB5UdMIe7cyfFg5I6sr2Lyrvdg1MjMrOieYfKhphH1bARhfV81GJxgzMyeYvKhphMP74eBextdXs3GXh8jMzJxg8mHEmOx931bG1VWzaad7MGZmTjD5UJMSzN4tjK+rpm2P7+Y3M3OCyYeaxux93zbG1VfTcSTY4lWVzWyIc4LJh6NDZFkPBmCjh8nMbIhzgsmHmtHZ+963E8wmX0lmZkOcE0w+VI8ClWeT/PXZzZZOMGY21DnB5IN0dLmYxhFVlJfJ98KY2ZDnBJMvI8fB7k2Ul4mxI6vYuNOT/GY2tDnB5EtdM+zKHpw5rq7aQ2RmNuQ5weRL3Wmwax3g5WLMzMAJJn/qToP92+DQfsbX+25+M7OCJRhJd0jaLGlFTmy0pMWSVqX3hpx9N0haLekVSZflxM+XtDztu0XpWcuSqiT9KMWXSpqcU+aa9B2rJF1TqDZ2Udecve9az7i6anYfOMzeA4f75avNzAaiQvZgvgfM6xa7HlgSEdOAJekzkqYD84GzUplbJZWnMt8CFgDT0qvznNcC2yNiKnAz8M10rtHAjcCFwGzgxtxEVjB1p2Xvu9YzPl2q7GEyMxvKCpZgIuIxYFu38JXAwrS9ELgqJ35PRByIiDXAamC2pAlAXUQ8HhEB3NmtTOe5FgFzU+/mMmBxRGyLiO3AYn4z0eVftx4M4GEyMxvS+nsOZlxEbABI72NTvBlYm3Nca4o1p+3u8S5lIuIwsBNo7OVcv0HSAknLJC1ra2s7hWaR04NZ9/bd/LudYMxs6Book/zqIRa9xE+2TNdgxG0RMSsiZjU1NfWposc0bER2R/+u9Yyv71yPzPfCmNnQ1d8JZlMa9iK9b07xVmBiznEtwPoUb+kh3qWMpAqgnmxI7ljnKrx0L0zNsApGVlf4XhgzG9L6O8E8AHRe1XUNcH9OfH66MmwK2WT+k2kYbbekOWl+5dPdynSe62rg4TRP8zPgUkkNaXL/0hQrvLrTYFc2ojeurtorKpvZkFZRqBNLuhu4GBgjqZXsyq5vAPdKuhZ4C/gYQES8KOleYCVwGPh8RHSkU32O7Iq04cCD6QVwO/B9SavJei7z07m2SfpL4Kl03NcjovvFBoVR3wzrnwV8s6WZWcESTET83jF2zT3G8TcBN/UQXwbM6CHeTkpQPey7A7ijz5XNl/qJsG8LHNzHuLpqVq/e0u9VMDMbKAbKJH9pGDUpe9+5lomjh7NpdzsHDnf0XsbMrEQ5weTTqHRtwY61TGqsIQLWbttf3DqZmRWJE0w+1acEs/MtJjWOAODNrXuLWCEzs+JxgsmnkeOhrBJ2vMWk0TUAvLl1X5ErZWZWHE4w+VRWnl1JtmMto0cMo7aqwj0YMxuynGDybdTpsHMtkpjUWMOb29yDMbOhyQkm3+pPhx1vAWQJxkNkZjZEOcHk26iJsHsjHD7A6aNH0Lp9H4c7jhS7VmZm/c4JJt9GTQICdqxlcmMNhzqCDV4yxsyGICeYfBs9JXvfvobTG30lmZkNXU4w+Tb6Hdn7tjVv3wuzzVeSmdnQ4wSTbyOaoHIEbHud8XXVDCsv4y33YMxsCHKCyTcpGybbvobyMtEyeriHyMxsSHKCKYTRU2Db6wBMbhzhe2HMbEhygimEhimw/Q040sHpo2t4a+tesmehmZkNHU4whTB6CnQchF3rmdRYw96DHWzde7DYtTIz61dOMIXQeSXZ9jVMOnqpsq8kM7OhxQmmEBrSvTA5lyq/scXzMGY2tBQlwUj6kqQXJa2QdLekakmjJS2WtCq9N+Qcf4Ok1ZJekXRZTvx8ScvTvlskKcWrJP0oxZdKmtyvDaxvyZbt3/Y6p4+uoaJMvNa2p1+rYGZWbP2eYCQ1A38EzIqIGUA5MB+4HlgSEdOAJekzkqan/WcB84BbJZWn030LWABMS695KX4tsD0ipgI3A9/sh6a9rawcGibB9jVUlpcxqbGG1ZudYMxsaCnWEFkFMFxSBVADrAeuBBam/QuBq9L2lcA9EXEgItYAq4HZkiYAdRHxeGSXaN3ZrUznuRYBczt7N/2m4e1LlaeOrWW1ezBmNsT0KcFI+oKkOmVul/SMpEtP5gsjYh3w18BbwAZgZ0T8HBgXERvSMRuAsalIM7A25xStKdactrvHu5SJiMPATqCxh3YtkLRM0rK2traTac6xNZ4BW1+HCKaOreWtrfs45FWVzWwI6WsP5g8iYhdwKdAEfAb4xsl8YZpbuRKYApwGjJD0yd6K9BCLXuK9lekaiLgtImZFxKympqbeK36ixkyDQ3th13rOaKrl8JHwlWRmNqT0NcF0/sK+HPjfEfE8Pf8S74sPAGsioi0iDgE/AX4b2JSGvUjvm9PxrcDEnPItZENqrWm7e7xLmTQMVw9sO8n6npwxZ2bvW15l6thaAM/DmNmQ0tcE87Skn5MlmJ9JGgmc7HjPW8AcSTVpXmQu8BLwAHBNOuYa4P60/QAwP10ZNoVsMv/JNIy2W9KcdJ5PdyvTea6rgYejv2+lH/PO7H3Lq5zRlCWY19rcgzGzoaOij8ddC5wDvB4R+ySNJhsmO2ERsVTSIuAZ4DDwLHAbUAvcK+lasiT0sXT8i5LuBVam4z8fER3pdJ8DvgcMBx5ML4Dbge9LWk3Wc5l/MnU9JbVjoaoetrzKiKoKTquvdg/GzIaUviaY9wDPRcTeNF9yHvB3J/ulEXEjcGO38AGy3kxPx98E3NRDfBkwo4d4OylBFY0ETWdC2ysAnDG21gnGzIaUvg6RfQvYJ+m3gD8D3iS7LNh6M+ZM2LIKgDOaanmtbQ9HjnjRSzMbGvqaYA6nOYwrgb+LiL8DRhauWiVizDTYsxHadzJ1bC37DnawcVd7sWtlZtYv+ppgdku6AfgU8K/pTvrKwlWrRByd6F91dKLfw2RmNlT0NcH8LtkcyR9ExEayGxn/qmC1KhW+VNnMhrA+JZiUVO4C6iV9GGiPCM/BHE/D5GzRy7ZXGFM7jPrhlV700syGjL4uFfNx4EmyK7M+DiyVdHUhK1YSyiuyJWO2vIqkbE0y92DMbIjo62XKXwUuiIjNAJKagF+QLSRpvRk7HdY9DcAZTSN4+OXNxylgZlYa+joHU9aZXJKtJ1B2aBs/A3a8Cft3MHVsLVv2HGTHPj8+2cxKX1+TxEOSfibp9yX9PvCvwE8LV60SMv7s7H3Ti0cn+j0PY2ZDQV8n+f+UbDmXs4HfAm6LiK8UsmIlY/zM7H3TCl+qbGZDSl/nYIiIHwM/LmBdSlPtOBjRBBtfoOWCGoZVlHnRSzMbEnpNMJJ208NzVMiW6o+IqCtIrUqJlPViNi6nvEy8Y8wI92DMbEjoNcFEhJeDyYfxM+GJb0HHIc4YW8vy1p3FrpGZWcH5SrD+MP5s6DiY3dHfVMva7ftoP9Rx/HJmZoOYE0x/GJeeKLBxOVPH1hIBa7Z4HsbMSpsTTH9onAoV1UcTDPhKMjMrfU4w/aG8Irujf+MLTBkzAskJxsxKX1ESjKRRkhZJelnSS5LeI2m0pMWSVqX3hpzjb5C0WtIrki7LiZ8vaXnad4skpXiVpB+l+FJJk4vQzK7Gz4SNK6iuKGPS6Bpe3bS72DUyMyuoYvVg/g54KCLeRXbj5kvA9cCSiJgGLEmfkTQdmA+cBcwDbk3Po4HsSZsLgGnpNS/FrwW2R8RU4Gbgm/3RqF6Nnwn7t8Gu9Zx1Wj0r1vtKMjMrbf2eYCTVAe8DbgeIiIMRsYPsaZkL02ELgavS9pXAPRFxICLWAKuB2ZImAHUR8Xh62uad3cp0nmsRMLezd1M0nUvGbFzOjOZ61m7b7zXJzKykFaMH8w6gDfjfkp6V9F1JI4BxEbEBIL2PTcc3A2tzyremWHPa7h7vUiYiDgM7gcbuFZG0QNIyScva2try1b6ejZsOCDYuZ2ZzPQAr1u0q7HeamRVRMRJMBXAe8K2IOBfYSxoOO4aeeh7RS7y3Ml0DEbdFxKyImNXU1NR7rU9V1UgYPQU2vsBZp2ULIHiYzMxKWTESTCvQGhFL0+dFZAlnUxr2Ir1vzjl+Yk75FmB9irf0EO9SRlIFUA9sy3tLTlRaMqZhxDBaGoazfJ0TjJmVrn5PMOnxy2slvTOF5gIrgQeAa1LsGuD+tP0AMD9dGTaFbDL/yTSMtlvSnDS/8uluZTrPdTXwcJqnKa7xM2H7GmjfxczmelY4wZhZCevzasp59p+AuyQNA14HPkOW7O6VdC3wFtnjmYmIFyXdS5aEDgOfj4jOdVY+B3wPGA48mF6QXUDwfUmryXou8/ujUcfVOdG/eSUzmsfw4IqN7Nx/iPrhlcWtl5lZARQlwUTEc8CsHnbNPcbxNwE39RBfBszoId5OSlADSuezYTYuZ0bzVQC8uH4nv33GmOLVycysQHwnf38aOQFqGmHjC8zonOj3MJmZlSgnmP6U82yYxtoqTquv9qXKZlaynGD62/iZsGkldBxihif6zayEOcH0t+bzoeMAbHyBmc31vL5lL7vbDxW7VmZmeecE099aZmfva59kRrqjf+V6D5OZWelxgulv9c1QPxHWLj2aYHzDpZmVIieYYph4Iax9kqaRVYyvq/Y8jJmVJCeYYph4IexaBzvWMqO5jhUeIjOzEuQEUwwTO+dhsmGy19r2sPfA4eLWycwsz5xgimHcDKisgbVPMrO5nghYucG9GDMrLU4wxVBekV2unDPR73kYMys1TjDFcvoc2LiccdUdNI2s8pVkZlZynGCKZeKFEB2w7mkv3W9mJckJplha0mLSa5cy47Q6Vm/ew/6DHb2XMTMbRJxgimV4AzS96+gd/Uc80W9mJcYJppgmzk5Xko0EPNFvZqXFCaaYJs6B9h2MP/gWY2qreH7tjmLXyMwsb4qWYCSVS3pW0r+kz6MlLZa0Kr035Bx7g6TVkl6RdFlO/HxJy9O+WyQpxask/SjFl0qa3O8N7IuJFwKgtU9yzsRRPOcEY2YlpJg9mC8AL+V8vh5YEhHTgCXpM5KmA/OBs4B5wK2SylOZbwELgGnpNS/FrwW2R8RU4Gbgm4VtyklqPAOGj4a1T3Lu6aN4fctedu7z0v1mVhqKkmAktQAfAr6bE74SWJi2FwJX5cTviYgDEbEGWA3MljQBqIuIxyMigDu7lek81yJgbmfvZkCR0sKXSzl34igAnmvdUdQqmZnlS7F6MH8L/BlwJCc2LiI2AKT3sSneDKzNOa41xZrTdvd4lzIRcRjYCTR2r4SkBZKWSVrW1tZ2ik06SRNnw9ZVnD36MBI8+9b24tTDzCzP+j3BSPowsDkinu5rkR5i0Uu8tzJdAxG3RcSsiJjV1NTUx+rk2elzAKjdtIxpY2s9D2NmJaMYPZiLgCskvQHcA7xf0g+ATWnYi/S+OR3fCkzMKd8CrE/xlh7iXcpIqgDqgW2FaMwpaz4/W/hyzaOcM3EUz6/dQTbiZ2Y2uPV7gomIGyKiJSImk03ePxwRnwQeAK5Jh10D3J+2HwDmpyvDppBN5j+ZhtF2S5qT5lc+3a1M57muTt8xMH9rV1TBpIvgtV9y7ukNbN93iDe37it2rczMTtlAug/mG8AlklYBl6TPRMSLwL3ASuAh4PMR0bmmyufILhRYDbwGPJjitwONklYDf0y6Im3AesfFsHUVsxqyxOJhMjMrBRXF/PKIeAR4JG1vBeYe47ibgJt6iC8DZvQQbwc+lseqFtYZ/0/2tvspaoY18exb27nq3ObjFDIzG9gGUg9m6Bo7HYaPpmztE8xsrncPxsxKghPMQCBBywXQuozzJjXw4vpd7DvoRyib2eDmBDNQtFwAbS/z3pYKDh8Jlr3h+2HMbHBzghkopvwOALM6nqeiTPz6ta1FrpCZ2alxghkoWi6A4Q1Uvb6YcyaO4vHXnWDMbHBzghkoysph6gdg1WLe844GlrfuYFe7F740s8HLCWYgmXYZ7NvCJfXrOBLw1JqBufiAmVlfOMEMJFPngsqYvudxqirK+L+rPUxmZoOXE8xAUjMaWmZT8dpiZk1u4NevbSl2jczMTpoTzEBz5qWw4Xk+0BK8vHE3W/ccKHaNzMxOihPMQDMteyL0+yueB/DlymY2aDnBDDTjzoK6Zia2/Rsjqyv4t1VFehCamdkpcoIZaCSYdillax7h4jPqeOzVLX4+jJkNSk4wA9GZl8HBPfy7xrfYuKudVZv3FLtGZmYnzAlmIJryPiivYvahZQA89qqHycxs8HGCGYiGjYApv0Ptm0s4o2kEjzrBmNkg5AQzUE27DLa9xr87/QBPrtlG+6GO45cxMxtA+j3BSJoo6ZeSXpL0oqQvpPhoSYslrUrvDTllbpC0WtIrki7LiZ8vaXnad4skpXiVpB+l+FJJk/u7nafszKyZH6x8mgOHj7DUy8aY2SBTjB7MYeDLEfFuYA7weUnTgeuBJRExDViSPpP2zQfOAuYBt0oqT+f6FrAAmJZe81L8WmB7REwFbga+2R8Ny6uGSTD+bKa0LWFYRZnnYcxs0On3BBMRGyLimbS9G3gJaAauBBamwxYCV6XtK4F7IuJARKwBVgOzJU0A6iLi8ciu472zW5nOcy0C5nb2bgaV6VdStm4Z8yZ2sOSlTb5c2cwGlaLOwaShq3OBpcC4iNgAWRICxqbDmoG1OcVaU6w5bXePdykTEYeBnUBjQRpRSNOvAuAzDct5Y+s+nnlrR1GrY2Z2IoqWYCTVAj8GvhgRu3o7tIdY9BLvrUz3OiyQtEzSsra2ATgENWYqjD2LmbseobqyjJ8803r8MmZmA0RREoykSrLkcldE/CSFN6VhL9L75hRvBSbmFG8B1qd4Sw/xLmUkVQD1wG/MkkfEbRExKyJmNTU15aNp+Tf9Cipal/LxMyv45+fX+2oyMxs0inEVmYDbgZci4m9ydj0AXJO2rwHuz4nPT1eGTSGbzH8yDaPtljQnnfPT3cp0nutq4OEYrBMYMz8GwLU1j7Cr/TBLXtp8nAJmZgNDMXowFwGfAt4v6bn0uhz4BnCJpFXAJekzEfEicC+wEngI+HxEdP43/nPAd8km/l8DHkzx24FGSauBPyZdkTYoNZ4BZ87j9Nfu4fSRHiYzs8Gjor+/MCJ+Rc9zJABzj1HmJuCmHuLLgBk9xNuBj51CNQeW91yHFn6E66cs5z+9MoO23QdoGllV7FqZmfXKd/IPBpN/B8bNZO7ORXQcOcL9z60rdo3MzI7LCWYwkOA911G17RU+PXYNP3nGCcbMBj4nmMFixkdhxFgWDHuIlRt28dKG3q7sNjMrPieYwaKiCmZ/lpYtv+Ld5Rv4wRNvFrtGZma9coIZTGb9AZRX8RfjHuWfnm6lbfeBYtfIzOyYnGAGkxFj4Lfmc8HOn1PbsYPv/XpNsWtkZnZMTjCDzZzrKOto56bxv+LOx99kd/uhYtfIzKxHTjCDzdh3wYyPctmuf6KufQM/XPpWsWtkZtYjJ5jB6ANfo0xl/HXDT/jur9Z4fTIzG5CcYAajURPhoj/iPfsfZdKe57nvWd8XY2YDjxPMYHXRF4iRp/HfR/yQ2x5ZxeGOI8WukZlZF04wg9WwEeiSrzHt8Gpm7XyIbz/2erFrZGbWhRPMYDbzY0TLBfyX6kXc8YtneHH9zmLXyMzsKCeYwUxCl/8VdbGL/znsNv74nuc4cNgT/mY2MDjBDHannYsu+ToXx1NcuvVO/mbxq8WukZkZ4ARTGuZcB2fP58uVi9jyq+/x0IqNxa6RmZkTTEmQ4Iq/p2Py+/hm5Xf4+T1/z7+tait2rcxsiHOCKRUVwyiffxdMvJC/qfgHlt755/z0Bd8fY2bFU9IJRtI8Sa9IWi3p+mLXp+Cq66i45v9w4J1X8ifldzN+0RXc/L0fsmnn/mLXzMyGIEVEsetQEJLKgVeBS4BW4Cng9yJiZU/Hz5o1K5YtW9aPNSygCA4+ezeHHvzPjDi0nZdiEqtGX0zD1AuZ8K4LaD7tdKqrq5BU7Jqa2SAn6emImNXTvor+rkw/mg2sjojXASTdA1wJ9JhgSorEsPP+A8Omf5itT/yAuifv5MPb76TsqYVZmgX2RDUHVUlQxhHKOII4QhkCRABBGV3/8xEovZOOEqf635NhHKaCw+ynmo4eO9S53/mbe6o4wDAOsZ9qDlFO5JxDbxfPi95aG+nncbJy/6N3rMR/6j/tk/F2Xbq3r/PvSU/H5/7dONGfSz7+yHr7SR3r/MdqX+e/g9y//yfXpt7//PL1V/Vk/p60jZjGuX/yz3mqwdtKOcE0A2tzPrcCF+YeIGkBsADg9NNP77+a9ZfqOhovvg4uvo6O/btY+/JStq15ngO7tlDWvp2OwwdRdKDI0oviSM4/IhHK0g0pAqB4O70c7x9MXxxRBR2qpPLIfsqi63I3nWfv/M6evu1QWRUdqqQq2imPDjr/+Ufko3Y96fproPM7ute9+/7elClLKhJEQMeRk/n12LM4Romev6Hr0V1/UUWX+Nu/YN9OrF1TStdvUET6+9TT1/b9T6qvRx79Jqnr3+CIY/5MupaPt//TkFNvRYB6ac9x2nIiiamznif+H5c44TKH6qec4Hf0TSknmOP+u4qI24DbIBsi649KFUv58DomnnsJE8+9pNhVMbMhopQn+VuBiTmfW4D1RaqLmdmQU8oJ5ilgmqQpkoYB84EHilwnM7Mho2SHyCLisKT/F/gZUA7cEREvFrlaZmZDRskmGICI+Cnw02LXw8xsKCrlITIzMysiJxgzMysIJxgzMysIJxgzMyuIkl2L7ERJagPePIVTjAG25Kk6g4XbPDS4zUPDybZ5UkQ09bTDCSZPJC071oJvpcptHhrc5qGhEG32EJmZmRWEE4yZmRWEE0z+3FbsChSB2zw0uM1DQ97b7DkYMzMrCPdgzMysIJxgzMysIJxgTpGkeZJekbRa0vXFrk++SLpD0mZJK3JioyUtlrQqvTfk7Lsh/QxekXRZcWp9aiRNlPRLSS9JelHSF1K8ZNstqVrSk5KeT23+WoqXbJs7SSqX9Kykf0mfS7rNkt6QtFzSc5KWpVhh2xwRfp3ki+wxAK8B7wCGAc8D04tdrzy17X3AecCKnNj/AK5P29cD30zb01Pbq4Ap6WdSXuw2nESbJwDnpe2RwKupbSXbbrInv9am7UpgKTCnlNuc0/Y/Bn4I/Ev6XNJtBt4AxnSLFbTN7sGcmtnA6oh4PSIOAvcAVxa5TnkREY8B27qFrwQWpu2FwFU58Xsi4kBErAFWk/1sBpWI2BARz6Tt3cBLQDMl3O7I7EkfK9MrKOE2A0hqAT4EfDcnXNJtPoaCttkJ5tQ0A2tzPremWKkaFxEbIPtlDIxN8ZL7OUiaDJxL9j/6km53Gip6DtgMLI6Ikm8z8LfAnwFHcmKl3uYAfi7paUkLUqygbS7pB471A/UQG4rXfZfUz0FSLfBj4IsRsUvqqXnZoT3EBl27I6IDOEfSKOA+STN6OXzQt1nSh4HNEfG0pIv7UqSH2KBqc3JRRKyXNBZYLOnlXo7NS5vdgzk1rcDEnM8twPoi1aU/bJI0ASC9b07xkvk5SKokSy53RcRPUrjk2w0QETuAR4B5lHabLwKukPQG2bD2+yX9gNJuMxGxPr1vBu4jG/IqaJudYE7NU8A0SVMkDQPmAw8UuU6F9ABwTdq+Brg/Jz5fUpWkKcA04Mki1O+UKOuq3A68FBF/k7OrZNstqSn1XJA0HPgA8DIl3OaIuCEiWiJiMtm/2Ycj4pOUcJsljZA0snMbuBRYQaHbXOwrGwb7C7ic7Gqj14CvFrs+eWzX3cAG4BDZ/2auBRqBJcCq9D465/ivpp/BK8AHi13/k2zze8mGAV4Ankuvy0u53cDZwLOpzSuA/5riJdvmbu2/mLevIivZNpNd6fp8er3Y+buq0G32UjFmZlYQHiIzM7OCcIIxM7OCcIIxM7OCcIIxM7OCcIIxM7OCcIIxKwGSLu5cFdhsoHCCMTOzgnCCMetHkj6Znr/ynKRvp4Um90j6n5KekbREUlM69hxJT0h6QdJ9nc/qkDRV0i/SM1yekXRGOn2tpEWSXpZ0l3pZRM2sPzjBmPUTSe8Gfpds0cFzgA7gE8AI4JmIOA94FLgxFbkT+EpEnA0sz4nfBfyviPgt4LfJVlyAbPXnL5I9y+MdZGtumRWNV1M26z9zgfOBp1LnYjjZ4oJHgB+lY34A/ERSPTAqIh5N8YXAP6X1pJoj4j6AiGgHSOd7MiJa0+fngMnArwreKrNjcIIx6z8CFkbEDV2C0p93O6639Zt6G/Y6kLPdgf99W5F5iMys/ywBrk7P4+h8Hvoksn+HV6dj/gPwq4jYCWyX9Dsp/ing0YjYBbRKuiqdo0pSTX82wqyv/D8cs34SESsl/ReypwqWka1U/XlgL3CWpKeBnWTzNJAtn/6PKYG8DnwmxT8FfFvS19M5PtaPzTDrM6+mbFZkkvZERG2x62GWbx4iMzOzgnAPxszMCsI9GDMzKwgnGDMzKwgnGDMzKwgnGDMzKwgnGDMzK4j/H449CsCoRyvmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does it take different times to get the best accuracy? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - https://keras.io/api/losses/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `binary_crossentropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'explanatory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10668/1622948362.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplanatory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'explanatory' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layer=Input(shape=(6,)))\n",
    "model.add(layer=Dense(units=3, kernel_initializer='glorot_uniform'))\n",
    "model.add(layer=Dense(units=1, activation='linear'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['mse'])\n",
    "\n",
    "X = explanatory\n",
    "y = target\n",
    "\n",
    "history = model.fit(X, y, epochs=500, verbose=2, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sparse_categorical_crossentropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `mean_absolute_error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `mean_squared_error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the end, what should be a feasible configuration of the Neural Network for this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `kernel_initializer` Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `activation` Function Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `optimizer` Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Number of `epochs` Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `loss` Function Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Number of `epochs` Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network's importance to find **Non-Linear Patterns** in the Data\n",
    "\n",
    "> - The number of Neurons & Hidden Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/beginners-ask-how-many-hidden-layers-neurons-to-use-in-artificial-neural-networks-51466afa0d3e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.87287&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Mathematical Formula\n",
    "- Weights / Kernel Initializer\n",
    "- Loss Function\n",
    "- Activation Function\n",
    "- Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What cannot you change arbitrarily of a Neural Network?\n",
    "\n",
    "- Input Neurons\n",
    "- Output Neurons\n",
    "- Loss Functions\n",
    "- Activation Functions"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Jes√∫s L√≥pez @sotastica"
   }
  ],
  "interpreter": {
   "hash": "a2b8701b642343483c5f5e717bcb0768c6b951acf38d76a6fc8ea01492bda71d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
